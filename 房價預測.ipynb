{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da152cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5eaac9c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21613, 21)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"kc_house_data.csv\")\n",
    "# 顯示dataset的形狀，共21613比資料，每一比資料有21種不同資訊。\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c1a463f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7129300520</td>\n",
       "      <td>20141013T000000</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6414100192</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>400</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5631500400</td>\n",
       "      <td>20150225T000000</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2487200875</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>910</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954400510</td>\n",
       "      <td>20150218T000000</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id             date     price  bedrooms  bathrooms  sqft_living  \\\n",
       "0  7129300520  20141013T000000  221900.0         3       1.00         1180   \n",
       "1  6414100192  20141209T000000  538000.0         3       2.25         2570   \n",
       "2  5631500400  20150225T000000  180000.0         2       1.00          770   \n",
       "3  2487200875  20141209T000000  604000.0         4       3.00         1960   \n",
       "4  1954400510  20150218T000000  510000.0         3       2.00         1680   \n",
       "\n",
       "   sqft_lot  floors  waterfront  view  condition  grade  sqft_above  \\\n",
       "0      5650     1.0           0     0          3      7        1180   \n",
       "1      7242     2.0           0     0          3      7        2170   \n",
       "2     10000     1.0           0     0          3      6         770   \n",
       "3      5000     1.0           0     0          5      7        1050   \n",
       "4      8080     1.0           0     0          3      8        1680   \n",
       "\n",
       "   sqft_basement  yr_built  yr_renovated  zipcode      lat     long  \\\n",
       "0              0      1955             0    98178  47.5112 -122.257   \n",
       "1            400      1951          1991    98125  47.7210 -122.319   \n",
       "2              0      1933             0    98028  47.7379 -122.233   \n",
       "3            910      1965             0    98136  47.5208 -122.393   \n",
       "4              0      1987             0    98074  47.6168 -122.045   \n",
       "\n",
       "   sqft_living15  sqft_lot15  \n",
       "0           1340        5650  \n",
       "1           1690        7639  \n",
       "2           2720        8062  \n",
       "3           1360        5000  \n",
       "4           1800        7503  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 將顯示列數設定為25，不然會有部份資料無法顯示\n",
    "pd.options.display.max_columns = 25\n",
    "# head 會顯示前五行的數據\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3205a1ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                 int64\n",
       "date              object\n",
       "price            float64\n",
       "bedrooms           int64\n",
       "bathrooms        float64\n",
       "sqft_living        int64\n",
       "sqft_lot           int64\n",
       "floors           float64\n",
       "waterfront         int64\n",
       "view               int64\n",
       "condition          int64\n",
       "grade              int64\n",
       "sqft_above         int64\n",
       "sqft_basement      int64\n",
       "yr_built           int64\n",
       "yr_renovated       int64\n",
       "zipcode            int64\n",
       "lat              float64\n",
       "long             float64\n",
       "sqft_living15      int64\n",
       "sqft_lot15         int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c159c3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "      <td>2014</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>400</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>910</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      price  bedrooms  bathrooms  sqft_living  sqft_lot  floors  waterfront  \\\n",
       "0  221900.0         3       1.00         1180      5650     1.0           0   \n",
       "1  538000.0         3       2.25         2570      7242     2.0           0   \n",
       "2  180000.0         2       1.00          770     10000     1.0           0   \n",
       "3  604000.0         4       3.00         1960      5000     1.0           0   \n",
       "4  510000.0         3       2.00         1680      8080     1.0           0   \n",
       "\n",
       "   view  condition  grade  sqft_above  sqft_basement  yr_built  yr_renovated  \\\n",
       "0     0          3      7        1180              0      1955             0   \n",
       "1     0          3      7        2170            400      1951          1991   \n",
       "2     0          3      6         770              0      1933             0   \n",
       "3     0          5      7        1050            910      1965             0   \n",
       "4     0          3      8        1680              0      1987             0   \n",
       "\n",
       "   zipcode      lat     long  sqft_living15  sqft_lot15  year  month  day  \n",
       "0    98178  47.5112 -122.257           1340        5650  2014     10   13  \n",
       "1    98125  47.7210 -122.319           1690        7639  2014     12    9  \n",
       "2    98028  47.7379 -122.233           2720        8062  2015      2   25  \n",
       "3    98136  47.5208 -122.393           1360        5000  2014     12    9  \n",
       "4    98074  47.6168 -122.045           1800        7503  2015      2   18  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 將date日期拆為年、月和日並轉成數值\n",
    "data['year'] = pd.to_numeric(data['date'].str.slice(0, 4))\n",
    "data['month'] = pd.to_numeric(data['date'].str.slice(4, 6))\n",
    "data['day'] = pd.to_numeric(data['date'].str.slice(6, 8))\n",
    "\n",
    "# 刪除沒有用的數據，inplace則是將更新後的資料存回原本的地方\n",
    "data.drop(['id'], axis=\"columns\", inplace=True)\n",
    "data.drop(['date'], axis=\"columns\", inplace=True)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce6ece50",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_num = data.shape[0]\n",
    "# 取得一筆與data數量相同的亂數索引，主要目的是用於打散資料\n",
    "indexes = np.random.permutation(data_num)\n",
    "# 並將亂數索引值分為Train、validation和test分為，這裡的劃分比例為8:1:1\n",
    "train_indexes = indexes[:int(data_num *0.8)]\n",
    "val_indexes = indexes[int(data_num *0.8):int(data_num *0.9)]\n",
    "test_indexes = indexes[int(data_num *0.9):]\n",
    "# 透過索引值從data取出訓練資料、驗證資料和測試資料\n",
    "train_data = data.loc[train_indexes]\n",
    "val_data = data.loc[val_indexes]\n",
    "test_data = data.loc[test_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b195fcfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_validation_data = pd.concat([train_data, val_data])\n",
    "mean = train_validation_data.mean()\n",
    "std = train_validation_data.std()\n",
    "\n",
    "train_data = (train_data - mean) / std\n",
    "val_data = (val_data - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6dc95d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(train_data.drop('price', axis='columns'))\n",
    "y_train = np.array(train_data['price'])\n",
    "x_val = np.array(val_data.drop('price', axis='columns'))\n",
    "y_val = np.array(val_data['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9e81f78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17290, 21)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af718c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model-1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 64)                1408      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 5,633\n",
      "Trainable params: 5,633\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 建立一個Sequential型態的model\n",
    "model = keras.Sequential(name='model-1')\n",
    "# 第1層全連接層設為64個unit，將輸入形狀設定為(21, )，而實際上我們輸入的數據形狀為(batch_size, 21)\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(21,)))\n",
    "# 第2層全連接層設為64個unit\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "# 最後一層全連接層設為1個unit\n",
    "model.add(layers.Dense(1))\n",
    "# 顯示網路模型架構\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d51c5281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 設定訓練使用的優化器、損失函數和指標函數：\n",
    "model.compile(keras.optimizers.Adam(0.001),\n",
    "              loss=keras.losses.MeanSquaredError(),\n",
    "              metrics=[keras.metrics.MeanAbsoluteError()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d13f9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立模型儲存目錄：\n",
    "model_dir = 'lab2-logs/models/' #儲存Model的位置\n",
    "if not os.path.isdir(model_dir):\n",
    "    os.makedirs(model_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6913d7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 設定回調函數：\n",
    "# TensorBoard回調函數會幫忙紀錄訓練資訊，並存成TensorBoard的紀錄檔\n",
    "log_dir = os.path.join('lab2-logs', 'model-1')\n",
    "model_cbk = keras.callbacks.TensorBoard(log_dir=log_dir)\n",
    "# ModelCheckpoint回調函數幫忙儲存網路模型，可以設定只儲存最好的模型，「monitor」表示被監測的數據，「mode」min則代表監測數據越小越好。\n",
    "model_mckp = keras.callbacks.ModelCheckpoint(model_dir + '/Best-model-1.h5',monitor='val_mean_absolute_error',save_best_only=True,mode='min')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa3d905f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "  1/271 [..............................] - ETA: 0s - loss: 0.6770 - mean_absolute_error: 0.6505WARNING:tensorflow:From C:\\Users\\HUANG\\tf2\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_train_batch_end` time: 0.0168s). Check your callbacks.\n",
      "271/271 [==============================] - 0s 855us/step - loss: 0.2625 - mean_absolute_error: 0.3230 - val_loss: 0.2237 - val_mean_absolute_error: 0.3063\n",
      "Epoch 2/300\n",
      "271/271 [==============================] - 0s 493us/step - loss: 0.1926 - mean_absolute_error: 0.2751 - val_loss: 0.1835 - val_mean_absolute_error: 0.2630\n",
      "Epoch 3/300\n",
      "271/271 [==============================] - 0s 529us/step - loss: 0.1655 - mean_absolute_error: 0.2545 - val_loss: 0.1863 - val_mean_absolute_error: 0.2569\n",
      "Epoch 4/300\n",
      "271/271 [==============================] - 0s 506us/step - loss: 0.1541 - mean_absolute_error: 0.2454 - val_loss: 0.1587 - val_mean_absolute_error: 0.2402\n",
      "Epoch 5/300\n",
      "271/271 [==============================] - 0s 521us/step - loss: 0.1408 - mean_absolute_error: 0.2319 - val_loss: 0.1472 - val_mean_absolute_error: 0.2238\n",
      "Epoch 6/300\n",
      "271/271 [==============================] - 0s 462us/step - loss: 0.1293 - mean_absolute_error: 0.2227 - val_loss: 0.1506 - val_mean_absolute_error: 0.2388\n",
      "Epoch 7/300\n",
      "271/271 [==============================] - 0s 499us/step - loss: 0.1243 - mean_absolute_error: 0.2183 - val_loss: 0.1347 - val_mean_absolute_error: 0.2131\n",
      "Epoch 8/300\n",
      "271/271 [==============================] - 0s 464us/step - loss: 0.1200 - mean_absolute_error: 0.2137 - val_loss: 0.1443 - val_mean_absolute_error: 0.2246\n",
      "Epoch 9/300\n",
      "271/271 [==============================] - 0s 504us/step - loss: 0.1126 - mean_absolute_error: 0.2081 - val_loss: 0.1291 - val_mean_absolute_error: 0.2097\n",
      "Epoch 10/300\n",
      "271/271 [==============================] - 0s 521us/step - loss: 0.1054 - mean_absolute_error: 0.2024 - val_loss: 0.1243 - val_mean_absolute_error: 0.2094\n",
      "Epoch 11/300\n",
      "271/271 [==============================] - 0s 489us/step - loss: 0.1017 - mean_absolute_error: 0.1994 - val_loss: 0.1287 - val_mean_absolute_error: 0.2171\n",
      "Epoch 12/300\n",
      "271/271 [==============================] - 0s 489us/step - loss: 0.1012 - mean_absolute_error: 0.1993 - val_loss: 0.1219 - val_mean_absolute_error: 0.2108\n",
      "Epoch 13/300\n",
      "271/271 [==============================] - 0s 511us/step - loss: 0.0957 - mean_absolute_error: 0.1940 - val_loss: 0.1207 - val_mean_absolute_error: 0.2020\n",
      "Epoch 14/300\n",
      "271/271 [==============================] - 0s 493us/step - loss: 0.0965 - mean_absolute_error: 0.1939 - val_loss: 0.1340 - val_mean_absolute_error: 0.2081\n",
      "Epoch 15/300\n",
      "271/271 [==============================] - 0s 464us/step - loss: 0.0923 - mean_absolute_error: 0.1918 - val_loss: 0.1259 - val_mean_absolute_error: 0.2021\n",
      "Epoch 16/300\n",
      "271/271 [==============================] - 0s 467us/step - loss: 0.0893 - mean_absolute_error: 0.1894 - val_loss: 0.1218 - val_mean_absolute_error: 0.2038\n",
      "Epoch 17/300\n",
      "271/271 [==============================] - 0s 544us/step - loss: 0.0846 - mean_absolute_error: 0.1867 - val_loss: 0.1145 - val_mean_absolute_error: 0.2009\n",
      "Epoch 18/300\n",
      "271/271 [==============================] - 0s 503us/step - loss: 0.0852 - mean_absolute_error: 0.1853 - val_loss: 0.1173 - val_mean_absolute_error: 0.1988\n",
      "Epoch 19/300\n",
      "271/271 [==============================] - 0s 493us/step - loss: 0.0836 - mean_absolute_error: 0.1847 - val_loss: 0.1173 - val_mean_absolute_error: 0.2033\n",
      "Epoch 20/300\n",
      "271/271 [==============================] - 0s 456us/step - loss: 0.0821 - mean_absolute_error: 0.1839 - val_loss: 0.1074 - val_mean_absolute_error: 0.2003\n",
      "Epoch 21/300\n",
      "271/271 [==============================] - 0s 467us/step - loss: 0.0809 - mean_absolute_error: 0.1830 - val_loss: 0.1174 - val_mean_absolute_error: 0.2098\n",
      "Epoch 22/300\n",
      "271/271 [==============================] - 0s 467us/step - loss: 0.0773 - mean_absolute_error: 0.1817 - val_loss: 0.1131 - val_mean_absolute_error: 0.2020\n",
      "Epoch 23/300\n",
      "271/271 [==============================] - 0s 471us/step - loss: 0.0785 - mean_absolute_error: 0.1810 - val_loss: 0.1131 - val_mean_absolute_error: 0.2085\n",
      "Epoch 24/300\n",
      "271/271 [==============================] - 0s 500us/step - loss: 0.0753 - mean_absolute_error: 0.1792 - val_loss: 0.1113 - val_mean_absolute_error: 0.1924\n",
      "Epoch 25/300\n",
      "271/271 [==============================] - 0s 467us/step - loss: 0.0757 - mean_absolute_error: 0.1783 - val_loss: 0.1147 - val_mean_absolute_error: 0.2011\n",
      "Epoch 26/300\n",
      "271/271 [==============================] - 0s 471us/step - loss: 0.0741 - mean_absolute_error: 0.1774 - val_loss: 0.1151 - val_mean_absolute_error: 0.2011\n",
      "Epoch 27/300\n",
      "271/271 [==============================] - 0s 464us/step - loss: 0.0721 - mean_absolute_error: 0.1759 - val_loss: 0.1103 - val_mean_absolute_error: 0.2055\n",
      "Epoch 28/300\n",
      "271/271 [==============================] - 0s 480us/step - loss: 0.0717 - mean_absolute_error: 0.1755 - val_loss: 0.1134 - val_mean_absolute_error: 0.2166\n",
      "Epoch 29/300\n",
      "271/271 [==============================] - 0s 482us/step - loss: 0.0709 - mean_absolute_error: 0.1750 - val_loss: 0.1086 - val_mean_absolute_error: 0.1963\n",
      "Epoch 30/300\n",
      "271/271 [==============================] - 0s 482us/step - loss: 0.0702 - mean_absolute_error: 0.1742 - val_loss: 0.1175 - val_mean_absolute_error: 0.2043\n",
      "Epoch 31/300\n",
      "271/271 [==============================] - 0s 480us/step - loss: 0.0692 - mean_absolute_error: 0.1738 - val_loss: 0.1076 - val_mean_absolute_error: 0.1957\n",
      "Epoch 32/300\n",
      "271/271 [==============================] - 0s 478us/step - loss: 0.0677 - mean_absolute_error: 0.1732 - val_loss: 0.1081 - val_mean_absolute_error: 0.1946\n",
      "Epoch 33/300\n",
      "271/271 [==============================] - 0s 460us/step - loss: 0.0665 - mean_absolute_error: 0.1711 - val_loss: 0.1091 - val_mean_absolute_error: 0.1986\n",
      "Epoch 34/300\n",
      "271/271 [==============================] - 0s 467us/step - loss: 0.0672 - mean_absolute_error: 0.1717 - val_loss: 0.1130 - val_mean_absolute_error: 0.1954\n",
      "Epoch 35/300\n",
      "271/271 [==============================] - 0s 493us/step - loss: 0.0655 - mean_absolute_error: 0.1707 - val_loss: 0.1066 - val_mean_absolute_error: 0.1908\n",
      "Epoch 36/300\n",
      "271/271 [==============================] - 0s 460us/step - loss: 0.0637 - mean_absolute_error: 0.1679 - val_loss: 0.1111 - val_mean_absolute_error: 0.1953\n",
      "Epoch 37/300\n",
      "271/271 [==============================] - 0s 456us/step - loss: 0.0652 - mean_absolute_error: 0.1689 - val_loss: 0.1071 - val_mean_absolute_error: 0.1921\n",
      "Epoch 38/300\n",
      "271/271 [==============================] - 0s 453us/step - loss: 0.0643 - mean_absolute_error: 0.1686 - val_loss: 0.1069 - val_mean_absolute_error: 0.1932\n",
      "Epoch 39/300\n",
      "271/271 [==============================] - 0s 453us/step - loss: 0.0617 - mean_absolute_error: 0.1665 - val_loss: 0.1141 - val_mean_absolute_error: 0.1965\n",
      "Epoch 40/300\n",
      "271/271 [==============================] - 0s 477us/step - loss: 0.0617 - mean_absolute_error: 0.1662 - val_loss: 0.1096 - val_mean_absolute_error: 0.1928\n",
      "Epoch 41/300\n",
      "271/271 [==============================] - 0s 474us/step - loss: 0.0612 - mean_absolute_error: 0.1654 - val_loss: 0.1081 - val_mean_absolute_error: 0.1920\n",
      "Epoch 42/300\n",
      "271/271 [==============================] - 0s 456us/step - loss: 0.0608 - mean_absolute_error: 0.1657 - val_loss: 0.1090 - val_mean_absolute_error: 0.1957\n",
      "Epoch 43/300\n",
      "271/271 [==============================] - 0s 477us/step - loss: 0.0588 - mean_absolute_error: 0.1634 - val_loss: 0.1126 - val_mean_absolute_error: 0.2113\n",
      "Epoch 44/300\n",
      "271/271 [==============================] - 0s 477us/step - loss: 0.0590 - mean_absolute_error: 0.1653 - val_loss: 0.1070 - val_mean_absolute_error: 0.1912\n",
      "Epoch 45/300\n",
      "271/271 [==============================] - 0s 453us/step - loss: 0.0601 - mean_absolute_error: 0.1659 - val_loss: 0.1128 - val_mean_absolute_error: 0.1923\n",
      "Epoch 46/300\n",
      "271/271 [==============================] - 0s 462us/step - loss: 0.0580 - mean_absolute_error: 0.1631 - val_loss: 0.1100 - val_mean_absolute_error: 0.1935\n",
      "Epoch 47/300\n",
      "271/271 [==============================] - 0s 486us/step - loss: 0.0579 - mean_absolute_error: 0.1634 - val_loss: 0.1110 - val_mean_absolute_error: 0.1997\n",
      "Epoch 48/300\n",
      "271/271 [==============================] - 0s 467us/step - loss: 0.0590 - mean_absolute_error: 0.1633 - val_loss: 0.1143 - val_mean_absolute_error: 0.1965\n",
      "Epoch 49/300\n",
      "271/271 [==============================] - 0s 453us/step - loss: 0.0565 - mean_absolute_error: 0.1628 - val_loss: 0.1155 - val_mean_absolute_error: 0.1959\n",
      "Epoch 50/300\n",
      "271/271 [==============================] - 0s 460us/step - loss: 0.0566 - mean_absolute_error: 0.1621 - val_loss: 0.1092 - val_mean_absolute_error: 0.1947\n",
      "Epoch 51/300\n",
      "271/271 [==============================] - 0s 474us/step - loss: 0.0566 - mean_absolute_error: 0.1615 - val_loss: 0.1135 - val_mean_absolute_error: 0.1976\n",
      "Epoch 52/300\n",
      "271/271 [==============================] - 0s 475us/step - loss: 0.0545 - mean_absolute_error: 0.1596 - val_loss: 0.1091 - val_mean_absolute_error: 0.1941\n",
      "Epoch 53/300\n",
      "271/271 [==============================] - 0s 459us/step - loss: 0.0569 - mean_absolute_error: 0.1625 - val_loss: 0.1145 - val_mean_absolute_error: 0.1955\n",
      "Epoch 54/300\n",
      "271/271 [==============================] - 0s 471us/step - loss: 0.0555 - mean_absolute_error: 0.1614 - val_loss: 0.1095 - val_mean_absolute_error: 0.2024\n",
      "Epoch 55/300\n",
      "271/271 [==============================] - 0s 469us/step - loss: 0.0552 - mean_absolute_error: 0.1607 - val_loss: 0.1069 - val_mean_absolute_error: 0.1973\n",
      "Epoch 56/300\n",
      "271/271 [==============================] - 0s 456us/step - loss: 0.0537 - mean_absolute_error: 0.1591 - val_loss: 0.1055 - val_mean_absolute_error: 0.1922\n",
      "Epoch 57/300\n",
      "271/271 [==============================] - 0s 475us/step - loss: 0.0525 - mean_absolute_error: 0.1585 - val_loss: 0.1154 - val_mean_absolute_error: 0.2017\n",
      "Epoch 58/300\n",
      "271/271 [==============================] - 0s 486us/step - loss: 0.0555 - mean_absolute_error: 0.1614 - val_loss: 0.1086 - val_mean_absolute_error: 0.1927\n",
      "Epoch 59/300\n",
      "271/271 [==============================] - 0s 463us/step - loss: 0.0510 - mean_absolute_error: 0.1563 - val_loss: 0.1076 - val_mean_absolute_error: 0.1913\n",
      "Epoch 60/300\n",
      "271/271 [==============================] - 0s 475us/step - loss: 0.0540 - mean_absolute_error: 0.1592 - val_loss: 0.1280 - val_mean_absolute_error: 0.2210\n",
      "Epoch 61/300\n",
      "271/271 [==============================] - 0s 460us/step - loss: 0.0550 - mean_absolute_error: 0.1606 - val_loss: 0.1126 - val_mean_absolute_error: 0.1964\n",
      "Epoch 62/300\n",
      "271/271 [==============================] - 0s 479us/step - loss: 0.0522 - mean_absolute_error: 0.1577 - val_loss: 0.1141 - val_mean_absolute_error: 0.1968\n",
      "Epoch 63/300\n",
      "271/271 [==============================] - 0s 456us/step - loss: 0.0496 - mean_absolute_error: 0.1549 - val_loss: 0.1108 - val_mean_absolute_error: 0.2011\n",
      "Epoch 64/300\n",
      "271/271 [==============================] - 0s 466us/step - loss: 0.0493 - mean_absolute_error: 0.1546 - val_loss: 0.1099 - val_mean_absolute_error: 0.1926\n",
      "Epoch 65/300\n",
      "271/271 [==============================] - 0s 476us/step - loss: 0.0509 - mean_absolute_error: 0.1565 - val_loss: 0.1191 - val_mean_absolute_error: 0.1966\n",
      "Epoch 66/300\n",
      "271/271 [==============================] - 0s 471us/step - loss: 0.0517 - mean_absolute_error: 0.1560 - val_loss: 0.1106 - val_mean_absolute_error: 0.1959\n",
      "Epoch 67/300\n",
      "271/271 [==============================] - 0s 475us/step - loss: 0.0506 - mean_absolute_error: 0.1562 - val_loss: 0.1094 - val_mean_absolute_error: 0.1949\n",
      "Epoch 68/300\n",
      "271/271 [==============================] - 0s 494us/step - loss: 0.0529 - mean_absolute_error: 0.1578 - val_loss: 0.1170 - val_mean_absolute_error: 0.1982\n",
      "Epoch 69/300\n",
      "271/271 [==============================] - 0s 471us/step - loss: 0.0537 - mean_absolute_error: 0.1578 - val_loss: 0.1104 - val_mean_absolute_error: 0.1943\n",
      "Epoch 70/300\n",
      "271/271 [==============================] - 0s 453us/step - loss: 0.0499 - mean_absolute_error: 0.1551 - val_loss: 0.1153 - val_mean_absolute_error: 0.1936\n",
      "Epoch 71/300\n",
      "271/271 [==============================] - 0s 468us/step - loss: 0.0473 - mean_absolute_error: 0.1523 - val_loss: 0.1138 - val_mean_absolute_error: 0.1938\n",
      "Epoch 72/300\n",
      "271/271 [==============================] - 0s 471us/step - loss: 0.0479 - mean_absolute_error: 0.1531 - val_loss: 0.1215 - val_mean_absolute_error: 0.2012\n",
      "Epoch 73/300\n",
      "271/271 [==============================] - 0s 475us/step - loss: 0.0478 - mean_absolute_error: 0.1529 - val_loss: 0.1126 - val_mean_absolute_error: 0.1925\n",
      "Epoch 74/300\n",
      "271/271 [==============================] - 0s 449us/step - loss: 0.0484 - mean_absolute_error: 0.1533 - val_loss: 0.1081 - val_mean_absolute_error: 0.1933\n",
      "Epoch 75/300\n",
      "271/271 [==============================] - 0s 460us/step - loss: 0.0504 - mean_absolute_error: 0.1563 - val_loss: 0.1112 - val_mean_absolute_error: 0.1930\n",
      "Epoch 76/300\n",
      "271/271 [==============================] - 0s 486us/step - loss: 0.0471 - mean_absolute_error: 0.1517 - val_loss: 0.1183 - val_mean_absolute_error: 0.2012\n",
      "Epoch 77/300\n",
      "271/271 [==============================] - 0s 492us/step - loss: 0.0504 - mean_absolute_error: 0.1558 - val_loss: 0.1181 - val_mean_absolute_error: 0.1999\n",
      "Epoch 78/300\n",
      "271/271 [==============================] - 0s 484us/step - loss: 0.0467 - mean_absolute_error: 0.1520 - val_loss: 0.1131 - val_mean_absolute_error: 0.1996\n",
      "Epoch 79/300\n",
      "271/271 [==============================] - 0s 493us/step - loss: 0.0448 - mean_absolute_error: 0.1494 - val_loss: 0.1117 - val_mean_absolute_error: 0.2042\n",
      "Epoch 80/300\n",
      "271/271 [==============================] - 0s 490us/step - loss: 0.0456 - mean_absolute_error: 0.1503 - val_loss: 0.1126 - val_mean_absolute_error: 0.2017\n",
      "Epoch 81/300\n",
      "271/271 [==============================] - 0s 471us/step - loss: 0.0447 - mean_absolute_error: 0.1494 - val_loss: 0.1103 - val_mean_absolute_error: 0.1954\n",
      "Epoch 82/300\n",
      "271/271 [==============================] - 0s 485us/step - loss: 0.0465 - mean_absolute_error: 0.1500 - val_loss: 0.1168 - val_mean_absolute_error: 0.1967\n",
      "Epoch 83/300\n",
      "271/271 [==============================] - 0s 487us/step - loss: 0.0490 - mean_absolute_error: 0.1527 - val_loss: 0.1123 - val_mean_absolute_error: 0.1962\n",
      "Epoch 84/300\n",
      "271/271 [==============================] - 0s 453us/step - loss: 0.0490 - mean_absolute_error: 0.1531 - val_loss: 0.1168 - val_mean_absolute_error: 0.2002\n",
      "Epoch 85/300\n",
      "271/271 [==============================] - 0s 451us/step - loss: 0.0475 - mean_absolute_error: 0.1518 - val_loss: 0.1098 - val_mean_absolute_error: 0.1940\n",
      "Epoch 86/300\n",
      "271/271 [==============================] - 0s 455us/step - loss: 0.0463 - mean_absolute_error: 0.1505 - val_loss: 0.1189 - val_mean_absolute_error: 0.1960\n",
      "Epoch 87/300\n",
      "271/271 [==============================] - 0s 478us/step - loss: 0.0456 - mean_absolute_error: 0.1500 - val_loss: 0.1160 - val_mean_absolute_error: 0.1971\n",
      "Epoch 88/300\n",
      "271/271 [==============================] - 0s 464us/step - loss: 0.0446 - mean_absolute_error: 0.1491 - val_loss: 0.1133 - val_mean_absolute_error: 0.1965\n",
      "Epoch 89/300\n",
      "271/271 [==============================] - 0s 467us/step - loss: 0.0453 - mean_absolute_error: 0.1486 - val_loss: 0.1144 - val_mean_absolute_error: 0.2022\n",
      "Epoch 90/300\n",
      "271/271 [==============================] - 0s 477us/step - loss: 0.0433 - mean_absolute_error: 0.1472 - val_loss: 0.1208 - val_mean_absolute_error: 0.2117\n",
      "Epoch 91/300\n",
      "271/271 [==============================] - 0s 467us/step - loss: 0.0467 - mean_absolute_error: 0.1507 - val_loss: 0.1120 - val_mean_absolute_error: 0.1972\n",
      "Epoch 92/300\n",
      "271/271 [==============================] - 0s 453us/step - loss: 0.0440 - mean_absolute_error: 0.1485 - val_loss: 0.1122 - val_mean_absolute_error: 0.1979\n",
      "Epoch 93/300\n",
      "271/271 [==============================] - 0s 449us/step - loss: 0.0436 - mean_absolute_error: 0.1483 - val_loss: 0.1209 - val_mean_absolute_error: 0.2054\n",
      "Epoch 94/300\n",
      "271/271 [==============================] - 0s 470us/step - loss: 0.0424 - mean_absolute_error: 0.1465 - val_loss: 0.1130 - val_mean_absolute_error: 0.1955\n",
      "Epoch 95/300\n",
      "271/271 [==============================] - 0s 475us/step - loss: 0.0439 - mean_absolute_error: 0.1485 - val_loss: 0.1222 - val_mean_absolute_error: 0.1999\n",
      "Epoch 96/300\n",
      "271/271 [==============================] - 0s 489us/step - loss: 0.0427 - mean_absolute_error: 0.1468 - val_loss: 0.1176 - val_mean_absolute_error: 0.1980\n",
      "Epoch 97/300\n",
      "271/271 [==============================] - 0s 478us/step - loss: 0.0440 - mean_absolute_error: 0.1491 - val_loss: 0.1162 - val_mean_absolute_error: 0.2034\n",
      "Epoch 98/300\n",
      "271/271 [==============================] - 0s 468us/step - loss: 0.0464 - mean_absolute_error: 0.1500 - val_loss: 0.1138 - val_mean_absolute_error: 0.1963\n",
      "Epoch 99/300\n",
      "271/271 [==============================] - 0s 462us/step - loss: 0.0427 - mean_absolute_error: 0.1463 - val_loss: 0.1182 - val_mean_absolute_error: 0.1968\n",
      "Epoch 100/300\n",
      "271/271 [==============================] - 0s 460us/step - loss: 0.0420 - mean_absolute_error: 0.1454 - val_loss: 0.1108 - val_mean_absolute_error: 0.1960\n",
      "Epoch 101/300\n",
      "271/271 [==============================] - 0s 466us/step - loss: 0.0425 - mean_absolute_error: 0.1464 - val_loss: 0.1161 - val_mean_absolute_error: 0.1977\n",
      "Epoch 102/300\n",
      "271/271 [==============================] - 0s 463us/step - loss: 0.0413 - mean_absolute_error: 0.1448 - val_loss: 0.1242 - val_mean_absolute_error: 0.2023\n",
      "Epoch 103/300\n",
      "271/271 [==============================] - 0s 457us/step - loss: 0.0450 - mean_absolute_error: 0.1493 - val_loss: 0.1170 - val_mean_absolute_error: 0.1976\n",
      "Epoch 104/300\n",
      "271/271 [==============================] - 0s 523us/step - loss: 0.0443 - mean_absolute_error: 0.1485 - val_loss: 0.1205 - val_mean_absolute_error: 0.2010\n",
      "Epoch 105/300\n",
      "271/271 [==============================] - 0s 501us/step - loss: 0.0415 - mean_absolute_error: 0.1449 - val_loss: 0.1180 - val_mean_absolute_error: 0.1962\n",
      "Epoch 106/300\n",
      "271/271 [==============================] - 0s 478us/step - loss: 0.0414 - mean_absolute_error: 0.1445 - val_loss: 0.1187 - val_mean_absolute_error: 0.1985\n",
      "Epoch 107/300\n",
      "271/271 [==============================] - 0s 577us/step - loss: 0.0432 - mean_absolute_error: 0.1473 - val_loss: 0.1167 - val_mean_absolute_error: 0.2035\n",
      "Epoch 108/300\n",
      "271/271 [==============================] - 0s 545us/step - loss: 0.0418 - mean_absolute_error: 0.1451 - val_loss: 0.1223 - val_mean_absolute_error: 0.2067\n",
      "Epoch 109/300\n",
      "271/271 [==============================] - 0s 482us/step - loss: 0.0423 - mean_absolute_error: 0.1463 - val_loss: 0.1194 - val_mean_absolute_error: 0.2024\n",
      "Epoch 110/300\n",
      "271/271 [==============================] - 0s 522us/step - loss: 0.0435 - mean_absolute_error: 0.1469 - val_loss: 0.1155 - val_mean_absolute_error: 0.2010\n",
      "Epoch 111/300\n",
      "271/271 [==============================] - 0s 609us/step - loss: 0.0412 - mean_absolute_error: 0.1443 - val_loss: 0.1151 - val_mean_absolute_error: 0.1971\n",
      "Epoch 112/300\n",
      "271/271 [==============================] - 0s 523us/step - loss: 0.0411 - mean_absolute_error: 0.1448 - val_loss: 0.1182 - val_mean_absolute_error: 0.1964\n",
      "Epoch 113/300\n",
      "271/271 [==============================] - 0s 580us/step - loss: 0.0388 - mean_absolute_error: 0.1410 - val_loss: 0.1155 - val_mean_absolute_error: 0.1973\n",
      "Epoch 114/300\n",
      "271/271 [==============================] - 0s 467us/step - loss: 0.0396 - mean_absolute_error: 0.1429 - val_loss: 0.1218 - val_mean_absolute_error: 0.2017\n",
      "Epoch 115/300\n",
      "271/271 [==============================] - 0s 545us/step - loss: 0.0427 - mean_absolute_error: 0.1469 - val_loss: 0.1205 - val_mean_absolute_error: 0.1991\n",
      "Epoch 116/300\n",
      "271/271 [==============================] - ETA: 0s - loss: 0.0445 - mean_absolute_error: 0.147 - 0s 519us/step - loss: 0.0437 - mean_absolute_error: 0.1468 - val_loss: 0.1155 - val_mean_absolute_error: 0.1958\n",
      "Epoch 117/300\n",
      "271/271 [==============================] - 0s 552us/step - loss: 0.0402 - mean_absolute_error: 0.1429 - val_loss: 0.1141 - val_mean_absolute_error: 0.1999\n",
      "Epoch 118/300\n",
      "271/271 [==============================] - 0s 637us/step - loss: 0.0389 - mean_absolute_error: 0.1418 - val_loss: 0.1182 - val_mean_absolute_error: 0.1983\n",
      "Epoch 119/300\n",
      "271/271 [==============================] - 0s 552us/step - loss: 0.0430 - mean_absolute_error: 0.1460 - val_loss: 0.1185 - val_mean_absolute_error: 0.1996\n",
      "Epoch 120/300\n",
      "271/271 [==============================] - 0s 544us/step - loss: 0.0389 - mean_absolute_error: 0.1414 - val_loss: 0.1195 - val_mean_absolute_error: 0.1985\n",
      "Epoch 121/300\n",
      "271/271 [==============================] - 0s 539us/step - loss: 0.0422 - mean_absolute_error: 0.1451 - val_loss: 0.1255 - val_mean_absolute_error: 0.2021\n",
      "Epoch 122/300\n",
      "271/271 [==============================] - 0s 482us/step - loss: 0.0407 - mean_absolute_error: 0.1431 - val_loss: 0.1227 - val_mean_absolute_error: 0.2004\n",
      "Epoch 123/300\n",
      "271/271 [==============================] - 0s 493us/step - loss: 0.0403 - mean_absolute_error: 0.1441 - val_loss: 0.1239 - val_mean_absolute_error: 0.1989\n",
      "Epoch 124/300\n",
      "271/271 [==============================] - 0s 453us/step - loss: 0.0398 - mean_absolute_error: 0.1420 - val_loss: 0.1195 - val_mean_absolute_error: 0.2027\n",
      "Epoch 125/300\n",
      "271/271 [==============================] - 0s 501us/step - loss: 0.0390 - mean_absolute_error: 0.1412 - val_loss: 0.1260 - val_mean_absolute_error: 0.2016\n",
      "Epoch 126/300\n",
      "271/271 [==============================] - 0s 574us/step - loss: 0.0376 - mean_absolute_error: 0.1391 - val_loss: 0.1153 - val_mean_absolute_error: 0.1978\n",
      "Epoch 127/300\n",
      "271/271 [==============================] - 0s 508us/step - loss: 0.0407 - mean_absolute_error: 0.1425 - val_loss: 0.1205 - val_mean_absolute_error: 0.1989\n",
      "Epoch 128/300\n",
      "271/271 [==============================] - 0s 486us/step - loss: 0.0402 - mean_absolute_error: 0.1424 - val_loss: 0.1210 - val_mean_absolute_error: 0.2040\n",
      "Epoch 129/300\n",
      "271/271 [==============================] - 0s 456us/step - loss: 0.0399 - mean_absolute_error: 0.1426 - val_loss: 0.1223 - val_mean_absolute_error: 0.2020\n",
      "Epoch 130/300\n",
      "271/271 [==============================] - 0s 485us/step - loss: 0.0386 - mean_absolute_error: 0.1403 - val_loss: 0.1166 - val_mean_absolute_error: 0.1989\n",
      "Epoch 131/300\n",
      "271/271 [==============================] - 0s 495us/step - loss: 0.0362 - mean_absolute_error: 0.1377 - val_loss: 0.1230 - val_mean_absolute_error: 0.2029\n",
      "Epoch 132/300\n",
      "271/271 [==============================] - 0s 489us/step - loss: 0.0375 - mean_absolute_error: 0.1393 - val_loss: 0.1248 - val_mean_absolute_error: 0.2015\n",
      "Epoch 133/300\n",
      "271/271 [==============================] - 0s 489us/step - loss: 0.0409 - mean_absolute_error: 0.1426 - val_loss: 0.1279 - val_mean_absolute_error: 0.2046\n",
      "Epoch 134/300\n",
      "271/271 [==============================] - 0s 474us/step - loss: 0.0382 - mean_absolute_error: 0.1399 - val_loss: 0.1210 - val_mean_absolute_error: 0.2021\n",
      "Epoch 135/300\n",
      "271/271 [==============================] - 0s 558us/step - loss: 0.0373 - mean_absolute_error: 0.1387 - val_loss: 0.1217 - val_mean_absolute_error: 0.2018\n",
      "Epoch 136/300\n",
      "271/271 [==============================] - 0s 475us/step - loss: 0.0377 - mean_absolute_error: 0.1399 - val_loss: 0.1260 - val_mean_absolute_error: 0.2009\n",
      "Epoch 137/300\n",
      "271/271 [==============================] - 0s 482us/step - loss: 0.0367 - mean_absolute_error: 0.1380 - val_loss: 0.1247 - val_mean_absolute_error: 0.2016\n",
      "Epoch 138/300\n",
      "271/271 [==============================] - 0s 475us/step - loss: 0.0370 - mean_absolute_error: 0.1384 - val_loss: 0.1227 - val_mean_absolute_error: 0.2039\n",
      "Epoch 139/300\n",
      "271/271 [==============================] - 0s 482us/step - loss: 0.0391 - mean_absolute_error: 0.1419 - val_loss: 0.1230 - val_mean_absolute_error: 0.1978\n",
      "Epoch 140/300\n",
      "271/271 [==============================] - 0s 478us/step - loss: 0.0393 - mean_absolute_error: 0.1405 - val_loss: 0.1299 - val_mean_absolute_error: 0.2040\n",
      "Epoch 141/300\n",
      "271/271 [==============================] - 0s 464us/step - loss: 0.0369 - mean_absolute_error: 0.1381 - val_loss: 0.1235 - val_mean_absolute_error: 0.2012\n",
      "Epoch 142/300\n",
      "271/271 [==============================] - 0s 453us/step - loss: 0.0391 - mean_absolute_error: 0.1402 - val_loss: 0.1306 - val_mean_absolute_error: 0.2093\n",
      "Epoch 143/300\n",
      "271/271 [==============================] - 0s 469us/step - loss: 0.0368 - mean_absolute_error: 0.1383 - val_loss: 0.1240 - val_mean_absolute_error: 0.1996\n",
      "Epoch 144/300\n",
      "271/271 [==============================] - 0s 451us/step - loss: 0.0352 - mean_absolute_error: 0.1362 - val_loss: 0.1256 - val_mean_absolute_error: 0.2014\n",
      "Epoch 145/300\n",
      "271/271 [==============================] - 0s 472us/step - loss: 0.0348 - mean_absolute_error: 0.1354 - val_loss: 0.1255 - val_mean_absolute_error: 0.2020\n",
      "Epoch 146/300\n",
      "271/271 [==============================] - 0s 464us/step - loss: 0.0380 - mean_absolute_error: 0.1407 - val_loss: 0.1286 - val_mean_absolute_error: 0.2050\n",
      "Epoch 147/300\n",
      "271/271 [==============================] - 0s 519us/step - loss: 0.0383 - mean_absolute_error: 0.1404 - val_loss: 0.1269 - val_mean_absolute_error: 0.2025\n",
      "Epoch 148/300\n",
      "271/271 [==============================] - 0s 512us/step - loss: 0.0368 - mean_absolute_error: 0.1379 - val_loss: 0.1336 - val_mean_absolute_error: 0.2071\n",
      "Epoch 149/300\n",
      "271/271 [==============================] - 0s 559us/step - loss: 0.0384 - mean_absolute_error: 0.1402 - val_loss: 0.1204 - val_mean_absolute_error: 0.2010\n",
      "Epoch 150/300\n",
      "271/271 [==============================] - 0s 515us/step - loss: 0.0397 - mean_absolute_error: 0.1411 - val_loss: 0.1277 - val_mean_absolute_error: 0.2021\n",
      "Epoch 151/300\n",
      "271/271 [==============================] - 0s 556us/step - loss: 0.0352 - mean_absolute_error: 0.1353 - val_loss: 0.1294 - val_mean_absolute_error: 0.2031\n",
      "Epoch 152/300\n",
      "271/271 [==============================] - 0s 602us/step - loss: 0.0350 - mean_absolute_error: 0.1356 - val_loss: 0.1291 - val_mean_absolute_error: 0.2070\n",
      "Epoch 153/300\n",
      "271/271 [==============================] - 0s 485us/step - loss: 0.0385 - mean_absolute_error: 0.1397 - val_loss: 0.1275 - val_mean_absolute_error: 0.2029\n",
      "Epoch 154/300\n",
      "271/271 [==============================] - 0s 523us/step - loss: 0.0359 - mean_absolute_error: 0.1368 - val_loss: 0.1278 - val_mean_absolute_error: 0.2027\n",
      "Epoch 155/300\n",
      "271/271 [==============================] - 0s 614us/step - loss: 0.0352 - mean_absolute_error: 0.1360 - val_loss: 0.1296 - val_mean_absolute_error: 0.2035\n",
      "Epoch 156/300\n",
      "271/271 [==============================] - 0s 604us/step - loss: 0.0357 - mean_absolute_error: 0.1373 - val_loss: 0.1426 - val_mean_absolute_error: 0.2128\n",
      "Epoch 157/300\n",
      "271/271 [==============================] - 0s 519us/step - loss: 0.0358 - mean_absolute_error: 0.1366 - val_loss: 0.1395 - val_mean_absolute_error: 0.2120\n",
      "Epoch 158/300\n",
      "271/271 [==============================] - 0s 537us/step - loss: 0.0417 - mean_absolute_error: 0.1418 - val_loss: 0.1263 - val_mean_absolute_error: 0.2026\n",
      "Epoch 159/300\n",
      "271/271 [==============================] - 0s 567us/step - loss: 0.0379 - mean_absolute_error: 0.1384 - val_loss: 0.1343 - val_mean_absolute_error: 0.2085\n",
      "Epoch 160/300\n",
      "271/271 [==============================] - 0s 488us/step - loss: 0.0373 - mean_absolute_error: 0.1379 - val_loss: 0.1298 - val_mean_absolute_error: 0.2047\n",
      "Epoch 161/300\n",
      "271/271 [==============================] - 0s 517us/step - loss: 0.0361 - mean_absolute_error: 0.1362 - val_loss: 0.1325 - val_mean_absolute_error: 0.2064\n",
      "Epoch 162/300\n",
      "271/271 [==============================] - 0s 530us/step - loss: 0.0372 - mean_absolute_error: 0.1380 - val_loss: 0.1298 - val_mean_absolute_error: 0.2036\n",
      "Epoch 163/300\n",
      "271/271 [==============================] - 0s 552us/step - loss: 0.0340 - mean_absolute_error: 0.1338 - val_loss: 0.1292 - val_mean_absolute_error: 0.2060\n",
      "Epoch 164/300\n",
      "271/271 [==============================] - 0s 525us/step - loss: 0.0350 - mean_absolute_error: 0.1355 - val_loss: 0.1319 - val_mean_absolute_error: 0.2053\n",
      "Epoch 165/300\n",
      "271/271 [==============================] - 0s 494us/step - loss: 0.0341 - mean_absolute_error: 0.1341 - val_loss: 0.1294 - val_mean_absolute_error: 0.2059\n",
      "Epoch 166/300\n",
      "271/271 [==============================] - 0s 483us/step - loss: 0.0337 - mean_absolute_error: 0.1337 - val_loss: 0.1314 - val_mean_absolute_error: 0.2051\n",
      "Epoch 167/300\n",
      "271/271 [==============================] - 0s 501us/step - loss: 0.0339 - mean_absolute_error: 0.1337 - val_loss: 0.1318 - val_mean_absolute_error: 0.2069\n",
      "Epoch 168/300\n",
      "271/271 [==============================] - 0s 515us/step - loss: 0.0349 - mean_absolute_error: 0.1362 - val_loss: 0.1321 - val_mean_absolute_error: 0.2072\n",
      "Epoch 169/300\n",
      "271/271 [==============================] - 0s 497us/step - loss: 0.0361 - mean_absolute_error: 0.1358 - val_loss: 0.1323 - val_mean_absolute_error: 0.2066\n",
      "Epoch 170/300\n",
      "271/271 [==============================] - 0s 493us/step - loss: 0.0399 - mean_absolute_error: 0.1417 - val_loss: 0.1292 - val_mean_absolute_error: 0.2065\n",
      "Epoch 171/300\n",
      "271/271 [==============================] - 0s 541us/step - loss: 0.0352 - mean_absolute_error: 0.1356 - val_loss: 0.1316 - val_mean_absolute_error: 0.2045\n",
      "Epoch 172/300\n",
      "271/271 [==============================] - 0s 550us/step - loss: 0.0343 - mean_absolute_error: 0.1347 - val_loss: 0.1304 - val_mean_absolute_error: 0.2086\n",
      "Epoch 173/300\n",
      "271/271 [==============================] - 0s 501us/step - loss: 0.0338 - mean_absolute_error: 0.1331 - val_loss: 0.1365 - val_mean_absolute_error: 0.2069\n",
      "Epoch 174/300\n",
      "271/271 [==============================] - 0s 512us/step - loss: 0.0344 - mean_absolute_error: 0.1345 - val_loss: 0.1299 - val_mean_absolute_error: 0.2097\n",
      "Epoch 175/300\n",
      "271/271 [==============================] - 0s 463us/step - loss: 0.0328 - mean_absolute_error: 0.1319 - val_loss: 0.1298 - val_mean_absolute_error: 0.2023\n",
      "Epoch 176/300\n",
      "271/271 [==============================] - 0s 445us/step - loss: 0.0332 - mean_absolute_error: 0.1331 - val_loss: 0.1326 - val_mean_absolute_error: 0.2044\n",
      "Epoch 177/300\n",
      "271/271 [==============================] - 0s 449us/step - loss: 0.0347 - mean_absolute_error: 0.1349 - val_loss: 0.1301 - val_mean_absolute_error: 0.2039\n",
      "Epoch 178/300\n",
      "271/271 [==============================] - 0s 486us/step - loss: 0.0351 - mean_absolute_error: 0.1357 - val_loss: 0.1353 - val_mean_absolute_error: 0.2063\n",
      "Epoch 179/300\n",
      "271/271 [==============================] - 0s 488us/step - loss: 0.0369 - mean_absolute_error: 0.1376 - val_loss: 0.1310 - val_mean_absolute_error: 0.2051\n",
      "Epoch 180/300\n",
      "271/271 [==============================] - 0s 493us/step - loss: 0.0368 - mean_absolute_error: 0.1380 - val_loss: 0.1276 - val_mean_absolute_error: 0.2064\n",
      "Epoch 181/300\n",
      "271/271 [==============================] - 0s 463us/step - loss: 0.0346 - mean_absolute_error: 0.1344 - val_loss: 0.1287 - val_mean_absolute_error: 0.2105\n",
      "Epoch 182/300\n",
      "271/271 [==============================] - 0s 459us/step - loss: 0.0347 - mean_absolute_error: 0.1345 - val_loss: 0.1302 - val_mean_absolute_error: 0.2063\n",
      "Epoch 183/300\n",
      "271/271 [==============================] - 0s 445us/step - loss: 0.0349 - mean_absolute_error: 0.1342 - val_loss: 0.1316 - val_mean_absolute_error: 0.2099\n",
      "Epoch 184/300\n",
      "271/271 [==============================] - 0s 460us/step - loss: 0.0365 - mean_absolute_error: 0.1374 - val_loss: 0.1341 - val_mean_absolute_error: 0.2174\n",
      "Epoch 185/300\n",
      "271/271 [==============================] - 0s 464us/step - loss: 0.0348 - mean_absolute_error: 0.1353 - val_loss: 0.1300 - val_mean_absolute_error: 0.2074\n",
      "Epoch 186/300\n",
      "271/271 [==============================] - 0s 456us/step - loss: 0.0325 - mean_absolute_error: 0.1314 - val_loss: 0.1300 - val_mean_absolute_error: 0.2065\n",
      "Epoch 187/300\n",
      "271/271 [==============================] - 0s 482us/step - loss: 0.0328 - mean_absolute_error: 0.1323 - val_loss: 0.1319 - val_mean_absolute_error: 0.2071\n",
      "Epoch 188/300\n",
      "271/271 [==============================] - 0s 467us/step - loss: 0.0331 - mean_absolute_error: 0.1324 - val_loss: 0.1282 - val_mean_absolute_error: 0.2036\n",
      "Epoch 189/300\n",
      "271/271 [==============================] - 0s 475us/step - loss: 0.0339 - mean_absolute_error: 0.1333 - val_loss: 0.1319 - val_mean_absolute_error: 0.2095\n",
      "Epoch 190/300\n",
      "271/271 [==============================] - 0s 467us/step - loss: 0.0341 - mean_absolute_error: 0.1340 - val_loss: 0.1329 - val_mean_absolute_error: 0.2108\n",
      "Epoch 191/300\n",
      "271/271 [==============================] - 0s 452us/step - loss: 0.0333 - mean_absolute_error: 0.1334 - val_loss: 0.1288 - val_mean_absolute_error: 0.2067\n",
      "Epoch 192/300\n",
      "271/271 [==============================] - 0s 467us/step - loss: 0.0376 - mean_absolute_error: 0.1377 - val_loss: 0.1336 - val_mean_absolute_error: 0.2074\n",
      "Epoch 193/300\n",
      "271/271 [==============================] - 0s 463us/step - loss: 0.0371 - mean_absolute_error: 0.1370 - val_loss: 0.1319 - val_mean_absolute_error: 0.2066\n",
      "Epoch 194/300\n",
      "271/271 [==============================] - 0s 456us/step - loss: 0.0331 - mean_absolute_error: 0.1325 - val_loss: 0.1287 - val_mean_absolute_error: 0.2048\n",
      "Epoch 195/300\n",
      "271/271 [==============================] - 0s 445us/step - loss: 0.0318 - mean_absolute_error: 0.1303 - val_loss: 0.1316 - val_mean_absolute_error: 0.2119\n",
      "Epoch 196/300\n",
      "271/271 [==============================] - 0s 466us/step - loss: 0.0342 - mean_absolute_error: 0.1337 - val_loss: 0.1370 - val_mean_absolute_error: 0.2103\n",
      "Epoch 197/300\n",
      "271/271 [==============================] - 0s 504us/step - loss: 0.0347 - mean_absolute_error: 0.1344 - val_loss: 0.1335 - val_mean_absolute_error: 0.2073\n",
      "Epoch 198/300\n",
      "271/271 [==============================] - 0s 508us/step - loss: 0.0330 - mean_absolute_error: 0.1319 - val_loss: 0.1314 - val_mean_absolute_error: 0.2043\n",
      "Epoch 199/300\n",
      "271/271 [==============================] - 0s 534us/step - loss: 0.0328 - mean_absolute_error: 0.1316 - val_loss: 0.1319 - val_mean_absolute_error: 0.2052\n",
      "Epoch 200/300\n",
      "271/271 [==============================] - 0s 497us/step - loss: 0.0341 - mean_absolute_error: 0.1338 - val_loss: 0.1354 - val_mean_absolute_error: 0.2104\n",
      "Epoch 201/300\n",
      "271/271 [==============================] - 0s 508us/step - loss: 0.0311 - mean_absolute_error: 0.1298 - val_loss: 0.1383 - val_mean_absolute_error: 0.2121\n",
      "Epoch 202/300\n",
      "271/271 [==============================] - 0s 471us/step - loss: 0.0338 - mean_absolute_error: 0.1331 - val_loss: 0.1312 - val_mean_absolute_error: 0.2081\n",
      "Epoch 203/300\n",
      "271/271 [==============================] - 0s 489us/step - loss: 0.0335 - mean_absolute_error: 0.1332 - val_loss: 0.1344 - val_mean_absolute_error: 0.2081\n",
      "Epoch 204/300\n",
      "271/271 [==============================] - 0s 471us/step - loss: 0.0348 - mean_absolute_error: 0.1344 - val_loss: 0.1301 - val_mean_absolute_error: 0.2063\n",
      "Epoch 205/300\n",
      "271/271 [==============================] - 0s 460us/step - loss: 0.0336 - mean_absolute_error: 0.1336 - val_loss: 0.1345 - val_mean_absolute_error: 0.2068\n",
      "Epoch 206/300\n",
      "271/271 [==============================] - 0s 537us/step - loss: 0.0349 - mean_absolute_error: 0.1351 - val_loss: 0.1360 - val_mean_absolute_error: 0.2091\n",
      "Epoch 207/300\n",
      "271/271 [==============================] - 0s 496us/step - loss: 0.0316 - mean_absolute_error: 0.1296 - val_loss: 0.1339 - val_mean_absolute_error: 0.2083\n",
      "Epoch 208/300\n",
      "271/271 [==============================] - 0s 475us/step - loss: 0.0334 - mean_absolute_error: 0.1323 - val_loss: 0.1380 - val_mean_absolute_error: 0.2069\n",
      "Epoch 209/300\n",
      "271/271 [==============================] - 0s 473us/step - loss: 0.0341 - mean_absolute_error: 0.1341 - val_loss: 0.1303 - val_mean_absolute_error: 0.2078\n",
      "Epoch 210/300\n",
      "271/271 [==============================] - 0s 471us/step - loss: 0.0315 - mean_absolute_error: 0.1304 - val_loss: 0.1317 - val_mean_absolute_error: 0.2123\n",
      "Epoch 211/300\n",
      "271/271 [==============================] - 0s 461us/step - loss: 0.0316 - mean_absolute_error: 0.1306 - val_loss: 0.1344 - val_mean_absolute_error: 0.2152\n",
      "Epoch 212/300\n",
      "271/271 [==============================] - 0s 456us/step - loss: 0.0320 - mean_absolute_error: 0.1308 - val_loss: 0.1386 - val_mean_absolute_error: 0.2091\n",
      "Epoch 213/300\n",
      "271/271 [==============================] - 0s 464us/step - loss: 0.0325 - mean_absolute_error: 0.1309 - val_loss: 0.1376 - val_mean_absolute_error: 0.2109\n",
      "Epoch 214/300\n",
      "271/271 [==============================] - 0s 463us/step - loss: 0.0324 - mean_absolute_error: 0.1317 - val_loss: 0.1368 - val_mean_absolute_error: 0.2135\n",
      "Epoch 215/300\n",
      "271/271 [==============================] - 0s 478us/step - loss: 0.0308 - mean_absolute_error: 0.1286 - val_loss: 0.1385 - val_mean_absolute_error: 0.2120\n",
      "Epoch 216/300\n",
      "271/271 [==============================] - 0s 471us/step - loss: 0.0309 - mean_absolute_error: 0.1287 - val_loss: 0.1305 - val_mean_absolute_error: 0.2071\n",
      "Epoch 217/300\n",
      "271/271 [==============================] - 0s 452us/step - loss: 0.0331 - mean_absolute_error: 0.1324 - val_loss: 0.1302 - val_mean_absolute_error: 0.2107\n",
      "Epoch 218/300\n",
      "271/271 [==============================] - 0s 445us/step - loss: 0.0358 - mean_absolute_error: 0.1353 - val_loss: 0.1330 - val_mean_absolute_error: 0.2130\n",
      "Epoch 219/300\n",
      "271/271 [==============================] - 0s 513us/step - loss: 0.0366 - mean_absolute_error: 0.1363 - val_loss: 0.1334 - val_mean_absolute_error: 0.2085\n",
      "Epoch 220/300\n",
      "271/271 [==============================] - 0s 559us/step - loss: 0.0346 - mean_absolute_error: 0.1340 - val_loss: 0.1306 - val_mean_absolute_error: 0.2081\n",
      "Epoch 221/300\n",
      "271/271 [==============================] - 0s 461us/step - loss: 0.0316 - mean_absolute_error: 0.1300 - val_loss: 0.1336 - val_mean_absolute_error: 0.2073\n",
      "Epoch 222/300\n",
      "271/271 [==============================] - 0s 460us/step - loss: 0.0300 - mean_absolute_error: 0.1276 - val_loss: 0.1368 - val_mean_absolute_error: 0.2131\n",
      "Epoch 223/300\n",
      "271/271 [==============================] - 0s 471us/step - loss: 0.0321 - mean_absolute_error: 0.1307 - val_loss: 0.1343 - val_mean_absolute_error: 0.2068\n",
      "Epoch 224/300\n",
      "271/271 [==============================] - 0s 478us/step - loss: 0.0339 - mean_absolute_error: 0.1322 - val_loss: 0.1289 - val_mean_absolute_error: 0.2102\n",
      "Epoch 225/300\n",
      "271/271 [==============================] - 0s 471us/step - loss: 0.0314 - mean_absolute_error: 0.1299 - val_loss: 0.1291 - val_mean_absolute_error: 0.2062\n",
      "Epoch 226/300\n",
      "271/271 [==============================] - 0s 523us/step - loss: 0.0301 - mean_absolute_error: 0.1276 - val_loss: 0.1343 - val_mean_absolute_error: 0.2086\n",
      "Epoch 227/300\n",
      "271/271 [==============================] - 0s 444us/step - loss: 0.0318 - mean_absolute_error: 0.1304 - val_loss: 0.1326 - val_mean_absolute_error: 0.2054\n",
      "Epoch 228/300\n",
      "271/271 [==============================] - 0s 471us/step - loss: 0.0315 - mean_absolute_error: 0.1297 - val_loss: 0.1316 - val_mean_absolute_error: 0.2080\n",
      "Epoch 229/300\n",
      "271/271 [==============================] - 0s 489us/step - loss: 0.0327 - mean_absolute_error: 0.1315 - val_loss: 0.1335 - val_mean_absolute_error: 0.2111\n",
      "Epoch 230/300\n",
      "271/271 [==============================] - 0s 467us/step - loss: 0.0339 - mean_absolute_error: 0.1325 - val_loss: 0.1360 - val_mean_absolute_error: 0.2085\n",
      "Epoch 231/300\n",
      "271/271 [==============================] - 0s 596us/step - loss: 0.0332 - mean_absolute_error: 0.1320 - val_loss: 0.1358 - val_mean_absolute_error: 0.2100\n",
      "Epoch 232/300\n",
      "271/271 [==============================] - 0s 525us/step - loss: 0.0324 - mean_absolute_error: 0.1308 - val_loss: 0.1365 - val_mean_absolute_error: 0.2117\n",
      "Epoch 233/300\n",
      "271/271 [==============================] - 0s 543us/step - loss: 0.0311 - mean_absolute_error: 0.1289 - val_loss: 0.1308 - val_mean_absolute_error: 0.2082\n",
      "Epoch 234/300\n",
      "271/271 [==============================] - 0s 456us/step - loss: 0.0310 - mean_absolute_error: 0.1291 - val_loss: 0.1352 - val_mean_absolute_error: 0.2080\n",
      "Epoch 235/300\n",
      "271/271 [==============================] - 0s 445us/step - loss: 0.0311 - mean_absolute_error: 0.1293 - val_loss: 0.1390 - val_mean_absolute_error: 0.2127\n",
      "Epoch 236/300\n",
      "271/271 [==============================] - 0s 536us/step - loss: 0.0316 - mean_absolute_error: 0.1300 - val_loss: 0.1430 - val_mean_absolute_error: 0.2127\n",
      "Epoch 237/300\n",
      "271/271 [==============================] - 0s 452us/step - loss: 0.0313 - mean_absolute_error: 0.1293 - val_loss: 0.1310 - val_mean_absolute_error: 0.2071\n",
      "Epoch 238/300\n",
      "271/271 [==============================] - 0s 445us/step - loss: 0.0302 - mean_absolute_error: 0.1277 - val_loss: 0.1346 - val_mean_absolute_error: 0.2087\n",
      "Epoch 239/300\n",
      "271/271 [==============================] - 0s 475us/step - loss: 0.0315 - mean_absolute_error: 0.1297 - val_loss: 0.1468 - val_mean_absolute_error: 0.2229\n",
      "Epoch 240/300\n",
      "271/271 [==============================] - 0s 453us/step - loss: 0.0317 - mean_absolute_error: 0.1304 - val_loss: 0.1298 - val_mean_absolute_error: 0.2045\n",
      "Epoch 241/300\n",
      "271/271 [==============================] - 0s 457us/step - loss: 0.0304 - mean_absolute_error: 0.1277 - val_loss: 0.1455 - val_mean_absolute_error: 0.2203\n",
      "Epoch 242/300\n",
      "271/271 [==============================] - 0s 470us/step - loss: 0.0318 - mean_absolute_error: 0.1305 - val_loss: 0.1333 - val_mean_absolute_error: 0.2095\n",
      "Epoch 243/300\n",
      "271/271 [==============================] - 0s 451us/step - loss: 0.0328 - mean_absolute_error: 0.1313 - val_loss: 0.1523 - val_mean_absolute_error: 0.2218\n",
      "Epoch 244/300\n",
      "271/271 [==============================] - 0s 449us/step - loss: 0.0367 - mean_absolute_error: 0.1367 - val_loss: 0.1310 - val_mean_absolute_error: 0.2137\n",
      "Epoch 245/300\n",
      "271/271 [==============================] - 0s 447us/step - loss: 0.0323 - mean_absolute_error: 0.1307 - val_loss: 0.1362 - val_mean_absolute_error: 0.2106\n",
      "Epoch 246/300\n",
      "271/271 [==============================] - 0s 447us/step - loss: 0.0302 - mean_absolute_error: 0.1277 - val_loss: 0.1320 - val_mean_absolute_error: 0.2070\n",
      "Epoch 247/300\n",
      "271/271 [==============================] - 0s 491us/step - loss: 0.0304 - mean_absolute_error: 0.1272 - val_loss: 0.1370 - val_mean_absolute_error: 0.2118\n",
      "Epoch 248/300\n",
      "271/271 [==============================] - 0s 448us/step - loss: 0.0318 - mean_absolute_error: 0.1302 - val_loss: 0.1349 - val_mean_absolute_error: 0.2077\n",
      "Epoch 249/300\n",
      "271/271 [==============================] - 0s 449us/step - loss: 0.0308 - mean_absolute_error: 0.1278 - val_loss: 0.1318 - val_mean_absolute_error: 0.2075\n",
      "Epoch 250/300\n",
      "271/271 [==============================] - 0s 453us/step - loss: 0.0312 - mean_absolute_error: 0.1292 - val_loss: 0.1307 - val_mean_absolute_error: 0.2078\n",
      "Epoch 251/300\n",
      "271/271 [==============================] - 0s 449us/step - loss: 0.0300 - mean_absolute_error: 0.1275 - val_loss: 0.1339 - val_mean_absolute_error: 0.2107\n",
      "Epoch 252/300\n",
      "271/271 [==============================] - 0s 449us/step - loss: 0.0322 - mean_absolute_error: 0.1307 - val_loss: 0.1368 - val_mean_absolute_error: 0.2149\n",
      "Epoch 253/300\n",
      "271/271 [==============================] - 0s 453us/step - loss: 0.0322 - mean_absolute_error: 0.1310 - val_loss: 0.1385 - val_mean_absolute_error: 0.2121\n",
      "Epoch 254/300\n",
      "271/271 [==============================] - 0s 442us/step - loss: 0.0309 - mean_absolute_error: 0.1285 - val_loss: 0.1366 - val_mean_absolute_error: 0.2093\n",
      "Epoch 255/300\n",
      "271/271 [==============================] - 0s 453us/step - loss: 0.0312 - mean_absolute_error: 0.1289 - val_loss: 0.1321 - val_mean_absolute_error: 0.2092\n",
      "Epoch 256/300\n",
      "271/271 [==============================] - 0s 456us/step - loss: 0.0302 - mean_absolute_error: 0.1279 - val_loss: 0.1432 - val_mean_absolute_error: 0.2168\n",
      "Epoch 257/300\n",
      "271/271 [==============================] - 0s 445us/step - loss: 0.0340 - mean_absolute_error: 0.1329 - val_loss: 0.1366 - val_mean_absolute_error: 0.2097\n",
      "Epoch 258/300\n",
      "271/271 [==============================] - 0s 455us/step - loss: 0.0326 - mean_absolute_error: 0.1304 - val_loss: 0.1420 - val_mean_absolute_error: 0.2177\n",
      "Epoch 259/300\n",
      "271/271 [==============================] - 0s 452us/step - loss: 0.0312 - mean_absolute_error: 0.1297 - val_loss: 0.1360 - val_mean_absolute_error: 0.2091\n",
      "Epoch 260/300\n",
      "271/271 [==============================] - 0s 459us/step - loss: 0.0325 - mean_absolute_error: 0.1305 - val_loss: 0.1385 - val_mean_absolute_error: 0.2144\n",
      "Epoch 261/300\n",
      "271/271 [==============================] - 0s 497us/step - loss: 0.0314 - mean_absolute_error: 0.1291 - val_loss: 0.1347 - val_mean_absolute_error: 0.2081\n",
      "Epoch 262/300\n",
      "271/271 [==============================] - 0s 519us/step - loss: 0.0299 - mean_absolute_error: 0.1268 - val_loss: 0.1336 - val_mean_absolute_error: 0.2102\n",
      "Epoch 263/300\n",
      "271/271 [==============================] - 0s 493us/step - loss: 0.0293 - mean_absolute_error: 0.1264 - val_loss: 0.1378 - val_mean_absolute_error: 0.2109\n",
      "Epoch 264/300\n",
      "271/271 [==============================] - 0s 548us/step - loss: 0.0295 - mean_absolute_error: 0.1267 - val_loss: 0.1358 - val_mean_absolute_error: 0.2099\n",
      "Epoch 265/300\n",
      "271/271 [==============================] - 0s 593us/step - loss: 0.0287 - mean_absolute_error: 0.1254 - val_loss: 0.1379 - val_mean_absolute_error: 0.2103\n",
      "Epoch 266/300\n",
      "271/271 [==============================] - 0s 563us/step - loss: 0.0308 - mean_absolute_error: 0.1289 - val_loss: 0.1295 - val_mean_absolute_error: 0.2050\n",
      "Epoch 267/300\n",
      "271/271 [==============================] - 0s 554us/step - loss: 0.0298 - mean_absolute_error: 0.1268 - val_loss: 0.1394 - val_mean_absolute_error: 0.2132\n",
      "Epoch 268/300\n",
      "271/271 [==============================] - 0s 503us/step - loss: 0.0301 - mean_absolute_error: 0.1283 - val_loss: 0.1378 - val_mean_absolute_error: 0.2127\n",
      "Epoch 269/300\n",
      "271/271 [==============================] - 0s 475us/step - loss: 0.0307 - mean_absolute_error: 0.1289 - val_loss: 0.1322 - val_mean_absolute_error: 0.2087\n",
      "Epoch 270/300\n",
      "271/271 [==============================] - 0s 470us/step - loss: 0.0303 - mean_absolute_error: 0.1281 - val_loss: 0.1427 - val_mean_absolute_error: 0.2143\n",
      "Epoch 271/300\n",
      "271/271 [==============================] - 0s 491us/step - loss: 0.0324 - mean_absolute_error: 0.1303 - val_loss: 0.1372 - val_mean_absolute_error: 0.2088\n",
      "Epoch 272/300\n",
      "271/271 [==============================] - 0s 478us/step - loss: 0.0306 - mean_absolute_error: 0.1277 - val_loss: 0.1329 - val_mean_absolute_error: 0.2088\n",
      "Epoch 273/300\n",
      "271/271 [==============================] - 0s 488us/step - loss: 0.0297 - mean_absolute_error: 0.1267 - val_loss: 0.1372 - val_mean_absolute_error: 0.2087\n",
      "Epoch 274/300\n",
      "271/271 [==============================] - 0s 501us/step - loss: 0.0292 - mean_absolute_error: 0.1263 - val_loss: 0.1344 - val_mean_absolute_error: 0.2092\n",
      "Epoch 275/300\n",
      "271/271 [==============================] - 0s 477us/step - loss: 0.0295 - mean_absolute_error: 0.1266 - val_loss: 0.1386 - val_mean_absolute_error: 0.2132\n",
      "Epoch 276/300\n",
      "271/271 [==============================] - 0s 486us/step - loss: 0.0293 - mean_absolute_error: 0.1263 - val_loss: 0.1444 - val_mean_absolute_error: 0.2125\n",
      "Epoch 277/300\n",
      "271/271 [==============================] - 0s 489us/step - loss: 0.0294 - mean_absolute_error: 0.1259 - val_loss: 0.1327 - val_mean_absolute_error: 0.2070\n",
      "Epoch 278/300\n",
      "271/271 [==============================] - 0s 493us/step - loss: 0.0289 - mean_absolute_error: 0.1255 - val_loss: 0.1358 - val_mean_absolute_error: 0.2101\n",
      "Epoch 279/300\n",
      "271/271 [==============================] - 0s 512us/step - loss: 0.0290 - mean_absolute_error: 0.1263 - val_loss: 0.1318 - val_mean_absolute_error: 0.2068\n",
      "Epoch 280/300\n",
      "271/271 [==============================] - 0s 486us/step - loss: 0.0303 - mean_absolute_error: 0.1275 - val_loss: 0.1371 - val_mean_absolute_error: 0.2097\n",
      "Epoch 281/300\n",
      "271/271 [==============================] - 0s 453us/step - loss: 0.0301 - mean_absolute_error: 0.1275 - val_loss: 0.1403 - val_mean_absolute_error: 0.2116\n",
      "Epoch 282/300\n",
      "271/271 [==============================] - 0s 451us/step - loss: 0.0328 - mean_absolute_error: 0.1300 - val_loss: 0.1494 - val_mean_absolute_error: 0.2388\n",
      "Epoch 283/300\n",
      "271/271 [==============================] - 0s 456us/step - loss: 0.0345 - mean_absolute_error: 0.1340 - val_loss: 0.1435 - val_mean_absolute_error: 0.2102\n",
      "Epoch 284/300\n",
      "271/271 [==============================] - 0s 470us/step - loss: 0.0297 - mean_absolute_error: 0.1267 - val_loss: 0.1366 - val_mean_absolute_error: 0.2104\n",
      "Epoch 285/300\n",
      "271/271 [==============================] - 0s 456us/step - loss: 0.0294 - mean_absolute_error: 0.1263 - val_loss: 0.1453 - val_mean_absolute_error: 0.2148\n",
      "Epoch 286/300\n",
      "271/271 [==============================] - 0s 524us/step - loss: 0.0288 - mean_absolute_error: 0.1253 - val_loss: 0.1373 - val_mean_absolute_error: 0.2156\n",
      "Epoch 287/300\n",
      "271/271 [==============================] - 0s 519us/step - loss: 0.0292 - mean_absolute_error: 0.1256 - val_loss: 0.1348 - val_mean_absolute_error: 0.2088\n",
      "Epoch 288/300\n",
      "271/271 [==============================] - 0s 515us/step - loss: 0.0286 - mean_absolute_error: 0.1246 - val_loss: 0.1380 - val_mean_absolute_error: 0.2107\n",
      "Epoch 289/300\n",
      "271/271 [==============================] - 0s 467us/step - loss: 0.0304 - mean_absolute_error: 0.1267 - val_loss: 0.1332 - val_mean_absolute_error: 0.2097\n",
      "Epoch 290/300\n",
      "271/271 [==============================] - 0s 489us/step - loss: 0.0281 - mean_absolute_error: 0.1233 - val_loss: 0.1353 - val_mean_absolute_error: 0.2091\n",
      "Epoch 291/300\n",
      "271/271 [==============================] - 0s 497us/step - loss: 0.0291 - mean_absolute_error: 0.1259 - val_loss: 0.1374 - val_mean_absolute_error: 0.2098\n",
      "Epoch 292/300\n",
      "271/271 [==============================] - 0s 501us/step - loss: 0.0294 - mean_absolute_error: 0.1264 - val_loss: 0.1373 - val_mean_absolute_error: 0.2110\n",
      "Epoch 293/300\n",
      "271/271 [==============================] - 0s 477us/step - loss: 0.0296 - mean_absolute_error: 0.1262 - val_loss: 0.1441 - val_mean_absolute_error: 0.2152\n",
      "Epoch 294/300\n",
      "271/271 [==============================] - 0s 621us/step - loss: 0.0305 - mean_absolute_error: 0.1281 - val_loss: 0.1372 - val_mean_absolute_error: 0.2096\n",
      "Epoch 295/300\n",
      "271/271 [==============================] - 0s 536us/step - loss: 0.0311 - mean_absolute_error: 0.1288 - val_loss: 0.1368 - val_mean_absolute_error: 0.2097\n",
      "Epoch 296/300\n",
      "271/271 [==============================] - 0s 549us/step - loss: 0.0290 - mean_absolute_error: 0.1256 - val_loss: 0.1323 - val_mean_absolute_error: 0.2076\n",
      "Epoch 297/300\n",
      "271/271 [==============================] - 0s 635us/step - loss: 0.0299 - mean_absolute_error: 0.1268 - val_loss: 0.1350 - val_mean_absolute_error: 0.2110\n",
      "Epoch 298/300\n",
      "271/271 [==============================] - 0s 486us/step - loss: 0.0280 - mean_absolute_error: 0.1234 - val_loss: 0.1364 - val_mean_absolute_error: 0.2107\n",
      "Epoch 299/300\n",
      "271/271 [==============================] - 0s 445us/step - loss: 0.0274 - mean_absolute_error: 0.1227 - val_loss: 0.1376 - val_mean_absolute_error: 0.2125\n",
      "Epoch 300/300\n",
      "271/271 [==============================] - 0s 486us/step - loss: 0.0276 - mean_absolute_error: 0.1234 - val_loss: 0.1377 - val_mean_absolute_error: 0.2106\n"
     ]
    }
   ],
   "source": [
    "# 訓練網路模型：\n",
    "history = model.fit(x_train, y_train,  # 傳入訓練數據\n",
    "               batch_size=64,  # 批次大小設為64\n",
    "               epochs=300,  # 整個dataset訓練300遍\n",
    "               validation_data=(x_val, y_val),  # 驗證數據\n",
    "               callbacks=[model_cbk, model_mckp]) \n",
    " # Tensorboard回調函數紀錄訓練過程，ModelCheckpoint回調函數儲存最好的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6229656",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'mean_absolute_error', 'val_loss', 'val_mean_absolute_error'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()  # 查看history儲存的資訊有哪些"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "66f55926",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1ce49456988>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='validation')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "713071e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1ce4b575848>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['mean_absolute_error'], label='train')\n",
    "plt.plot(history.history['val_mean_absolute_error'], label='validation')\n",
    "plt.ylim(0.12, 0.26)\n",
    "plt.title('Mean absolute error')\n",
    "plt.ylabel('metrics')\n",
    "plt.xlabel('epochs')\n",
    "plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f7ca4e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_1 Percentage Error: 13.17%\n"
     ]
    }
   ],
   "source": [
    "# 載入模型\n",
    "model = keras.models.load_model('lab2-logs/models/Best-model-1.h5')\n",
    "# 先將房屋價格取出\n",
    "y_test = np.array(test_data['price'])\n",
    "# 標準化數據\n",
    "test_data = (test_data - mean) / std\n",
    "# 將輸入數據存成Numpy 格式\n",
    "x_test = np.array(test_data.drop('price', axis='columns'))\n",
    "# 預測測試數據\n",
    "y_pred = model.predict(x_test)\n",
    "# 將預測結果轉換回來(因為訓練時的訓練目標也有經過標準化)\n",
    "y_pred = np.reshape(y_pred * std['price'] + mean['price'], y_test.shape)\n",
    "# 計算平均的誤差百分比\n",
    "percentage_error = np.mean(np.abs(y_test - y_pred)) / np.mean(y_test) * 100\n",
    "# 顯示誤差百分比\n",
    "print(\"Model_1 Percentage Error: {:.2f}%\".format(percentage_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a6d7361d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "  1/271 [..............................] - ETA: 0s - loss: 0.9343 - mean_absolute_error: 0.6997WARNING:tensorflow:Callbacks method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_begin` time: 0.0010s). Check your callbacks.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0251s). Check your callbacks.\n",
      "271/271 [==============================] - 0s 764us/step - loss: 0.5019 - mean_absolute_error: 0.4405 - val_loss: 0.3056 - val_mean_absolute_error: 0.3363\n",
      "Epoch 2/300\n",
      "271/271 [==============================] - 0s 460us/step - loss: 0.2774 - mean_absolute_error: 0.3256 - val_loss: 0.2563 - val_mean_absolute_error: 0.3067\n",
      "Epoch 3/300\n",
      "271/271 [==============================] - 0s 460us/step - loss: 0.2317 - mean_absolute_error: 0.2989 - val_loss: 0.2191 - val_mean_absolute_error: 0.2820\n",
      "Epoch 4/300\n",
      "271/271 [==============================] - 0s 463us/step - loss: 0.2059 - mean_absolute_error: 0.2821 - val_loss: 0.2011 - val_mean_absolute_error: 0.2703\n",
      "Epoch 5/300\n",
      "271/271 [==============================] - 0s 431us/step - loss: 0.1912 - mean_absolute_error: 0.2704 - val_loss: 0.1868 - val_mean_absolute_error: 0.2593\n",
      "Epoch 6/300\n",
      "271/271 [==============================] - 0s 458us/step - loss: 0.1791 - mean_absolute_error: 0.2619 - val_loss: 0.1852 - val_mean_absolute_error: 0.2549\n",
      "Epoch 7/300\n",
      "271/271 [==============================] - 0s 475us/step - loss: 0.1681 - mean_absolute_error: 0.2519 - val_loss: 0.1743 - val_mean_absolute_error: 0.2447\n",
      "Epoch 8/300\n",
      "271/271 [==============================] - 0s 480us/step - loss: 0.1570 - mean_absolute_error: 0.2435 - val_loss: 0.1730 - val_mean_absolute_error: 0.2424\n",
      "Epoch 9/300\n",
      "271/271 [==============================] - 0s 464us/step - loss: 0.1508 - mean_absolute_error: 0.2378 - val_loss: 0.1621 - val_mean_absolute_error: 0.2327\n",
      "Epoch 10/300\n",
      "271/271 [==============================] - 0s 456us/step - loss: 0.1441 - mean_absolute_error: 0.2328 - val_loss: 0.1525 - val_mean_absolute_error: 0.2300\n",
      "Epoch 11/300\n",
      "271/271 [==============================] - 0s 454us/step - loss: 0.1384 - mean_absolute_error: 0.2275 - val_loss: 0.1453 - val_mean_absolute_error: 0.2250\n",
      "Epoch 12/300\n",
      "271/271 [==============================] - 0s 457us/step - loss: 0.1362 - mean_absolute_error: 0.2268 - val_loss: 0.1434 - val_mean_absolute_error: 0.2226\n",
      "Epoch 13/300\n",
      "271/271 [==============================] - 0s 430us/step - loss: 0.1292 - mean_absolute_error: 0.2208 - val_loss: 0.1412 - val_mean_absolute_error: 0.2228\n",
      "Epoch 14/300\n",
      "271/271 [==============================] - 0s 467us/step - loss: 0.1281 - mean_absolute_error: 0.2197 - val_loss: 0.1402 - val_mean_absolute_error: 0.2198\n",
      "Epoch 15/300\n",
      "271/271 [==============================] - ETA: 0s - loss: 0.1209 - mean_absolute_error: 0.214 - 0s 416us/step - loss: 0.1258 - mean_absolute_error: 0.2176 - val_loss: 0.1375 - val_mean_absolute_error: 0.2252\n",
      "Epoch 16/300\n",
      "271/271 [==============================] - 0s 453us/step - loss: 0.1223 - mean_absolute_error: 0.2148 - val_loss: 0.1375 - val_mean_absolute_error: 0.2168\n",
      "Epoch 17/300\n",
      "271/271 [==============================] - 0s 439us/step - loss: 0.1211 - mean_absolute_error: 0.2147 - val_loss: 0.1342 - val_mean_absolute_error: 0.2146\n",
      "Epoch 18/300\n",
      "271/271 [==============================] - 0s 409us/step - loss: 0.1182 - mean_absolute_error: 0.2122 - val_loss: 0.1333 - val_mean_absolute_error: 0.2209\n",
      "Epoch 19/300\n",
      "271/271 [==============================] - 0s 426us/step - loss: 0.1174 - mean_absolute_error: 0.2109 - val_loss: 0.1320 - val_mean_absolute_error: 0.2176\n",
      "Epoch 20/300\n",
      "271/271 [==============================] - 0s 427us/step - loss: 0.1160 - mean_absolute_error: 0.2110 - val_loss: 0.1312 - val_mean_absolute_error: 0.2188\n",
      "Epoch 21/300\n",
      "271/271 [==============================] - 0s 421us/step - loss: 0.1138 - mean_absolute_error: 0.2085 - val_loss: 0.1296 - val_mean_absolute_error: 0.2164\n",
      "Epoch 22/300\n",
      "271/271 [==============================] - 0s 487us/step - loss: 0.1131 - mean_absolute_error: 0.2084 - val_loss: 0.1306 - val_mean_absolute_error: 0.2132\n",
      "Epoch 23/300\n",
      "271/271 [==============================] - 0s 404us/step - loss: 0.1120 - mean_absolute_error: 0.2069 - val_loss: 0.1297 - val_mean_absolute_error: 0.2148\n",
      "Epoch 24/300\n",
      "271/271 [==============================] - 0s 408us/step - loss: 0.1102 - mean_absolute_error: 0.2053 - val_loss: 0.1290 - val_mean_absolute_error: 0.2133\n",
      "Epoch 25/300\n",
      "271/271 [==============================] - 0s 416us/step - loss: 0.1097 - mean_absolute_error: 0.2048 - val_loss: 0.1302 - val_mean_absolute_error: 0.2161\n",
      "Epoch 26/300\n",
      "271/271 [==============================] - 0s 447us/step - loss: 0.1089 - mean_absolute_error: 0.2044 - val_loss: 0.1242 - val_mean_absolute_error: 0.2070\n",
      "Epoch 27/300\n",
      "271/271 [==============================] - 0s 412us/step - loss: 0.1082 - mean_absolute_error: 0.2041 - val_loss: 0.1288 - val_mean_absolute_error: 0.2102\n",
      "Epoch 28/300\n",
      "271/271 [==============================] - 0s 456us/step - loss: 0.1058 - mean_absolute_error: 0.2017 - val_loss: 0.1260 - val_mean_absolute_error: 0.2058\n",
      "Epoch 29/300\n",
      "271/271 [==============================] - 0s 434us/step - loss: 0.1059 - mean_absolute_error: 0.2031 - val_loss: 0.1237 - val_mean_absolute_error: 0.2085\n",
      "Epoch 30/300\n",
      "271/271 [==============================] - 0s 460us/step - loss: 0.1048 - mean_absolute_error: 0.2017 - val_loss: 0.1260 - val_mean_absolute_error: 0.2088\n",
      "Epoch 31/300\n",
      "271/271 [==============================] - 0s 449us/step - loss: 0.1049 - mean_absolute_error: 0.2015 - val_loss: 0.1238 - val_mean_absolute_error: 0.2048\n",
      "Epoch 32/300\n",
      "271/271 [==============================] - 0s 406us/step - loss: 0.1033 - mean_absolute_error: 0.2005 - val_loss: 0.1269 - val_mean_absolute_error: 0.2059\n",
      "Epoch 33/300\n",
      "271/271 [==============================] - 0s 397us/step - loss: 0.1030 - mean_absolute_error: 0.1998 - val_loss: 0.1236 - val_mean_absolute_error: 0.2050\n",
      "Epoch 34/300\n",
      "271/271 [==============================] - 0s 408us/step - loss: 0.1017 - mean_absolute_error: 0.1989 - val_loss: 0.1219 - val_mean_absolute_error: 0.2076\n",
      "Epoch 35/300\n",
      "271/271 [==============================] - 0s 434us/step - loss: 0.1015 - mean_absolute_error: 0.1986 - val_loss: 0.1209 - val_mean_absolute_error: 0.2037\n",
      "Epoch 36/300\n",
      "271/271 [==============================] - 0s 463us/step - loss: 0.1020 - mean_absolute_error: 0.1986 - val_loss: 0.1192 - val_mean_absolute_error: 0.2033\n",
      "Epoch 37/300\n",
      "271/271 [==============================] - 0s 428us/step - loss: 0.0988 - mean_absolute_error: 0.1968 - val_loss: 0.1235 - val_mean_absolute_error: 0.2111\n",
      "Epoch 38/300\n",
      "271/271 [==============================] - 0s 434us/step - loss: 0.0997 - mean_absolute_error: 0.1975 - val_loss: 0.1168 - val_mean_absolute_error: 0.2003\n",
      "Epoch 39/300\n",
      "271/271 [==============================] - 0s 425us/step - loss: 0.0982 - mean_absolute_error: 0.1960 - val_loss: 0.1188 - val_mean_absolute_error: 0.2069\n",
      "Epoch 40/300\n",
      "271/271 [==============================] - 0s 419us/step - loss: 0.0990 - mean_absolute_error: 0.1968 - val_loss: 0.1170 - val_mean_absolute_error: 0.2019\n",
      "Epoch 41/300\n",
      "271/271 [==============================] - 0s 542us/step - loss: 0.0974 - mean_absolute_error: 0.1949 - val_loss: 0.1207 - val_mean_absolute_error: 0.2020\n",
      "Epoch 42/300\n",
      "271/271 [==============================] - 0s 422us/step - loss: 0.0990 - mean_absolute_error: 0.1962 - val_loss: 0.1161 - val_mean_absolute_error: 0.2023\n",
      "Epoch 43/300\n",
      "271/271 [==============================] - 0s 416us/step - loss: 0.0968 - mean_absolute_error: 0.1955 - val_loss: 0.1207 - val_mean_absolute_error: 0.2116\n",
      "Epoch 44/300\n",
      "271/271 [==============================] - 0s 394us/step - loss: 0.0967 - mean_absolute_error: 0.1945 - val_loss: 0.1184 - val_mean_absolute_error: 0.2046\n",
      "Epoch 45/300\n",
      "271/271 [==============================] - 0s 434us/step - loss: 0.0939 - mean_absolute_error: 0.1929 - val_loss: 0.1129 - val_mean_absolute_error: 0.1978\n",
      "Epoch 46/300\n",
      "271/271 [==============================] - 0s 396us/step - loss: 0.0952 - mean_absolute_error: 0.1932 - val_loss: 0.1166 - val_mean_absolute_error: 0.1995\n",
      "Epoch 47/300\n",
      "271/271 [==============================] - 0s 390us/step - loss: 0.0944 - mean_absolute_error: 0.1925 - val_loss: 0.1165 - val_mean_absolute_error: 0.2053\n",
      "Epoch 48/300\n",
      "271/271 [==============================] - 0s 429us/step - loss: 0.0944 - mean_absolute_error: 0.1926 - val_loss: 0.1122 - val_mean_absolute_error: 0.1968\n",
      "Epoch 49/300\n",
      "271/271 [==============================] - 0s 409us/step - loss: 0.0938 - mean_absolute_error: 0.1924 - val_loss: 0.1145 - val_mean_absolute_error: 0.2014\n",
      "Epoch 50/300\n",
      "271/271 [==============================] - 0s 411us/step - loss: 0.0953 - mean_absolute_error: 0.1946 - val_loss: 0.1148 - val_mean_absolute_error: 0.2001\n",
      "Epoch 51/300\n",
      "271/271 [==============================] - 0s 407us/step - loss: 0.0928 - mean_absolute_error: 0.1928 - val_loss: 0.1154 - val_mean_absolute_error: 0.2084\n",
      "Epoch 52/300\n",
      "271/271 [==============================] - 0s 422us/step - loss: 0.0926 - mean_absolute_error: 0.1918 - val_loss: 0.1185 - val_mean_absolute_error: 0.2055\n",
      "Epoch 53/300\n",
      "271/271 [==============================] - 0s 394us/step - loss: 0.0921 - mean_absolute_error: 0.1910 - val_loss: 0.1175 - val_mean_absolute_error: 0.2079\n",
      "Epoch 54/300\n",
      "271/271 [==============================] - 0s 391us/step - loss: 0.0923 - mean_absolute_error: 0.1912 - val_loss: 0.1169 - val_mean_absolute_error: 0.2020\n",
      "Epoch 55/300\n",
      "271/271 [==============================] - 0s 390us/step - loss: 0.0916 - mean_absolute_error: 0.1915 - val_loss: 0.1118 - val_mean_absolute_error: 0.2034\n",
      "Epoch 56/300\n",
      "271/271 [==============================] - 0s 403us/step - loss: 0.0917 - mean_absolute_error: 0.1920 - val_loss: 0.1166 - val_mean_absolute_error: 0.2062\n",
      "Epoch 57/300\n",
      "271/271 [==============================] - 0s 397us/step - loss: 0.0909 - mean_absolute_error: 0.1906 - val_loss: 0.1100 - val_mean_absolute_error: 0.1990\n",
      "Epoch 58/300\n",
      "271/271 [==============================] - 0s 394us/step - loss: 0.0906 - mean_absolute_error: 0.1909 - val_loss: 0.1126 - val_mean_absolute_error: 0.1975\n",
      "Epoch 59/300\n",
      "271/271 [==============================] - 0s 394us/step - loss: 0.0902 - mean_absolute_error: 0.1902 - val_loss: 0.1123 - val_mean_absolute_error: 0.2010\n",
      "Epoch 60/300\n",
      "271/271 [==============================] - 0s 412us/step - loss: 0.0887 - mean_absolute_error: 0.1897 - val_loss: 0.1114 - val_mean_absolute_error: 0.2022\n",
      "Epoch 61/300\n",
      "271/271 [==============================] - 0s 416us/step - loss: 0.0895 - mean_absolute_error: 0.1892 - val_loss: 0.1115 - val_mean_absolute_error: 0.1986\n",
      "Epoch 62/300\n",
      "271/271 [==============================] - 0s 398us/step - loss: 0.0885 - mean_absolute_error: 0.1898 - val_loss: 0.1107 - val_mean_absolute_error: 0.1994\n",
      "Epoch 63/300\n",
      "271/271 [==============================] - 0s 400us/step - loss: 0.0893 - mean_absolute_error: 0.1901 - val_loss: 0.1175 - val_mean_absolute_error: 0.2072\n",
      "Epoch 64/300\n",
      "271/271 [==============================] - 0s 392us/step - loss: 0.0885 - mean_absolute_error: 0.1885 - val_loss: 0.1158 - val_mean_absolute_error: 0.2040\n",
      "Epoch 65/300\n",
      "271/271 [==============================] - 0s 416us/step - loss: 0.0880 - mean_absolute_error: 0.1887 - val_loss: 0.1135 - val_mean_absolute_error: 0.2007\n",
      "Epoch 66/300\n",
      "271/271 [==============================] - 0s 456us/step - loss: 0.0885 - mean_absolute_error: 0.1897 - val_loss: 0.1110 - val_mean_absolute_error: 0.1965\n",
      "Epoch 67/300\n",
      "271/271 [==============================] - 0s 403us/step - loss: 0.0890 - mean_absolute_error: 0.1888 - val_loss: 0.1137 - val_mean_absolute_error: 0.1969\n",
      "Epoch 68/300\n",
      "271/271 [==============================] - 0s 392us/step - loss: 0.0880 - mean_absolute_error: 0.1879 - val_loss: 0.1140 - val_mean_absolute_error: 0.2011\n",
      "Epoch 69/300\n",
      "271/271 [==============================] - 0s 416us/step - loss: 0.0866 - mean_absolute_error: 0.1885 - val_loss: 0.1119 - val_mean_absolute_error: 0.2070\n",
      "Epoch 70/300\n",
      "271/271 [==============================] - 0s 415us/step - loss: 0.0874 - mean_absolute_error: 0.1885 - val_loss: 0.1116 - val_mean_absolute_error: 0.2044\n",
      "Epoch 71/300\n",
      "271/271 [==============================] - 0s 396us/step - loss: 0.0868 - mean_absolute_error: 0.1878 - val_loss: 0.1126 - val_mean_absolute_error: 0.1968\n",
      "Epoch 72/300\n",
      "271/271 [==============================] - 0s 399us/step - loss: 0.0869 - mean_absolute_error: 0.1875 - val_loss: 0.1129 - val_mean_absolute_error: 0.2001\n",
      "Epoch 73/300\n",
      "271/271 [==============================] - 0s 393us/step - loss: 0.0869 - mean_absolute_error: 0.1877 - val_loss: 0.1124 - val_mean_absolute_error: 0.2007\n",
      "Epoch 74/300\n",
      "271/271 [==============================] - 0s 408us/step - loss: 0.0859 - mean_absolute_error: 0.1874 - val_loss: 0.1110 - val_mean_absolute_error: 0.1971\n",
      "Epoch 75/300\n",
      "271/271 [==============================] - 0s 412us/step - loss: 0.0859 - mean_absolute_error: 0.1866 - val_loss: 0.1102 - val_mean_absolute_error: 0.1968\n",
      "Epoch 76/300\n",
      "271/271 [==============================] - 0s 445us/step - loss: 0.0862 - mean_absolute_error: 0.1876 - val_loss: 0.1094 - val_mean_absolute_error: 0.1931\n",
      "Epoch 77/300\n",
      "271/271 [==============================] - 0s 400us/step - loss: 0.0862 - mean_absolute_error: 0.1876 - val_loss: 0.1069 - val_mean_absolute_error: 0.1972\n",
      "Epoch 78/300\n",
      "271/271 [==============================] - 0s 394us/step - loss: 0.0846 - mean_absolute_error: 0.1864 - val_loss: 0.1124 - val_mean_absolute_error: 0.1958\n",
      "Epoch 79/300\n",
      "271/271 [==============================] - 0s 400us/step - loss: 0.0851 - mean_absolute_error: 0.1859 - val_loss: 0.1152 - val_mean_absolute_error: 0.2074\n",
      "Epoch 80/300\n",
      "271/271 [==============================] - 0s 394us/step - loss: 0.0856 - mean_absolute_error: 0.1865 - val_loss: 0.1147 - val_mean_absolute_error: 0.1993\n",
      "Epoch 81/300\n",
      "271/271 [==============================] - 0s 402us/step - loss: 0.0847 - mean_absolute_error: 0.1865 - val_loss: 0.1116 - val_mean_absolute_error: 0.1982\n",
      "Epoch 82/300\n",
      "271/271 [==============================] - 0s 397us/step - loss: 0.0859 - mean_absolute_error: 0.1875 - val_loss: 0.1133 - val_mean_absolute_error: 0.1988\n",
      "Epoch 83/300\n",
      "271/271 [==============================] - 0s 397us/step - loss: 0.0842 - mean_absolute_error: 0.1849 - val_loss: 0.1103 - val_mean_absolute_error: 0.1972\n",
      "Epoch 84/300\n",
      "271/271 [==============================] - 0s 405us/step - loss: 0.0847 - mean_absolute_error: 0.1861 - val_loss: 0.1182 - val_mean_absolute_error: 0.1981\n",
      "Epoch 85/300\n",
      "271/271 [==============================] - 0s 412us/step - loss: 0.0842 - mean_absolute_error: 0.1854 - val_loss: 0.1132 - val_mean_absolute_error: 0.1981\n",
      "Epoch 86/300\n",
      "271/271 [==============================] - 0s 409us/step - loss: 0.0845 - mean_absolute_error: 0.1865 - val_loss: 0.1096 - val_mean_absolute_error: 0.1966\n",
      "Epoch 87/300\n",
      "271/271 [==============================] - 0s 398us/step - loss: 0.0836 - mean_absolute_error: 0.1854 - val_loss: 0.1107 - val_mean_absolute_error: 0.2001\n",
      "Epoch 88/300\n",
      "271/271 [==============================] - 0s 400us/step - loss: 0.0836 - mean_absolute_error: 0.1858 - val_loss: 0.1188 - val_mean_absolute_error: 0.2042\n",
      "Epoch 89/300\n",
      "271/271 [==============================] - 0s 400us/step - loss: 0.0846 - mean_absolute_error: 0.1857 - val_loss: 0.1114 - val_mean_absolute_error: 0.1962\n",
      "Epoch 90/300\n",
      "271/271 [==============================] - 0s 408us/step - loss: 0.0832 - mean_absolute_error: 0.1846 - val_loss: 0.1114 - val_mean_absolute_error: 0.1948\n",
      "Epoch 91/300\n",
      "271/271 [==============================] - 0s 420us/step - loss: 0.0841 - mean_absolute_error: 0.1862 - val_loss: 0.1097 - val_mean_absolute_error: 0.1965\n",
      "Epoch 92/300\n",
      "271/271 [==============================] - 0s 405us/step - loss: 0.0828 - mean_absolute_error: 0.1848 - val_loss: 0.1110 - val_mean_absolute_error: 0.2066\n",
      "Epoch 93/300\n",
      "271/271 [==============================] - 0s 401us/step - loss: 0.0823 - mean_absolute_error: 0.1838 - val_loss: 0.1131 - val_mean_absolute_error: 0.1966\n",
      "Epoch 94/300\n",
      "271/271 [==============================] - 0s 390us/step - loss: 0.0834 - mean_absolute_error: 0.1845 - val_loss: 0.1075 - val_mean_absolute_error: 0.1988\n",
      "Epoch 95/300\n",
      "271/271 [==============================] - 0s 401us/step - loss: 0.0809 - mean_absolute_error: 0.1831 - val_loss: 0.1161 - val_mean_absolute_error: 0.1973\n",
      "Epoch 96/300\n",
      "271/271 [==============================] - 0s 390us/step - loss: 0.0810 - mean_absolute_error: 0.1828 - val_loss: 0.1127 - val_mean_absolute_error: 0.1980\n",
      "Epoch 97/300\n",
      "271/271 [==============================] - 0s 438us/step - loss: 0.0821 - mean_absolute_error: 0.1840 - val_loss: 0.1140 - val_mean_absolute_error: 0.1931\n",
      "Epoch 98/300\n",
      "271/271 [==============================] - 0s 409us/step - loss: 0.0823 - mean_absolute_error: 0.1847 - val_loss: 0.1086 - val_mean_absolute_error: 0.1964\n",
      "Epoch 99/300\n",
      "271/271 [==============================] - 0s 405us/step - loss: 0.0818 - mean_absolute_error: 0.1844 - val_loss: 0.1048 - val_mean_absolute_error: 0.1934\n",
      "Epoch 100/300\n",
      "271/271 [==============================] - 0s 412us/step - loss: 0.0819 - mean_absolute_error: 0.1840 - val_loss: 0.1103 - val_mean_absolute_error: 0.1972\n",
      "Epoch 101/300\n",
      "271/271 [==============================] - 0s 418us/step - loss: 0.0807 - mean_absolute_error: 0.1824 - val_loss: 0.1070 - val_mean_absolute_error: 0.1934\n",
      "Epoch 102/300\n",
      "271/271 [==============================] - 0s 453us/step - loss: 0.0810 - mean_absolute_error: 0.1831 - val_loss: 0.1093 - val_mean_absolute_error: 0.1921\n",
      "Epoch 103/300\n",
      "271/271 [==============================] - 0s 409us/step - loss: 0.0810 - mean_absolute_error: 0.1836 - val_loss: 0.1048 - val_mean_absolute_error: 0.1956\n",
      "Epoch 104/300\n",
      "271/271 [==============================] - 0s 420us/step - loss: 0.0809 - mean_absolute_error: 0.1834 - val_loss: 0.1061 - val_mean_absolute_error: 0.1938\n",
      "Epoch 105/300\n",
      "271/271 [==============================] - 0s 434us/step - loss: 0.0811 - mean_absolute_error: 0.1832 - val_loss: 0.1052 - val_mean_absolute_error: 0.1924\n",
      "Epoch 106/300\n",
      "271/271 [==============================] - 0s 397us/step - loss: 0.0820 - mean_absolute_error: 0.1841 - val_loss: 0.1098 - val_mean_absolute_error: 0.1998\n",
      "Epoch 107/300\n",
      "271/271 [==============================] - 0s 390us/step - loss: 0.0790 - mean_absolute_error: 0.1830 - val_loss: 0.1113 - val_mean_absolute_error: 0.1956\n",
      "Epoch 108/300\n",
      "271/271 [==============================] - 0s 416us/step - loss: 0.0811 - mean_absolute_error: 0.1832 - val_loss: 0.1100 - val_mean_absolute_error: 0.1973\n",
      "Epoch 109/300\n",
      "271/271 [==============================] - 0s 431us/step - loss: 0.0804 - mean_absolute_error: 0.1829 - val_loss: 0.1054 - val_mean_absolute_error: 0.1925\n",
      "Epoch 110/300\n",
      "271/271 [==============================] - 0s 409us/step - loss: 0.0809 - mean_absolute_error: 0.1839 - val_loss: 0.1087 - val_mean_absolute_error: 0.1950\n",
      "Epoch 111/300\n",
      "271/271 [==============================] - 0s 412us/step - loss: 0.0799 - mean_absolute_error: 0.1826 - val_loss: 0.1079 - val_mean_absolute_error: 0.1953\n",
      "Epoch 112/300\n",
      "271/271 [==============================] - 0s 409us/step - loss: 0.0817 - mean_absolute_error: 0.1839 - val_loss: 0.1113 - val_mean_absolute_error: 0.1956\n",
      "Epoch 113/300\n",
      "271/271 [==============================] - 0s 420us/step - loss: 0.0792 - mean_absolute_error: 0.1815 - val_loss: 0.1062 - val_mean_absolute_error: 0.1942\n",
      "Epoch 114/300\n",
      "271/271 [==============================] - 0s 402us/step - loss: 0.0797 - mean_absolute_error: 0.1825 - val_loss: 0.1142 - val_mean_absolute_error: 0.2045\n",
      "Epoch 115/300\n",
      "271/271 [==============================] - 0s 391us/step - loss: 0.0799 - mean_absolute_error: 0.1825 - val_loss: 0.1106 - val_mean_absolute_error: 0.1953\n",
      "Epoch 116/300\n",
      "271/271 [==============================] - 0s 388us/step - loss: 0.0803 - mean_absolute_error: 0.1831 - val_loss: 0.1071 - val_mean_absolute_error: 0.1934\n",
      "Epoch 117/300\n",
      "271/271 [==============================] - 0s 389us/step - loss: 0.0804 - mean_absolute_error: 0.1826 - val_loss: 0.1085 - val_mean_absolute_error: 0.1938\n",
      "Epoch 118/300\n",
      "271/271 [==============================] - 0s 393us/step - loss: 0.0790 - mean_absolute_error: 0.1818 - val_loss: 0.1080 - val_mean_absolute_error: 0.1930\n",
      "Epoch 119/300\n",
      "271/271 [==============================] - 0s 433us/step - loss: 0.0804 - mean_absolute_error: 0.1828 - val_loss: 0.1043 - val_mean_absolute_error: 0.1912\n",
      "Epoch 120/300\n",
      "271/271 [==============================] - 0s 431us/step - loss: 0.0795 - mean_absolute_error: 0.1825 - val_loss: 0.1056 - val_mean_absolute_error: 0.1912\n",
      "Epoch 121/300\n",
      "271/271 [==============================] - 0s 432us/step - loss: 0.0817 - mean_absolute_error: 0.1840 - val_loss: 0.1073 - val_mean_absolute_error: 0.1892\n",
      "Epoch 122/300\n",
      "271/271 [==============================] - 0s 392us/step - loss: 0.0795 - mean_absolute_error: 0.1817 - val_loss: 0.1059 - val_mean_absolute_error: 0.1902\n",
      "Epoch 123/300\n",
      "271/271 [==============================] - 0s 390us/step - loss: 0.0794 - mean_absolute_error: 0.1820 - val_loss: 0.1149 - val_mean_absolute_error: 0.1987\n",
      "Epoch 124/300\n",
      "271/271 [==============================] - 0s 390us/step - loss: 0.0790 - mean_absolute_error: 0.1814 - val_loss: 0.1089 - val_mean_absolute_error: 0.1914\n",
      "Epoch 125/300\n",
      "271/271 [==============================] - 0s 390us/step - loss: 0.0783 - mean_absolute_error: 0.1813 - val_loss: 0.1132 - val_mean_absolute_error: 0.1962\n",
      "Epoch 126/300\n",
      "271/271 [==============================] - 0s 387us/step - loss: 0.0809 - mean_absolute_error: 0.1840 - val_loss: 0.1117 - val_mean_absolute_error: 0.2033\n",
      "Epoch 127/300\n",
      "271/271 [==============================] - 0s 398us/step - loss: 0.0788 - mean_absolute_error: 0.1818 - val_loss: 0.1074 - val_mean_absolute_error: 0.1951\n",
      "Epoch 128/300\n",
      "271/271 [==============================] - 0s 417us/step - loss: 0.0797 - mean_absolute_error: 0.1822 - val_loss: 0.1063 - val_mean_absolute_error: 0.1923\n",
      "Epoch 129/300\n",
      "271/271 [==============================] - 0s 431us/step - loss: 0.0784 - mean_absolute_error: 0.1805 - val_loss: 0.1076 - val_mean_absolute_error: 0.1956\n",
      "Epoch 130/300\n",
      "271/271 [==============================] - 0s 427us/step - loss: 0.0780 - mean_absolute_error: 0.1806 - val_loss: 0.1099 - val_mean_absolute_error: 0.1949\n",
      "Epoch 131/300\n",
      "271/271 [==============================] - 0s 420us/step - loss: 0.0783 - mean_absolute_error: 0.1812 - val_loss: 0.1057 - val_mean_absolute_error: 0.1898\n",
      "Epoch 132/300\n",
      "271/271 [==============================] - 0s 443us/step - loss: 0.0800 - mean_absolute_error: 0.1833 - val_loss: 0.1034 - val_mean_absolute_error: 0.1898\n",
      "Epoch 133/300\n",
      "271/271 [==============================] - 0s 434us/step - loss: 0.0779 - mean_absolute_error: 0.1810 - val_loss: 0.1085 - val_mean_absolute_error: 0.1978\n",
      "Epoch 134/300\n",
      "271/271 [==============================] - 0s 422us/step - loss: 0.0777 - mean_absolute_error: 0.1814 - val_loss: 0.1116 - val_mean_absolute_error: 0.2022\n",
      "Epoch 135/300\n",
      "271/271 [==============================] - 0s 397us/step - loss: 0.0789 - mean_absolute_error: 0.1818 - val_loss: 0.1082 - val_mean_absolute_error: 0.1927\n",
      "Epoch 136/300\n",
      "271/271 [==============================] - 0s 403us/step - loss: 0.0780 - mean_absolute_error: 0.1810 - val_loss: 0.1073 - val_mean_absolute_error: 0.1980\n",
      "Epoch 137/300\n",
      "271/271 [==============================] - 0s 408us/step - loss: 0.0816 - mean_absolute_error: 0.1840 - val_loss: 0.1061 - val_mean_absolute_error: 0.1929\n",
      "Epoch 138/300\n",
      "271/271 [==============================] - 0s 420us/step - loss: 0.0770 - mean_absolute_error: 0.1800 - val_loss: 0.1049 - val_mean_absolute_error: 0.1928\n",
      "Epoch 139/300\n",
      "271/271 [==============================] - 0s 433us/step - loss: 0.0766 - mean_absolute_error: 0.1796 - val_loss: 0.1077 - val_mean_absolute_error: 0.1922\n",
      "Epoch 140/300\n",
      "271/271 [==============================] - 0s 410us/step - loss: 0.0795 - mean_absolute_error: 0.1832 - val_loss: 0.1055 - val_mean_absolute_error: 0.1981\n",
      "Epoch 141/300\n",
      "271/271 [==============================] - 0s 393us/step - loss: 0.0766 - mean_absolute_error: 0.1808 - val_loss: 0.1084 - val_mean_absolute_error: 0.1958\n",
      "Epoch 142/300\n",
      "271/271 [==============================] - 0s 410us/step - loss: 0.0775 - mean_absolute_error: 0.1812 - val_loss: 0.1084 - val_mean_absolute_error: 0.1965\n",
      "Epoch 143/300\n",
      "271/271 [==============================] - 0s 427us/step - loss: 0.0780 - mean_absolute_error: 0.1817 - val_loss: 0.1076 - val_mean_absolute_error: 0.2005\n",
      "Epoch 144/300\n",
      "271/271 [==============================] - 0s 412us/step - loss: 0.0772 - mean_absolute_error: 0.1813 - val_loss: 0.1043 - val_mean_absolute_error: 0.1948\n",
      "Epoch 145/300\n",
      "271/271 [==============================] - 0s 401us/step - loss: 0.0766 - mean_absolute_error: 0.1805 - val_loss: 0.1057 - val_mean_absolute_error: 0.1939\n",
      "Epoch 146/300\n",
      "271/271 [==============================] - 0s 408us/step - loss: 0.0764 - mean_absolute_error: 0.1799 - val_loss: 0.1046 - val_mean_absolute_error: 0.1945\n",
      "Epoch 147/300\n",
      "271/271 [==============================] - 0s 402us/step - loss: 0.0764 - mean_absolute_error: 0.1803 - val_loss: 0.1102 - val_mean_absolute_error: 0.2042\n",
      "Epoch 148/300\n",
      "271/271 [==============================] - 0s 397us/step - loss: 0.0764 - mean_absolute_error: 0.1804 - val_loss: 0.1089 - val_mean_absolute_error: 0.1995\n",
      "Epoch 149/300\n",
      "271/271 [==============================] - 0s 397us/step - loss: 0.0766 - mean_absolute_error: 0.1799 - val_loss: 0.1074 - val_mean_absolute_error: 0.1927\n",
      "Epoch 150/300\n",
      "271/271 [==============================] - 0s 438us/step - loss: 0.0767 - mean_absolute_error: 0.1808 - val_loss: 0.1071 - val_mean_absolute_error: 0.2002\n",
      "Epoch 151/300\n",
      "271/271 [==============================] - 0s 407us/step - loss: 0.0769 - mean_absolute_error: 0.1805 - val_loss: 0.1064 - val_mean_absolute_error: 0.1940\n",
      "Epoch 152/300\n",
      "271/271 [==============================] - 0s 405us/step - loss: 0.0760 - mean_absolute_error: 0.1794 - val_loss: 0.1077 - val_mean_absolute_error: 0.1921\n",
      "Epoch 153/300\n",
      "271/271 [==============================] - 0s 392us/step - loss: 0.0760 - mean_absolute_error: 0.1804 - val_loss: 0.1070 - val_mean_absolute_error: 0.1939\n",
      "Epoch 154/300\n",
      "271/271 [==============================] - 0s 392us/step - loss: 0.0769 - mean_absolute_error: 0.1801 - val_loss: 0.1056 - val_mean_absolute_error: 0.1935\n",
      "Epoch 155/300\n",
      "271/271 [==============================] - 0s 397us/step - loss: 0.0757 - mean_absolute_error: 0.1796 - val_loss: 0.1121 - val_mean_absolute_error: 0.1965\n",
      "Epoch 156/300\n",
      "271/271 [==============================] - 0s 394us/step - loss: 0.0760 - mean_absolute_error: 0.1803 - val_loss: 0.1073 - val_mean_absolute_error: 0.1958\n",
      "Epoch 157/300\n",
      "271/271 [==============================] - 0s 392us/step - loss: 0.0783 - mean_absolute_error: 0.1810 - val_loss: 0.1122 - val_mean_absolute_error: 0.1960\n",
      "Epoch 158/300\n",
      "271/271 [==============================] - 0s 414us/step - loss: 0.0765 - mean_absolute_error: 0.1804 - val_loss: 0.1076 - val_mean_absolute_error: 0.1925\n",
      "Epoch 159/300\n",
      "271/271 [==============================] - 0s 399us/step - loss: 0.0760 - mean_absolute_error: 0.1805 - val_loss: 0.1134 - val_mean_absolute_error: 0.2005\n",
      "Epoch 160/300\n",
      "271/271 [==============================] - 0s 401us/step - loss: 0.0760 - mean_absolute_error: 0.1795 - val_loss: 0.1070 - val_mean_absolute_error: 0.1921\n",
      "Epoch 161/300\n",
      "271/271 [==============================] - 0s 431us/step - loss: 0.0766 - mean_absolute_error: 0.1800 - val_loss: 0.1092 - val_mean_absolute_error: 0.1965\n",
      "Epoch 162/300\n",
      "271/271 [==============================] - 0s 420us/step - loss: 0.0753 - mean_absolute_error: 0.1800 - val_loss: 0.1077 - val_mean_absolute_error: 0.2005\n",
      "Epoch 163/300\n",
      "271/271 [==============================] - 0s 405us/step - loss: 0.0759 - mean_absolute_error: 0.1810 - val_loss: 0.1168 - val_mean_absolute_error: 0.2059\n",
      "Epoch 164/300\n",
      "271/271 [==============================] - 0s 416us/step - loss: 0.0761 - mean_absolute_error: 0.1802 - val_loss: 0.1071 - val_mean_absolute_error: 0.1940\n",
      "Epoch 165/300\n",
      "271/271 [==============================] - 0s 403us/step - loss: 0.0759 - mean_absolute_error: 0.1797 - val_loss: 0.1090 - val_mean_absolute_error: 0.1969\n",
      "Epoch 166/300\n",
      "271/271 [==============================] - 0s 386us/step - loss: 0.0748 - mean_absolute_error: 0.1790 - val_loss: 0.1074 - val_mean_absolute_error: 0.1951\n",
      "Epoch 167/300\n",
      "271/271 [==============================] - 0s 423us/step - loss: 0.0751 - mean_absolute_error: 0.1791 - val_loss: 0.1190 - val_mean_absolute_error: 0.1973\n",
      "Epoch 168/300\n",
      "271/271 [==============================] - 0s 431us/step - loss: 0.0758 - mean_absolute_error: 0.1795 - val_loss: 0.1108 - val_mean_absolute_error: 0.1957\n",
      "Epoch 169/300\n",
      "271/271 [==============================] - 0s 418us/step - loss: 0.0749 - mean_absolute_error: 0.1790 - val_loss: 0.1122 - val_mean_absolute_error: 0.1989\n",
      "Epoch 170/300\n",
      "271/271 [==============================] - 0s 389us/step - loss: 0.0752 - mean_absolute_error: 0.1791 - val_loss: 0.1118 - val_mean_absolute_error: 0.2014\n",
      "Epoch 171/300\n",
      "271/271 [==============================] - 0s 390us/step - loss: 0.0751 - mean_absolute_error: 0.1800 - val_loss: 0.1046 - val_mean_absolute_error: 0.1991\n",
      "Epoch 172/300\n",
      "271/271 [==============================] - 0s 404us/step - loss: 0.0754 - mean_absolute_error: 0.1795 - val_loss: 0.1112 - val_mean_absolute_error: 0.1950\n",
      "Epoch 173/300\n",
      "271/271 [==============================] - 0s 449us/step - loss: 0.0753 - mean_absolute_error: 0.1796 - val_loss: 0.1093 - val_mean_absolute_error: 0.1970\n",
      "Epoch 174/300\n",
      "271/271 [==============================] - 0s 480us/step - loss: 0.0743 - mean_absolute_error: 0.1787 - val_loss: 0.1096 - val_mean_absolute_error: 0.1942\n",
      "Epoch 175/300\n",
      "271/271 [==============================] - 0s 451us/step - loss: 0.0742 - mean_absolute_error: 0.1781 - val_loss: 0.1119 - val_mean_absolute_error: 0.2026\n",
      "Epoch 176/300\n",
      "271/271 [==============================] - 0s 504us/step - loss: 0.0748 - mean_absolute_error: 0.1792 - val_loss: 0.1096 - val_mean_absolute_error: 0.1996\n",
      "Epoch 177/300\n",
      "271/271 [==============================] - 0s 497us/step - loss: 0.0753 - mean_absolute_error: 0.1803 - val_loss: 0.1113 - val_mean_absolute_error: 0.1986\n",
      "Epoch 178/300\n",
      "271/271 [==============================] - 0s 482us/step - loss: 0.0754 - mean_absolute_error: 0.1799 - val_loss: 0.1085 - val_mean_absolute_error: 0.1968\n",
      "Epoch 179/300\n",
      "271/271 [==============================] - 0s 449us/step - loss: 0.0763 - mean_absolute_error: 0.1806 - val_loss: 0.1073 - val_mean_absolute_error: 0.1942\n",
      "Epoch 180/300\n",
      "271/271 [==============================] - 0s 420us/step - loss: 0.0760 - mean_absolute_error: 0.1798 - val_loss: 0.1058 - val_mean_absolute_error: 0.1940\n",
      "Epoch 181/300\n",
      "271/271 [==============================] - 0s 556us/step - loss: 0.0746 - mean_absolute_error: 0.1784 - val_loss: 0.1105 - val_mean_absolute_error: 0.1933\n",
      "Epoch 182/300\n",
      "271/271 [==============================] - 0s 423us/step - loss: 0.0746 - mean_absolute_error: 0.1784 - val_loss: 0.1068 - val_mean_absolute_error: 0.1966\n",
      "Epoch 183/300\n",
      "271/271 [==============================] - 0s 423us/step - loss: 0.0761 - mean_absolute_error: 0.1800 - val_loss: 0.1084 - val_mean_absolute_error: 0.2015\n",
      "Epoch 184/300\n",
      "271/271 [==============================] - 0s 414us/step - loss: 0.0742 - mean_absolute_error: 0.1788 - val_loss: 0.1067 - val_mean_absolute_error: 0.1975\n",
      "Epoch 185/300\n",
      "271/271 [==============================] - 0s 395us/step - loss: 0.0742 - mean_absolute_error: 0.1785 - val_loss: 0.1075 - val_mean_absolute_error: 0.1964\n",
      "Epoch 186/300\n",
      "271/271 [==============================] - 0s 405us/step - loss: 0.0743 - mean_absolute_error: 0.1790 - val_loss: 0.1069 - val_mean_absolute_error: 0.1919\n",
      "Epoch 187/300\n",
      "271/271 [==============================] - 0s 414us/step - loss: 0.0748 - mean_absolute_error: 0.1803 - val_loss: 0.1073 - val_mean_absolute_error: 0.1961\n",
      "Epoch 188/300\n",
      "271/271 [==============================] - 0s 399us/step - loss: 0.0746 - mean_absolute_error: 0.1795 - val_loss: 0.1096 - val_mean_absolute_error: 0.1994\n",
      "Epoch 189/300\n",
      "271/271 [==============================] - 0s 398us/step - loss: 0.0749 - mean_absolute_error: 0.1793 - val_loss: 0.1094 - val_mean_absolute_error: 0.1944\n",
      "Epoch 190/300\n",
      "271/271 [==============================] - 0s 412us/step - loss: 0.0745 - mean_absolute_error: 0.1786 - val_loss: 0.1099 - val_mean_absolute_error: 0.1984\n",
      "Epoch 191/300\n",
      "271/271 [==============================] - 0s 412us/step - loss: 0.0755 - mean_absolute_error: 0.1794 - val_loss: 0.1068 - val_mean_absolute_error: 0.1975\n",
      "Epoch 192/300\n",
      "271/271 [==============================] - 0s 396us/step - loss: 0.0745 - mean_absolute_error: 0.1789 - val_loss: 0.1075 - val_mean_absolute_error: 0.1959\n",
      "Epoch 193/300\n",
      "271/271 [==============================] - 0s 397us/step - loss: 0.0754 - mean_absolute_error: 0.1787 - val_loss: 0.1073 - val_mean_absolute_error: 0.1927\n",
      "Epoch 194/300\n",
      "271/271 [==============================] - 0s 401us/step - loss: 0.0739 - mean_absolute_error: 0.1780 - val_loss: 0.1028 - val_mean_absolute_error: 0.1929\n",
      "Epoch 195/300\n",
      "271/271 [==============================] - 0s 401us/step - loss: 0.0743 - mean_absolute_error: 0.1784 - val_loss: 0.1059 - val_mean_absolute_error: 0.1956\n",
      "Epoch 196/300\n",
      "271/271 [==============================] - 0s 436us/step - loss: 0.0736 - mean_absolute_error: 0.1781 - val_loss: 0.1093 - val_mean_absolute_error: 0.1958\n",
      "Epoch 197/300\n",
      "271/271 [==============================] - 0s 390us/step - loss: 0.0738 - mean_absolute_error: 0.1772 - val_loss: 0.1028 - val_mean_absolute_error: 0.1916\n",
      "Epoch 198/300\n",
      "271/271 [==============================] - 0s 392us/step - loss: 0.0744 - mean_absolute_error: 0.1782 - val_loss: 0.1102 - val_mean_absolute_error: 0.1961\n",
      "Epoch 199/300\n",
      "271/271 [==============================] - 0s 390us/step - loss: 0.0743 - mean_absolute_error: 0.1783 - val_loss: 0.1037 - val_mean_absolute_error: 0.1906\n",
      "Epoch 200/300\n",
      "271/271 [==============================] - 0s 392us/step - loss: 0.0744 - mean_absolute_error: 0.1787 - val_loss: 0.1055 - val_mean_absolute_error: 0.1942\n",
      "Epoch 201/300\n",
      "271/271 [==============================] - 0s 388us/step - loss: 0.0749 - mean_absolute_error: 0.1787 - val_loss: 0.1056 - val_mean_absolute_error: 0.1913\n",
      "Epoch 202/300\n",
      "271/271 [==============================] - 0s 390us/step - loss: 0.0744 - mean_absolute_error: 0.1786 - val_loss: 0.1095 - val_mean_absolute_error: 0.1946\n",
      "Epoch 203/300\n",
      "271/271 [==============================] - 0s 392us/step - loss: 0.0743 - mean_absolute_error: 0.1782 - val_loss: 0.1079 - val_mean_absolute_error: 0.1966\n",
      "Epoch 204/300\n",
      "271/271 [==============================] - 0s 405us/step - loss: 0.0742 - mean_absolute_error: 0.1781 - val_loss: 0.1025 - val_mean_absolute_error: 0.1917\n",
      "Epoch 205/300\n",
      "271/271 [==============================] - 0s 405us/step - loss: 0.0752 - mean_absolute_error: 0.1794 - val_loss: 0.1020 - val_mean_absolute_error: 0.1903\n",
      "Epoch 206/300\n",
      "271/271 [==============================] - 0s 400us/step - loss: 0.0736 - mean_absolute_error: 0.1783 - val_loss: 0.1048 - val_mean_absolute_error: 0.1917\n",
      "Epoch 207/300\n",
      "271/271 [==============================] - 0s 416us/step - loss: 0.0736 - mean_absolute_error: 0.1784 - val_loss: 0.1083 - val_mean_absolute_error: 0.2021\n",
      "Epoch 208/300\n",
      "271/271 [==============================] - 0s 405us/step - loss: 0.0745 - mean_absolute_error: 0.1786 - val_loss: 0.1049 - val_mean_absolute_error: 0.1979\n",
      "Epoch 209/300\n",
      "271/271 [==============================] - 0s 397us/step - loss: 0.0734 - mean_absolute_error: 0.1787 - val_loss: 0.1050 - val_mean_absolute_error: 0.1923\n",
      "Epoch 210/300\n",
      "271/271 [==============================] - 0s 408us/step - loss: 0.0738 - mean_absolute_error: 0.1781 - val_loss: 0.1063 - val_mean_absolute_error: 0.1932\n",
      "Epoch 211/300\n",
      "271/271 [==============================] - 0s 453us/step - loss: 0.0736 - mean_absolute_error: 0.1783 - val_loss: 0.1054 - val_mean_absolute_error: 0.1922\n",
      "Epoch 212/300\n",
      "271/271 [==============================] - 0s 485us/step - loss: 0.0741 - mean_absolute_error: 0.1780 - val_loss: 0.1129 - val_mean_absolute_error: 0.1991\n",
      "Epoch 213/300\n",
      "271/271 [==============================] - 0s 412us/step - loss: 0.0737 - mean_absolute_error: 0.1783 - val_loss: 0.1067 - val_mean_absolute_error: 0.1988\n",
      "Epoch 214/300\n",
      "271/271 [==============================] - 0s 427us/step - loss: 0.0748 - mean_absolute_error: 0.1789 - val_loss: 0.1047 - val_mean_absolute_error: 0.1913\n",
      "Epoch 215/300\n",
      "271/271 [==============================] - 0s 515us/step - loss: 0.0739 - mean_absolute_error: 0.1783 - val_loss: 0.1043 - val_mean_absolute_error: 0.1912\n",
      "Epoch 216/300\n",
      "271/271 [==============================] - 0s 417us/step - loss: 0.0735 - mean_absolute_error: 0.1780 - val_loss: 0.1070 - val_mean_absolute_error: 0.1908\n",
      "Epoch 217/300\n",
      "271/271 [==============================] - 0s 416us/step - loss: 0.0731 - mean_absolute_error: 0.1775 - val_loss: 0.1088 - val_mean_absolute_error: 0.2035\n",
      "Epoch 218/300\n",
      "271/271 [==============================] - 0s 419us/step - loss: 0.0737 - mean_absolute_error: 0.1788 - val_loss: 0.1032 - val_mean_absolute_error: 0.1898\n",
      "Epoch 219/300\n",
      "271/271 [==============================] - 0s 385us/step - loss: 0.0743 - mean_absolute_error: 0.1790 - val_loss: 0.1075 - val_mean_absolute_error: 0.1972\n",
      "Epoch 220/300\n",
      "271/271 [==============================] - 0s 405us/step - loss: 0.0734 - mean_absolute_error: 0.1771 - val_loss: 0.1052 - val_mean_absolute_error: 0.1929\n",
      "Epoch 221/300\n",
      "271/271 [==============================] - 0s 387us/step - loss: 0.0745 - mean_absolute_error: 0.1781 - val_loss: 0.1073 - val_mean_absolute_error: 0.1965\n",
      "Epoch 222/300\n",
      "271/271 [==============================] - 0s 412us/step - loss: 0.0738 - mean_absolute_error: 0.1786 - val_loss: 0.1053 - val_mean_absolute_error: 0.1918\n",
      "Epoch 223/300\n",
      "271/271 [==============================] - 0s 408us/step - loss: 0.0738 - mean_absolute_error: 0.1784 - val_loss: 0.1066 - val_mean_absolute_error: 0.1942\n",
      "Epoch 224/300\n",
      "271/271 [==============================] - 0s 405us/step - loss: 0.0743 - mean_absolute_error: 0.1784 - val_loss: 0.1052 - val_mean_absolute_error: 0.1955\n",
      "Epoch 225/300\n",
      "271/271 [==============================] - 0s 401us/step - loss: 0.0737 - mean_absolute_error: 0.1780 - val_loss: 0.1020 - val_mean_absolute_error: 0.1917\n",
      "Epoch 226/300\n",
      "271/271 [==============================] - 0s 405us/step - loss: 0.0741 - mean_absolute_error: 0.1777 - val_loss: 0.1046 - val_mean_absolute_error: 0.1941\n",
      "Epoch 227/300\n",
      "271/271 [==============================] - 0s 394us/step - loss: 0.0740 - mean_absolute_error: 0.1785 - val_loss: 0.1080 - val_mean_absolute_error: 0.1983\n",
      "Epoch 228/300\n",
      "271/271 [==============================] - 0s 404us/step - loss: 0.0734 - mean_absolute_error: 0.1778 - val_loss: 0.1069 - val_mean_absolute_error: 0.1915\n",
      "Epoch 229/300\n",
      "271/271 [==============================] - 0s 401us/step - loss: 0.0732 - mean_absolute_error: 0.1775 - val_loss: 0.1061 - val_mean_absolute_error: 0.1944\n",
      "Epoch 230/300\n",
      "271/271 [==============================] - 0s 425us/step - loss: 0.0731 - mean_absolute_error: 0.1776 - val_loss: 0.1105 - val_mean_absolute_error: 0.1987\n",
      "Epoch 231/300\n",
      "271/271 [==============================] - 0s 412us/step - loss: 0.0747 - mean_absolute_error: 0.1795 - val_loss: 0.1104 - val_mean_absolute_error: 0.1998\n",
      "Epoch 232/300\n",
      "271/271 [==============================] - 0s 403us/step - loss: 0.0737 - mean_absolute_error: 0.1770 - val_loss: 0.1100 - val_mean_absolute_error: 0.1982\n",
      "Epoch 233/300\n",
      "271/271 [==============================] - 0s 401us/step - loss: 0.0741 - mean_absolute_error: 0.1802 - val_loss: 0.1124 - val_mean_absolute_error: 0.1955\n",
      "Epoch 234/300\n",
      "271/271 [==============================] - 0s 386us/step - loss: 0.0727 - mean_absolute_error: 0.1778 - val_loss: 0.1046 - val_mean_absolute_error: 0.1919\n",
      "Epoch 235/300\n",
      "271/271 [==============================] - 0s 386us/step - loss: 0.0729 - mean_absolute_error: 0.1769 - val_loss: 0.1070 - val_mean_absolute_error: 0.1954\n",
      "Epoch 236/300\n",
      "271/271 [==============================] - 0s 389us/step - loss: 0.0730 - mean_absolute_error: 0.1778 - val_loss: 0.1113 - val_mean_absolute_error: 0.1961\n",
      "Epoch 237/300\n",
      "271/271 [==============================] - 0s 416us/step - loss: 0.0741 - mean_absolute_error: 0.1789 - val_loss: 0.1098 - val_mean_absolute_error: 0.1935\n",
      "Epoch 238/300\n",
      "271/271 [==============================] - 0s 412us/step - loss: 0.0723 - mean_absolute_error: 0.1770 - val_loss: 0.1097 - val_mean_absolute_error: 0.1968\n",
      "Epoch 239/300\n",
      "271/271 [==============================] - 0s 408us/step - loss: 0.0741 - mean_absolute_error: 0.1777 - val_loss: 0.1032 - val_mean_absolute_error: 0.1893\n",
      "Epoch 240/300\n",
      "271/271 [==============================] - 0s 412us/step - loss: 0.0732 - mean_absolute_error: 0.1781 - val_loss: 0.1081 - val_mean_absolute_error: 0.1906\n",
      "Epoch 241/300\n",
      "271/271 [==============================] - 0s 414us/step - loss: 0.0735 - mean_absolute_error: 0.1779 - val_loss: 0.1051 - val_mean_absolute_error: 0.1925\n",
      "Epoch 242/300\n",
      "271/271 [==============================] - 0s 409us/step - loss: 0.0733 - mean_absolute_error: 0.1783 - val_loss: 0.1046 - val_mean_absolute_error: 0.1910\n",
      "Epoch 243/300\n",
      "271/271 [==============================] - 0s 423us/step - loss: 0.0731 - mean_absolute_error: 0.1782 - val_loss: 0.1078 - val_mean_absolute_error: 0.1922\n",
      "Epoch 244/300\n",
      "271/271 [==============================] - 0s 408us/step - loss: 0.0733 - mean_absolute_error: 0.1777 - val_loss: 0.1117 - val_mean_absolute_error: 0.1959\n",
      "Epoch 245/300\n",
      "271/271 [==============================] - 0s 405us/step - loss: 0.0721 - mean_absolute_error: 0.1767 - val_loss: 0.1064 - val_mean_absolute_error: 0.1908\n",
      "Epoch 246/300\n",
      "271/271 [==============================] - 0s 415us/step - loss: 0.0727 - mean_absolute_error: 0.1771 - val_loss: 0.1046 - val_mean_absolute_error: 0.1922\n",
      "Epoch 247/300\n",
      "271/271 [==============================] - 0s 407us/step - loss: 0.0727 - mean_absolute_error: 0.1777 - val_loss: 0.1062 - val_mean_absolute_error: 0.1915\n",
      "Epoch 248/300\n",
      "271/271 [==============================] - 0s 405us/step - loss: 0.0738 - mean_absolute_error: 0.1783 - val_loss: 0.1095 - val_mean_absolute_error: 0.1964\n",
      "Epoch 249/300\n",
      "271/271 [==============================] - 0s 401us/step - loss: 0.0731 - mean_absolute_error: 0.1776 - val_loss: 0.1067 - val_mean_absolute_error: 0.1965\n",
      "Epoch 250/300\n",
      "271/271 [==============================] - 0s 408us/step - loss: 0.0724 - mean_absolute_error: 0.1763 - val_loss: 0.1109 - val_mean_absolute_error: 0.2012\n",
      "Epoch 251/300\n",
      "271/271 [==============================] - 0s 397us/step - loss: 0.0737 - mean_absolute_error: 0.1788 - val_loss: 0.1058 - val_mean_absolute_error: 0.1939\n",
      "Epoch 252/300\n",
      "271/271 [==============================] - 0s 420us/step - loss: 0.0737 - mean_absolute_error: 0.1778 - val_loss: 0.1087 - val_mean_absolute_error: 0.1940\n",
      "Epoch 253/300\n",
      "271/271 [==============================] - 0s 438us/step - loss: 0.0727 - mean_absolute_error: 0.1774 - val_loss: 0.1069 - val_mean_absolute_error: 0.2082\n",
      "Epoch 254/300\n",
      "271/271 [==============================] - 0s 407us/step - loss: 0.0724 - mean_absolute_error: 0.1774 - val_loss: 0.1064 - val_mean_absolute_error: 0.1919\n",
      "Epoch 255/300\n",
      "271/271 [==============================] - 0s 396us/step - loss: 0.0731 - mean_absolute_error: 0.1779 - val_loss: 0.1096 - val_mean_absolute_error: 0.1953\n",
      "Epoch 256/300\n",
      "271/271 [==============================] - 0s 397us/step - loss: 0.0731 - mean_absolute_error: 0.1773 - val_loss: 0.1034 - val_mean_absolute_error: 0.1927\n",
      "Epoch 257/300\n",
      "271/271 [==============================] - 0s 418us/step - loss: 0.0721 - mean_absolute_error: 0.1766 - val_loss: 0.1062 - val_mean_absolute_error: 0.1934\n",
      "Epoch 258/300\n",
      "271/271 [==============================] - 0s 397us/step - loss: 0.0734 - mean_absolute_error: 0.1782 - val_loss: 0.1078 - val_mean_absolute_error: 0.1937\n",
      "Epoch 259/300\n",
      "271/271 [==============================] - 0s 396us/step - loss: 0.0741 - mean_absolute_error: 0.1781 - val_loss: 0.1081 - val_mean_absolute_error: 0.1940\n",
      "Epoch 260/300\n",
      "271/271 [==============================] - 0s 389us/step - loss: 0.0729 - mean_absolute_error: 0.1773 - val_loss: 0.1084 - val_mean_absolute_error: 0.1989\n",
      "Epoch 261/300\n",
      "271/271 [==============================] - 0s 386us/step - loss: 0.0734 - mean_absolute_error: 0.1780 - val_loss: 0.1080 - val_mean_absolute_error: 0.1939\n",
      "Epoch 262/300\n",
      "271/271 [==============================] - 0s 434us/step - loss: 0.0725 - mean_absolute_error: 0.1774 - val_loss: 0.1053 - val_mean_absolute_error: 0.1916\n",
      "Epoch 263/300\n",
      "271/271 [==============================] - 0s 390us/step - loss: 0.0718 - mean_absolute_error: 0.1767 - val_loss: 0.1038 - val_mean_absolute_error: 0.1916\n",
      "Epoch 264/300\n",
      "271/271 [==============================] - 0s 394us/step - loss: 0.0721 - mean_absolute_error: 0.1766 - val_loss: 0.1059 - val_mean_absolute_error: 0.1953\n",
      "Epoch 265/300\n",
      "271/271 [==============================] - 0s 390us/step - loss: 0.0729 - mean_absolute_error: 0.1778 - val_loss: 0.1042 - val_mean_absolute_error: 0.1963\n",
      "Epoch 266/300\n",
      "271/271 [==============================] - 0s 393us/step - loss: 0.0723 - mean_absolute_error: 0.1769 - val_loss: 0.1150 - val_mean_absolute_error: 0.1988\n",
      "Epoch 267/300\n",
      "271/271 [==============================] - 0s 395us/step - loss: 0.0726 - mean_absolute_error: 0.1768 - val_loss: 0.1034 - val_mean_absolute_error: 0.1914\n",
      "Epoch 268/300\n",
      "271/271 [==============================] - 0s 389us/step - loss: 0.0726 - mean_absolute_error: 0.1775 - val_loss: 0.1102 - val_mean_absolute_error: 0.1955\n",
      "Epoch 269/300\n",
      "271/271 [==============================] - 0s 390us/step - loss: 0.0727 - mean_absolute_error: 0.1773 - val_loss: 0.1049 - val_mean_absolute_error: 0.1943\n",
      "Epoch 270/300\n",
      "271/271 [==============================] - 0s 420us/step - loss: 0.0721 - mean_absolute_error: 0.1771 - val_loss: 0.1067 - val_mean_absolute_error: 0.1899\n",
      "Epoch 271/300\n",
      "271/271 [==============================] - 0s 401us/step - loss: 0.0732 - mean_absolute_error: 0.1780 - val_loss: 0.1095 - val_mean_absolute_error: 0.1979\n",
      "Epoch 272/300\n",
      "271/271 [==============================] - 0s 390us/step - loss: 0.0716 - mean_absolute_error: 0.1759 - val_loss: 0.1046 - val_mean_absolute_error: 0.1896\n",
      "Epoch 273/300\n",
      "271/271 [==============================] - 0s 383us/step - loss: 0.0726 - mean_absolute_error: 0.1777 - val_loss: 0.1068 - val_mean_absolute_error: 0.1906\n",
      "Epoch 274/300\n",
      "271/271 [==============================] - 0s 386us/step - loss: 0.0725 - mean_absolute_error: 0.1780 - val_loss: 0.1016 - val_mean_absolute_error: 0.1927\n",
      "Epoch 275/300\n",
      "271/271 [==============================] - 0s 401us/step - loss: 0.0724 - mean_absolute_error: 0.1769 - val_loss: 0.1077 - val_mean_absolute_error: 0.1965\n",
      "Epoch 276/300\n",
      "271/271 [==============================] - 0s 386us/step - loss: 0.0727 - mean_absolute_error: 0.1776 - val_loss: 0.1062 - val_mean_absolute_error: 0.1922\n",
      "Epoch 277/300\n",
      "271/271 [==============================] - 0s 396us/step - loss: 0.0719 - mean_absolute_error: 0.1766 - val_loss: 0.1057 - val_mean_absolute_error: 0.1929\n",
      "Epoch 278/300\n",
      "271/271 [==============================] - 0s 432us/step - loss: 0.0725 - mean_absolute_error: 0.1770 - val_loss: 0.1010 - val_mean_absolute_error: 0.1891\n",
      "Epoch 279/300\n",
      "271/271 [==============================] - 0s 404us/step - loss: 0.0722 - mean_absolute_error: 0.1768 - val_loss: 0.1073 - val_mean_absolute_error: 0.1967\n",
      "Epoch 280/300\n",
      "271/271 [==============================] - 0s 395us/step - loss: 0.0726 - mean_absolute_error: 0.1771 - val_loss: 0.1026 - val_mean_absolute_error: 0.1929\n",
      "Epoch 281/300\n",
      "271/271 [==============================] - 0s 387us/step - loss: 0.0729 - mean_absolute_error: 0.1777 - val_loss: 0.1096 - val_mean_absolute_error: 0.1966\n",
      "Epoch 282/300\n",
      "271/271 [==============================] - 0s 397us/step - loss: 0.0719 - mean_absolute_error: 0.1765 - val_loss: 0.1051 - val_mean_absolute_error: 0.1918\n",
      "Epoch 283/300\n",
      "271/271 [==============================] - 0s 395us/step - loss: 0.0720 - mean_absolute_error: 0.1758 - val_loss: 0.1064 - val_mean_absolute_error: 0.1913\n",
      "Epoch 284/300\n",
      "271/271 [==============================] - 0s 401us/step - loss: 0.0741 - mean_absolute_error: 0.1770 - val_loss: 0.1109 - val_mean_absolute_error: 0.1959\n",
      "Epoch 285/300\n",
      "271/271 [==============================] - 0s 412us/step - loss: 0.0725 - mean_absolute_error: 0.1775 - val_loss: 0.1051 - val_mean_absolute_error: 0.2040\n",
      "Epoch 286/300\n",
      "271/271 [==============================] - 0s 412us/step - loss: 0.0723 - mean_absolute_error: 0.1776 - val_loss: 0.1050 - val_mean_absolute_error: 0.1967\n",
      "Epoch 287/300\n",
      "271/271 [==============================] - 0s 394us/step - loss: 0.0734 - mean_absolute_error: 0.1780 - val_loss: 0.1072 - val_mean_absolute_error: 0.1943\n",
      "Epoch 288/300\n",
      "271/271 [==============================] - 0s 397us/step - loss: 0.0713 - mean_absolute_error: 0.1758 - val_loss: 0.1047 - val_mean_absolute_error: 0.1914\n",
      "Epoch 289/300\n",
      "271/271 [==============================] - 0s 389us/step - loss: 0.0718 - mean_absolute_error: 0.1764 - val_loss: 0.1096 - val_mean_absolute_error: 0.2082\n",
      "Epoch 290/300\n",
      "271/271 [==============================] - 0s 387us/step - loss: 0.0721 - mean_absolute_error: 0.1773 - val_loss: 0.1087 - val_mean_absolute_error: 0.1928\n",
      "Epoch 291/300\n",
      "271/271 [==============================] - 0s 392us/step - loss: 0.0734 - mean_absolute_error: 0.1776 - val_loss: 0.1074 - val_mean_absolute_error: 0.2006\n",
      "Epoch 292/300\n",
      "271/271 [==============================] - 0s 399us/step - loss: 0.0725 - mean_absolute_error: 0.1780 - val_loss: 0.1131 - val_mean_absolute_error: 0.2035\n",
      "Epoch 293/300\n",
      "271/271 [==============================] - 0s 390us/step - loss: 0.0717 - mean_absolute_error: 0.1763 - val_loss: 0.1052 - val_mean_absolute_error: 0.1922\n",
      "Epoch 294/300\n",
      "271/271 [==============================] - 0s 396us/step - loss: 0.0719 - mean_absolute_error: 0.1763 - val_loss: 0.1081 - val_mean_absolute_error: 0.1931\n",
      "Epoch 295/300\n",
      "271/271 [==============================] - 0s 401us/step - loss: 0.0723 - mean_absolute_error: 0.1767 - val_loss: 0.1104 - val_mean_absolute_error: 0.1960\n",
      "Epoch 296/300\n",
      "271/271 [==============================] - 0s 393us/step - loss: 0.0717 - mean_absolute_error: 0.1762 - val_loss: 0.1074 - val_mean_absolute_error: 0.1911\n",
      "Epoch 297/300\n",
      "271/271 [==============================] - 0s 387us/step - loss: 0.0726 - mean_absolute_error: 0.1777 - val_loss: 0.1066 - val_mean_absolute_error: 0.1988\n",
      "Epoch 298/300\n",
      "271/271 [==============================] - 0s 400us/step - loss: 0.0714 - mean_absolute_error: 0.1756 - val_loss: 0.1055 - val_mean_absolute_error: 0.1939\n",
      "Epoch 299/300\n",
      "271/271 [==============================] - 0s 397us/step - loss: 0.0720 - mean_absolute_error: 0.1771 - val_loss: 0.1045 - val_mean_absolute_error: 0.1921\n",
      "Epoch 300/300\n",
      "271/271 [==============================] - 0s 393us/step - loss: 0.0732 - mean_absolute_error: 0.1788 - val_loss: 0.1042 - val_mean_absolute_error: 0.1918\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ce4c5ff748>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2 = keras.Sequential(name='model-2')\n",
    "model_2.add(layers.Dense(16, activation='relu', input_shape=(21,)))\n",
    "model_2.add(layers.Dense(16, activation='relu'))\n",
    "model_2.add(layers.Dense(1))\n",
    "model_2.compile(keras.optimizers.Adam(0.001),\n",
    "                loss=keras.losses.MeanSquaredError(),\n",
    "                metrics=[keras.metrics.MeanAbsoluteError()])\n",
    "log_dir = os.path.join('lab2-logs', 'model-2')\n",
    "model_cbk = keras.callbacks.TensorBoard(log_dir=log_dir)\n",
    "model_mckp = keras.callbacks.ModelCheckpoint(model_dir + '/Best-model-2.h5', \n",
    "                                             monitor='val_mean_absolute_error',                                         save_best_only=True, \n",
    "                                             mode='min')\n",
    "model_2.fit(x_train, y_train, \n",
    "            batch_size=64 ,\n",
    "            epochs=300, \n",
    "            validation_data=(x_val, y_val), \n",
    "            callbacks=[model_cbk, model_mckp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3c5f94f7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "  1/271 [..............................] - ETA: 0s - loss: 6.9625 - mean_absolute_error: 0.9784WARNING:tensorflow:Callbacks method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_begin` time: 0.0010s). Check your callbacks.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0239s). Check your callbacks.\n",
      "271/271 [==============================] - 0s 796us/step - loss: 0.3960 - mean_absolute_error: 0.3298 - val_loss: 0.3004 - val_mean_absolute_error: 0.2865\n",
      "Epoch 2/300\n",
      "271/271 [==============================] - 0s 502us/step - loss: 0.2782 - mean_absolute_error: 0.2748 - val_loss: 0.2622 - val_mean_absolute_error: 0.2588\n",
      "Epoch 3/300\n",
      "271/271 [==============================] - 0s 490us/step - loss: 0.2418 - mean_absolute_error: 0.2524 - val_loss: 0.2422 - val_mean_absolute_error: 0.2451\n",
      "Epoch 4/300\n",
      "271/271 [==============================] - 0s 452us/step - loss: 0.2202 - mean_absolute_error: 0.2374 - val_loss: 0.2792 - val_mean_absolute_error: 0.2795\n",
      "Epoch 5/300\n",
      "271/271 [==============================] - 0s 481us/step - loss: 0.2077 - mean_absolute_error: 0.2314 - val_loss: 0.2087 - val_mean_absolute_error: 0.2292\n",
      "Epoch 6/300\n",
      "271/271 [==============================] - 0s 510us/step - loss: 0.1952 - mean_absolute_error: 0.2226 - val_loss: 0.2009 - val_mean_absolute_error: 0.2259\n",
      "Epoch 7/300\n",
      "271/271 [==============================] - 0s 489us/step - loss: 0.1852 - mean_absolute_error: 0.2159 - val_loss: 0.1934 - val_mean_absolute_error: 0.2102\n",
      "Epoch 8/300\n",
      "271/271 [==============================] - 0s 451us/step - loss: 0.1740 - mean_absolute_error: 0.2082 - val_loss: 0.1877 - val_mean_absolute_error: 0.2142\n",
      "Epoch 9/300\n",
      "271/271 [==============================] - 0s 486us/step - loss: 0.1691 - mean_absolute_error: 0.2068 - val_loss: 0.1878 - val_mean_absolute_error: 0.2063\n",
      "Epoch 10/300\n",
      "271/271 [==============================] - 0s 534us/step - loss: 0.1600 - mean_absolute_error: 0.2013 - val_loss: 0.1735 - val_mean_absolute_error: 0.2045\n",
      "Epoch 11/300\n",
      "271/271 [==============================] - 0s 501us/step - loss: 0.1577 - mean_absolute_error: 0.2022 - val_loss: 0.1658 - val_mean_absolute_error: 0.1997\n",
      "Epoch 12/300\n",
      "271/271 [==============================] - 0s 467us/step - loss: 0.1562 - mean_absolute_error: 0.2006 - val_loss: 0.1677 - val_mean_absolute_error: 0.2095\n",
      "Epoch 13/300\n",
      "271/271 [==============================] - 0s 488us/step - loss: 0.1500 - mean_absolute_error: 0.1975 - val_loss: 0.1726 - val_mean_absolute_error: 0.1990\n",
      "Epoch 14/300\n",
      "271/271 [==============================] - 0s 534us/step - loss: 0.1479 - mean_absolute_error: 0.1983 - val_loss: 0.1767 - val_mean_absolute_error: 0.2282\n",
      "Epoch 15/300\n",
      "271/271 [==============================] - 0s 448us/step - loss: 0.1435 - mean_absolute_error: 0.1940 - val_loss: 0.1597 - val_mean_absolute_error: 0.2025\n",
      "Epoch 16/300\n",
      "271/271 [==============================] - 0s 442us/step - loss: 0.1424 - mean_absolute_error: 0.1975 - val_loss: 0.1553 - val_mean_absolute_error: 0.2009\n",
      "Epoch 17/300\n",
      "271/271 [==============================] - 0s 448us/step - loss: 0.1399 - mean_absolute_error: 0.1927 - val_loss: 0.1562 - val_mean_absolute_error: 0.2113\n",
      "Epoch 18/300\n",
      "271/271 [==============================] - 0s 492us/step - loss: 0.1373 - mean_absolute_error: 0.1938 - val_loss: 0.1653 - val_mean_absolute_error: 0.2155\n",
      "Epoch 19/300\n",
      "271/271 [==============================] - 0s 602us/step - loss: 0.1411 - mean_absolute_error: 0.1936 - val_loss: 0.1556 - val_mean_absolute_error: 0.1959\n",
      "Epoch 20/300\n",
      "271/271 [==============================] - 0s 485us/step - loss: 0.1327 - mean_absolute_error: 0.1899 - val_loss: 0.1479 - val_mean_absolute_error: 0.1940\n",
      "Epoch 21/300\n",
      "271/271 [==============================] - 0s 476us/step - loss: 0.1301 - mean_absolute_error: 0.1877 - val_loss: 0.1463 - val_mean_absolute_error: 0.1914\n",
      "Epoch 22/300\n",
      "271/271 [==============================] - 0s 454us/step - loss: 0.1301 - mean_absolute_error: 0.1886 - val_loss: 0.1490 - val_mean_absolute_error: 0.1927\n",
      "Epoch 23/300\n",
      "271/271 [==============================] - 0s 456us/step - loss: 0.1275 - mean_absolute_error: 0.1873 - val_loss: 0.1454 - val_mean_absolute_error: 0.1971\n",
      "Epoch 24/300\n",
      "271/271 [==============================] - 0s 504us/step - loss: 0.1271 - mean_absolute_error: 0.1874 - val_loss: 0.1490 - val_mean_absolute_error: 0.2033\n",
      "Epoch 25/300\n",
      "271/271 [==============================] - 0s 464us/step - loss: 0.1264 - mean_absolute_error: 0.1887 - val_loss: 0.1568 - val_mean_absolute_error: 0.1975\n",
      "Epoch 26/300\n",
      "271/271 [==============================] - 0s 462us/step - loss: 0.1252 - mean_absolute_error: 0.1871 - val_loss: 0.1705 - val_mean_absolute_error: 0.2264\n",
      "Epoch 27/300\n",
      "271/271 [==============================] - 0s 445us/step - loss: 0.1212 - mean_absolute_error: 0.1844 - val_loss: 0.1447 - val_mean_absolute_error: 0.1991\n",
      "Epoch 28/300\n",
      "271/271 [==============================] - 0s 447us/step - loss: 0.1201 - mean_absolute_error: 0.1852 - val_loss: 0.1596 - val_mean_absolute_error: 0.2082\n",
      "Epoch 29/300\n",
      "271/271 [==============================] - 0s 495us/step - loss: 0.1211 - mean_absolute_error: 0.1855 - val_loss: 0.1359 - val_mean_absolute_error: 0.1885\n",
      "Epoch 30/300\n",
      "271/271 [==============================] - 0s 448us/step - loss: 0.1211 - mean_absolute_error: 0.1848 - val_loss: 0.1428 - val_mean_absolute_error: 0.1995\n",
      "Epoch 31/300\n",
      "271/271 [==============================] - 0s 495us/step - loss: 0.1187 - mean_absolute_error: 0.1842 - val_loss: 0.1479 - val_mean_absolute_error: 0.1932\n",
      "Epoch 32/300\n",
      "271/271 [==============================] - 0s 515us/step - loss: 0.1197 - mean_absolute_error: 0.1852 - val_loss: 0.1413 - val_mean_absolute_error: 0.1915\n",
      "Epoch 33/300\n",
      "271/271 [==============================] - 0s 442us/step - loss: 0.1164 - mean_absolute_error: 0.1833 - val_loss: 0.1353 - val_mean_absolute_error: 0.1941\n",
      "Epoch 34/300\n",
      "271/271 [==============================] - 0s 476us/step - loss: 0.1117 - mean_absolute_error: 0.1808 - val_loss: 0.1391 - val_mean_absolute_error: 0.1963\n",
      "Epoch 35/300\n",
      "271/271 [==============================] - 0s 455us/step - loss: 0.1145 - mean_absolute_error: 0.1834 - val_loss: 0.1400 - val_mean_absolute_error: 0.1936\n",
      "Epoch 36/300\n",
      "271/271 [==============================] - 0s 459us/step - loss: 0.1160 - mean_absolute_error: 0.1829 - val_loss: 0.1412 - val_mean_absolute_error: 0.1901\n",
      "Epoch 37/300\n",
      "271/271 [==============================] - 0s 474us/step - loss: 0.1122 - mean_absolute_error: 0.1806 - val_loss: 0.1393 - val_mean_absolute_error: 0.1908\n",
      "Epoch 38/300\n",
      "271/271 [==============================] - 0s 492us/step - loss: 0.1112 - mean_absolute_error: 0.1808 - val_loss: 0.1396 - val_mean_absolute_error: 0.1934\n",
      "Epoch 39/300\n",
      "271/271 [==============================] - 0s 482us/step - loss: 0.1141 - mean_absolute_error: 0.1837 - val_loss: 0.1404 - val_mean_absolute_error: 0.1947\n",
      "Epoch 40/300\n",
      "271/271 [==============================] - 0s 471us/step - loss: 0.1126 - mean_absolute_error: 0.1824 - val_loss: 0.1512 - val_mean_absolute_error: 0.2059\n",
      "Epoch 41/300\n",
      "271/271 [==============================] - 0s 453us/step - loss: 0.1102 - mean_absolute_error: 0.1813 - val_loss: 0.1406 - val_mean_absolute_error: 0.1920\n",
      "Epoch 42/300\n",
      "271/271 [==============================] - 0s 453us/step - loss: 0.1073 - mean_absolute_error: 0.1778 - val_loss: 0.1414 - val_mean_absolute_error: 0.1968\n",
      "Epoch 43/300\n",
      "271/271 [==============================] - 0s 449us/step - loss: 0.1088 - mean_absolute_error: 0.1815 - val_loss: 0.1466 - val_mean_absolute_error: 0.1936\n",
      "Epoch 44/300\n",
      "271/271 [==============================] - 0s 485us/step - loss: 0.1087 - mean_absolute_error: 0.1793 - val_loss: 0.1280 - val_mean_absolute_error: 0.1852\n",
      "Epoch 45/300\n",
      "271/271 [==============================] - 0s 449us/step - loss: 0.1147 - mean_absolute_error: 0.1840 - val_loss: 0.1341 - val_mean_absolute_error: 0.1900\n",
      "Epoch 46/300\n",
      "271/271 [==============================] - 0s 442us/step - loss: 0.1070 - mean_absolute_error: 0.1793 - val_loss: 0.1371 - val_mean_absolute_error: 0.1994\n",
      "Epoch 47/300\n",
      "271/271 [==============================] - 0s 453us/step - loss: 0.1083 - mean_absolute_error: 0.1808 - val_loss: 0.1467 - val_mean_absolute_error: 0.2013\n",
      "Epoch 48/300\n",
      "271/271 [==============================] - 0s 449us/step - loss: 0.1058 - mean_absolute_error: 0.1783 - val_loss: 0.1522 - val_mean_absolute_error: 0.2050\n",
      "Epoch 49/300\n",
      "271/271 [==============================] - 0s 441us/step - loss: 0.1081 - mean_absolute_error: 0.1804 - val_loss: 0.1312 - val_mean_absolute_error: 0.1855\n",
      "Epoch 50/300\n",
      "271/271 [==============================] - 0s 444us/step - loss: 0.1062 - mean_absolute_error: 0.1775 - val_loss: 0.1323 - val_mean_absolute_error: 0.1881\n",
      "Epoch 51/300\n",
      "271/271 [==============================] - 0s 457us/step - loss: 0.1059 - mean_absolute_error: 0.1787 - val_loss: 0.1343 - val_mean_absolute_error: 0.1944\n",
      "Epoch 52/300\n",
      "271/271 [==============================] - 0s 438us/step - loss: 0.1025 - mean_absolute_error: 0.1766 - val_loss: 0.1314 - val_mean_absolute_error: 0.1860\n",
      "Epoch 53/300\n",
      "271/271 [==============================] - 0s 467us/step - loss: 0.1023 - mean_absolute_error: 0.1762 - val_loss: 0.1478 - val_mean_absolute_error: 0.2012\n",
      "Epoch 54/300\n",
      "271/271 [==============================] - 0s 445us/step - loss: 0.1075 - mean_absolute_error: 0.1800 - val_loss: 0.1470 - val_mean_absolute_error: 0.1942\n",
      "Epoch 55/300\n",
      "271/271 [==============================] - 0s 451us/step - loss: 0.1030 - mean_absolute_error: 0.1765 - val_loss: 0.1372 - val_mean_absolute_error: 0.1947\n",
      "Epoch 56/300\n",
      "271/271 [==============================] - 0s 446us/step - loss: 0.1037 - mean_absolute_error: 0.1777 - val_loss: 0.1380 - val_mean_absolute_error: 0.1918\n",
      "Epoch 57/300\n",
      "271/271 [==============================] - 0s 438us/step - loss: 0.1016 - mean_absolute_error: 0.1760 - val_loss: 0.1481 - val_mean_absolute_error: 0.1954\n",
      "Epoch 58/300\n",
      "271/271 [==============================] - 0s 467us/step - loss: 0.1041 - mean_absolute_error: 0.1776 - val_loss: 0.1383 - val_mean_absolute_error: 0.1946\n",
      "Epoch 59/300\n",
      "271/271 [==============================] - 0s 438us/step - loss: 0.1009 - mean_absolute_error: 0.1749 - val_loss: 0.1351 - val_mean_absolute_error: 0.1893\n",
      "Epoch 60/300\n",
      "271/271 [==============================] - 0s 445us/step - loss: 0.1019 - mean_absolute_error: 0.1770 - val_loss: 0.1439 - val_mean_absolute_error: 0.1994\n",
      "Epoch 61/300\n",
      "271/271 [==============================] - 0s 441us/step - loss: 0.0996 - mean_absolute_error: 0.1750 - val_loss: 0.1333 - val_mean_absolute_error: 0.1947\n",
      "Epoch 62/300\n",
      "271/271 [==============================] - 0s 438us/step - loss: 0.1014 - mean_absolute_error: 0.1762 - val_loss: 0.1302 - val_mean_absolute_error: 0.1866\n",
      "Epoch 63/300\n",
      "271/271 [==============================] - 0s 449us/step - loss: 0.1025 - mean_absolute_error: 0.1777 - val_loss: 0.1428 - val_mean_absolute_error: 0.1950\n",
      "Epoch 64/300\n",
      "271/271 [==============================] - 0s 442us/step - loss: 0.1038 - mean_absolute_error: 0.1773 - val_loss: 0.1342 - val_mean_absolute_error: 0.1902\n",
      "Epoch 65/300\n",
      "271/271 [==============================] - 0s 443us/step - loss: 0.0964 - mean_absolute_error: 0.1727 - val_loss: 0.1294 - val_mean_absolute_error: 0.1871\n",
      "Epoch 66/300\n",
      "271/271 [==============================] - 0s 490us/step - loss: 0.0985 - mean_absolute_error: 0.1748 - val_loss: 0.1313 - val_mean_absolute_error: 0.1841\n",
      "Epoch 67/300\n",
      "271/271 [==============================] - 0s 460us/step - loss: 0.0996 - mean_absolute_error: 0.1732 - val_loss: 0.1415 - val_mean_absolute_error: 0.1930\n",
      "Epoch 68/300\n",
      "271/271 [==============================] - 0s 511us/step - loss: 0.1014 - mean_absolute_error: 0.1757 - val_loss: 0.1414 - val_mean_absolute_error: 0.1929\n",
      "Epoch 69/300\n",
      "271/271 [==============================] - 0s 459us/step - loss: 0.0991 - mean_absolute_error: 0.1747 - val_loss: 0.1320 - val_mean_absolute_error: 0.1979\n",
      "Epoch 70/300\n",
      "271/271 [==============================] - 0s 471us/step - loss: 0.0972 - mean_absolute_error: 0.1740 - val_loss: 0.1320 - val_mean_absolute_error: 0.1898\n",
      "Epoch 71/300\n",
      "271/271 [==============================] - 0s 453us/step - loss: 0.0958 - mean_absolute_error: 0.1734 - val_loss: 0.1325 - val_mean_absolute_error: 0.1886\n",
      "Epoch 72/300\n",
      "271/271 [==============================] - 0s 471us/step - loss: 0.0954 - mean_absolute_error: 0.1732 - val_loss: 0.1337 - val_mean_absolute_error: 0.1869\n",
      "Epoch 73/300\n",
      "271/271 [==============================] - 0s 458us/step - loss: 0.0965 - mean_absolute_error: 0.1740 - val_loss: 0.1311 - val_mean_absolute_error: 0.1861\n",
      "Epoch 74/300\n",
      "271/271 [==============================] - 0s 452us/step - loss: 0.0949 - mean_absolute_error: 0.1734 - val_loss: 0.1301 - val_mean_absolute_error: 0.1911\n",
      "Epoch 75/300\n",
      "271/271 [==============================] - 0s 445us/step - loss: 0.0958 - mean_absolute_error: 0.1736 - val_loss: 0.1371 - val_mean_absolute_error: 0.1892\n",
      "Epoch 76/300\n",
      "271/271 [==============================] - 0s 453us/step - loss: 0.0980 - mean_absolute_error: 0.1744 - val_loss: 0.1283 - val_mean_absolute_error: 0.1895\n",
      "Epoch 77/300\n",
      "271/271 [==============================] - 0s 460us/step - loss: 0.0923 - mean_absolute_error: 0.1711 - val_loss: 0.1399 - val_mean_absolute_error: 0.1929\n",
      "Epoch 78/300\n",
      "271/271 [==============================] - 0s 465us/step - loss: 0.0961 - mean_absolute_error: 0.1725 - val_loss: 0.1262 - val_mean_absolute_error: 0.1867\n",
      "Epoch 79/300\n",
      "271/271 [==============================] - 0s 467us/step - loss: 0.0966 - mean_absolute_error: 0.1737 - val_loss: 0.1280 - val_mean_absolute_error: 0.1890\n",
      "Epoch 80/300\n",
      "271/271 [==============================] - 0s 460us/step - loss: 0.0947 - mean_absolute_error: 0.1721 - val_loss: 0.1315 - val_mean_absolute_error: 0.1945\n",
      "Epoch 81/300\n",
      "271/271 [==============================] - 0s 448us/step - loss: 0.0961 - mean_absolute_error: 0.1748 - val_loss: 0.1281 - val_mean_absolute_error: 0.1866\n",
      "Epoch 82/300\n",
      "271/271 [==============================] - 0s 460us/step - loss: 0.0990 - mean_absolute_error: 0.1748 - val_loss: 0.1242 - val_mean_absolute_error: 0.1849\n",
      "Epoch 83/300\n",
      "271/271 [==============================] - 0s 466us/step - loss: 0.0901 - mean_absolute_error: 0.1697 - val_loss: 0.1327 - val_mean_absolute_error: 0.1945\n",
      "Epoch 84/300\n",
      "271/271 [==============================] - 0s 461us/step - loss: 0.0941 - mean_absolute_error: 0.1708 - val_loss: 0.1309 - val_mean_absolute_error: 0.1937\n",
      "Epoch 85/300\n",
      "271/271 [==============================] - 0s 453us/step - loss: 0.0913 - mean_absolute_error: 0.1705 - val_loss: 0.1296 - val_mean_absolute_error: 0.1952\n",
      "Epoch 86/300\n",
      "271/271 [==============================] - 0s 464us/step - loss: 0.0929 - mean_absolute_error: 0.1713 - val_loss: 0.1289 - val_mean_absolute_error: 0.1909\n",
      "Epoch 87/300\n",
      "271/271 [==============================] - 0s 482us/step - loss: 0.0926 - mean_absolute_error: 0.1727 - val_loss: 0.1291 - val_mean_absolute_error: 0.1867\n",
      "Epoch 88/300\n",
      "271/271 [==============================] - 0s 483us/step - loss: 0.0897 - mean_absolute_error: 0.1693 - val_loss: 0.1270 - val_mean_absolute_error: 0.1846\n",
      "Epoch 89/300\n",
      "271/271 [==============================] - 0s 460us/step - loss: 0.0925 - mean_absolute_error: 0.1700 - val_loss: 0.1280 - val_mean_absolute_error: 0.1915\n",
      "Epoch 90/300\n",
      "271/271 [==============================] - 0s 456us/step - loss: 0.0915 - mean_absolute_error: 0.1710 - val_loss: 0.1275 - val_mean_absolute_error: 0.1912\n",
      "Epoch 91/300\n",
      "271/271 [==============================] - 0s 456us/step - loss: 0.0894 - mean_absolute_error: 0.1694 - val_loss: 0.1282 - val_mean_absolute_error: 0.1864\n",
      "Epoch 92/300\n",
      "271/271 [==============================] - 0s 464us/step - loss: 0.0969 - mean_absolute_error: 0.1757 - val_loss: 0.1255 - val_mean_absolute_error: 0.1995\n",
      "Epoch 93/300\n",
      "271/271 [==============================] - 0s 475us/step - loss: 0.0879 - mean_absolute_error: 0.1678 - val_loss: 0.1287 - val_mean_absolute_error: 0.1898\n",
      "Epoch 94/300\n",
      "271/271 [==============================] - 0s 492us/step - loss: 0.0890 - mean_absolute_error: 0.1695 - val_loss: 0.1387 - val_mean_absolute_error: 0.1933\n",
      "Epoch 95/300\n",
      "271/271 [==============================] - 0s 491us/step - loss: 0.0902 - mean_absolute_error: 0.1696 - val_loss: 0.1313 - val_mean_absolute_error: 0.1870\n",
      "Epoch 96/300\n",
      "271/271 [==============================] - 0s 492us/step - loss: 0.0880 - mean_absolute_error: 0.1686 - val_loss: 0.1249 - val_mean_absolute_error: 0.1871\n",
      "Epoch 97/300\n",
      "271/271 [==============================] - 0s 528us/step - loss: 0.0912 - mean_absolute_error: 0.1704 - val_loss: 0.1269 - val_mean_absolute_error: 0.1838\n",
      "Epoch 98/300\n",
      "271/271 [==============================] - 0s 455us/step - loss: 0.0877 - mean_absolute_error: 0.1693 - val_loss: 0.1320 - val_mean_absolute_error: 0.1903\n",
      "Epoch 99/300\n",
      "271/271 [==============================] - 0s 459us/step - loss: 0.0941 - mean_absolute_error: 0.1738 - val_loss: 0.1263 - val_mean_absolute_error: 0.1864\n",
      "Epoch 100/300\n",
      "271/271 [==============================] - 0s 497us/step - loss: 0.0904 - mean_absolute_error: 0.1703 - val_loss: 0.1271 - val_mean_absolute_error: 0.1887\n",
      "Epoch 101/300\n",
      "271/271 [==============================] - 0s 512us/step - loss: 0.0879 - mean_absolute_error: 0.1697 - val_loss: 0.1231 - val_mean_absolute_error: 0.1938\n",
      "Epoch 102/300\n",
      "271/271 [==============================] - 0s 504us/step - loss: 0.0884 - mean_absolute_error: 0.1683 - val_loss: 0.1245 - val_mean_absolute_error: 0.1896\n",
      "Epoch 103/300\n",
      "271/271 [==============================] - 0s 507us/step - loss: 0.0877 - mean_absolute_error: 0.1686 - val_loss: 0.1231 - val_mean_absolute_error: 0.1874\n",
      "Epoch 104/300\n",
      "271/271 [==============================] - 0s 490us/step - loss: 0.0879 - mean_absolute_error: 0.1675 - val_loss: 0.1263 - val_mean_absolute_error: 0.1858\n",
      "Epoch 105/300\n",
      "271/271 [==============================] - 0s 456us/step - loss: 0.0887 - mean_absolute_error: 0.1702 - val_loss: 0.1212 - val_mean_absolute_error: 0.1876\n",
      "Epoch 106/300\n",
      "271/271 [==============================] - 0s 508us/step - loss: 0.0861 - mean_absolute_error: 0.1678 - val_loss: 0.1235 - val_mean_absolute_error: 0.1836\n",
      "Epoch 107/300\n",
      "271/271 [==============================] - 0s 504us/step - loss: 0.0887 - mean_absolute_error: 0.1698 - val_loss: 0.1270 - val_mean_absolute_error: 0.1866\n",
      "Epoch 108/300\n",
      "271/271 [==============================] - 0s 455us/step - loss: 0.0903 - mean_absolute_error: 0.1707 - val_loss: 0.1194 - val_mean_absolute_error: 0.1850\n",
      "Epoch 109/300\n",
      "271/271 [==============================] - 0s 493us/step - loss: 0.0856 - mean_absolute_error: 0.1666 - val_loss: 0.1266 - val_mean_absolute_error: 0.1861\n",
      "Epoch 110/300\n",
      "271/271 [==============================] - 0s 473us/step - loss: 0.0861 - mean_absolute_error: 0.1678 - val_loss: 0.1226 - val_mean_absolute_error: 0.1896\n",
      "Epoch 111/300\n",
      "271/271 [==============================] - 0s 453us/step - loss: 0.0895 - mean_absolute_error: 0.1703 - val_loss: 0.1314 - val_mean_absolute_error: 0.1894\n",
      "Epoch 112/300\n",
      "271/271 [==============================] - 0s 447us/step - loss: 0.0874 - mean_absolute_error: 0.1682 - val_loss: 0.1260 - val_mean_absolute_error: 0.1874\n",
      "Epoch 113/300\n",
      "271/271 [==============================] - 0s 444us/step - loss: 0.0852 - mean_absolute_error: 0.1677 - val_loss: 0.1262 - val_mean_absolute_error: 0.1859\n",
      "Epoch 114/300\n",
      "271/271 [==============================] - 0s 456us/step - loss: 0.0861 - mean_absolute_error: 0.1682 - val_loss: 0.1268 - val_mean_absolute_error: 0.1845\n",
      "Epoch 115/300\n",
      "271/271 [==============================] - 0s 467us/step - loss: 0.0877 - mean_absolute_error: 0.1682 - val_loss: 0.1254 - val_mean_absolute_error: 0.1873\n",
      "Epoch 116/300\n",
      "271/271 [==============================] - 0s 456us/step - loss: 0.0881 - mean_absolute_error: 0.1695 - val_loss: 0.1298 - val_mean_absolute_error: 0.1870\n",
      "Epoch 117/300\n",
      "271/271 [==============================] - 0s 467us/step - loss: 0.0870 - mean_absolute_error: 0.1686 - val_loss: 0.1201 - val_mean_absolute_error: 0.1865\n",
      "Epoch 118/300\n",
      "271/271 [==============================] - 0s 471us/step - loss: 0.0858 - mean_absolute_error: 0.1681 - val_loss: 0.1186 - val_mean_absolute_error: 0.1868\n",
      "Epoch 119/300\n",
      "271/271 [==============================] - 0s 593us/step - loss: 0.0842 - mean_absolute_error: 0.1665 - val_loss: 0.1339 - val_mean_absolute_error: 0.1998\n",
      "Epoch 120/300\n",
      "271/271 [==============================] - 0s 482us/step - loss: 0.0879 - mean_absolute_error: 0.1686 - val_loss: 0.1402 - val_mean_absolute_error: 0.1973\n",
      "Epoch 121/300\n",
      "271/271 [==============================] - 0s 477us/step - loss: 0.0882 - mean_absolute_error: 0.1689 - val_loss: 0.1364 - val_mean_absolute_error: 0.1911\n",
      "Epoch 122/300\n",
      "271/271 [==============================] - 0s 486us/step - loss: 0.0851 - mean_absolute_error: 0.1667 - val_loss: 0.1255 - val_mean_absolute_error: 0.1864\n",
      "Epoch 123/300\n",
      "271/271 [==============================] - 0s 486us/step - loss: 0.0861 - mean_absolute_error: 0.1676 - val_loss: 0.1253 - val_mean_absolute_error: 0.1855\n",
      "Epoch 124/300\n",
      "271/271 [==============================] - 0s 481us/step - loss: 0.0870 - mean_absolute_error: 0.1681 - val_loss: 0.1215 - val_mean_absolute_error: 0.1863\n",
      "Epoch 125/300\n",
      "271/271 [==============================] - 0s 501us/step - loss: 0.0840 - mean_absolute_error: 0.1665 - val_loss: 0.1222 - val_mean_absolute_error: 0.1847\n",
      "Epoch 126/300\n",
      "271/271 [==============================] - 0s 540us/step - loss: 0.0866 - mean_absolute_error: 0.1688 - val_loss: 0.1195 - val_mean_absolute_error: 0.1835\n",
      "Epoch 127/300\n",
      "271/271 [==============================] - 0s 544us/step - loss: 0.0842 - mean_absolute_error: 0.1658 - val_loss: 0.1231 - val_mean_absolute_error: 0.1833\n",
      "Epoch 128/300\n",
      "271/271 [==============================] - 0s 493us/step - loss: 0.0863 - mean_absolute_error: 0.1676 - val_loss: 0.1298 - val_mean_absolute_error: 0.1870\n",
      "Epoch 129/300\n",
      "271/271 [==============================] - 0s 452us/step - loss: 0.0838 - mean_absolute_error: 0.1653 - val_loss: 0.1245 - val_mean_absolute_error: 0.1847\n",
      "Epoch 130/300\n",
      "271/271 [==============================] - 0s 471us/step - loss: 0.0834 - mean_absolute_error: 0.1658 - val_loss: 0.1255 - val_mean_absolute_error: 0.1865\n",
      "Epoch 131/300\n",
      "271/271 [==============================] - 0s 486us/step - loss: 0.0843 - mean_absolute_error: 0.1667 - val_loss: 0.1233 - val_mean_absolute_error: 0.1851\n",
      "Epoch 132/300\n",
      "271/271 [==============================] - 0s 471us/step - loss: 0.0890 - mean_absolute_error: 0.1679 - val_loss: 0.1401 - val_mean_absolute_error: 0.1941\n",
      "Epoch 133/300\n",
      "271/271 [==============================] - 0s 563us/step - loss: 0.0867 - mean_absolute_error: 0.1672 - val_loss: 0.1334 - val_mean_absolute_error: 0.1887\n",
      "Epoch 134/300\n",
      "271/271 [==============================] - 0s 515us/step - loss: 0.0810 - mean_absolute_error: 0.1637 - val_loss: 0.1205 - val_mean_absolute_error: 0.1836\n",
      "Epoch 135/300\n",
      "271/271 [==============================] - 0s 623us/step - loss: 0.0811 - mean_absolute_error: 0.1635 - val_loss: 0.1173 - val_mean_absolute_error: 0.1820\n",
      "Epoch 136/300\n",
      "271/271 [==============================] - 0s 455us/step - loss: 0.0814 - mean_absolute_error: 0.1649 - val_loss: 0.1183 - val_mean_absolute_error: 0.1827\n",
      "Epoch 137/300\n",
      "271/271 [==============================] - 0s 471us/step - loss: 0.0826 - mean_absolute_error: 0.1654 - val_loss: 0.1266 - val_mean_absolute_error: 0.1895\n",
      "Epoch 138/300\n",
      "271/271 [==============================] - 0s 476us/step - loss: 0.0859 - mean_absolute_error: 0.1681 - val_loss: 0.1302 - val_mean_absolute_error: 0.1859\n",
      "Epoch 139/300\n",
      "271/271 [==============================] - 0s 468us/step - loss: 0.0858 - mean_absolute_error: 0.1673 - val_loss: 0.1267 - val_mean_absolute_error: 0.1865\n",
      "Epoch 140/300\n",
      "271/271 [==============================] - 0s 458us/step - loss: 0.0856 - mean_absolute_error: 0.1672 - val_loss: 0.1348 - val_mean_absolute_error: 0.1966\n",
      "Epoch 141/300\n",
      "271/271 [==============================] - 0s 459us/step - loss: 0.0908 - mean_absolute_error: 0.1707 - val_loss: 0.1235 - val_mean_absolute_error: 0.1883\n",
      "Epoch 142/300\n",
      "271/271 [==============================] - 0s 449us/step - loss: 0.0815 - mean_absolute_error: 0.1638 - val_loss: 0.1242 - val_mean_absolute_error: 0.1848\n",
      "Epoch 143/300\n",
      "271/271 [==============================] - 0s 438us/step - loss: 0.0825 - mean_absolute_error: 0.1641 - val_loss: 0.1244 - val_mean_absolute_error: 0.1895\n",
      "Epoch 144/300\n",
      "271/271 [==============================] - 0s 442us/step - loss: 0.0848 - mean_absolute_error: 0.1669 - val_loss: 0.1310 - val_mean_absolute_error: 0.1857\n",
      "Epoch 145/300\n",
      "271/271 [==============================] - 0s 460us/step - loss: 0.0815 - mean_absolute_error: 0.1640 - val_loss: 0.1290 - val_mean_absolute_error: 0.1873\n",
      "Epoch 146/300\n",
      "271/271 [==============================] - 0s 482us/step - loss: 0.0819 - mean_absolute_error: 0.1647 - val_loss: 0.1359 - val_mean_absolute_error: 0.1927\n",
      "Epoch 147/300\n",
      "271/271 [==============================] - 0s 493us/step - loss: 0.0813 - mean_absolute_error: 0.1634 - val_loss: 0.1256 - val_mean_absolute_error: 0.1879\n",
      "Epoch 148/300\n",
      "271/271 [==============================] - 0s 461us/step - loss: 0.0805 - mean_absolute_error: 0.1646 - val_loss: 0.1383 - val_mean_absolute_error: 0.1885\n",
      "Epoch 149/300\n",
      "271/271 [==============================] - 0s 523us/step - loss: 0.0864 - mean_absolute_error: 0.1667 - val_loss: 0.1325 - val_mean_absolute_error: 0.1906\n",
      "Epoch 150/300\n",
      "271/271 [==============================] - 0s 460us/step - loss: 0.0844 - mean_absolute_error: 0.1670 - val_loss: 0.1522 - val_mean_absolute_error: 0.2017\n",
      "Epoch 151/300\n",
      "271/271 [==============================] - 0s 521us/step - loss: 0.0906 - mean_absolute_error: 0.1729 - val_loss: 0.1265 - val_mean_absolute_error: 0.1891\n",
      "Epoch 152/300\n",
      "271/271 [==============================] - 0s 497us/step - loss: 0.0822 - mean_absolute_error: 0.1640 - val_loss: 0.1370 - val_mean_absolute_error: 0.1994\n",
      "Epoch 153/300\n",
      "271/271 [==============================] - 0s 494us/step - loss: 0.0872 - mean_absolute_error: 0.1678 - val_loss: 0.1283 - val_mean_absolute_error: 0.1883\n",
      "Epoch 154/300\n",
      "271/271 [==============================] - 0s 462us/step - loss: 0.0813 - mean_absolute_error: 0.1639 - val_loss: 0.1259 - val_mean_absolute_error: 0.1853\n",
      "Epoch 155/300\n",
      "271/271 [==============================] - 0s 448us/step - loss: 0.0844 - mean_absolute_error: 0.1661 - val_loss: 0.1224 - val_mean_absolute_error: 0.1900\n",
      "Epoch 156/300\n",
      "271/271 [==============================] - 0s 464us/step - loss: 0.0832 - mean_absolute_error: 0.1656 - val_loss: 0.1179 - val_mean_absolute_error: 0.1844\n",
      "Epoch 157/300\n",
      "271/271 [==============================] - 0s 449us/step - loss: 0.0819 - mean_absolute_error: 0.1644 - val_loss: 0.1413 - val_mean_absolute_error: 0.1967\n",
      "Epoch 158/300\n",
      "271/271 [==============================] - 0s 447us/step - loss: 0.0817 - mean_absolute_error: 0.1647 - val_loss: 0.1257 - val_mean_absolute_error: 0.1864\n",
      "Epoch 159/300\n",
      "271/271 [==============================] - 0s 450us/step - loss: 0.0840 - mean_absolute_error: 0.1654 - val_loss: 0.1217 - val_mean_absolute_error: 0.1850\n",
      "Epoch 160/300\n",
      "271/271 [==============================] - 0s 453us/step - loss: 0.0807 - mean_absolute_error: 0.1637 - val_loss: 0.1184 - val_mean_absolute_error: 0.1836\n",
      "Epoch 161/300\n",
      "271/271 [==============================] - 0s 445us/step - loss: 0.0805 - mean_absolute_error: 0.1630 - val_loss: 0.1231 - val_mean_absolute_error: 0.1879\n",
      "Epoch 162/300\n",
      "271/271 [==============================] - 0s 468us/step - loss: 0.0815 - mean_absolute_error: 0.1651 - val_loss: 0.1240 - val_mean_absolute_error: 0.1841\n",
      "Epoch 163/300\n",
      "271/271 [==============================] - 0s 456us/step - loss: 0.0850 - mean_absolute_error: 0.1671 - val_loss: 0.1239 - val_mean_absolute_error: 0.1894\n",
      "Epoch 164/300\n",
      "271/271 [==============================] - 0s 449us/step - loss: 0.0851 - mean_absolute_error: 0.1678 - val_loss: 0.1298 - val_mean_absolute_error: 0.1906\n",
      "Epoch 165/300\n",
      "271/271 [==============================] - 0s 451us/step - loss: 0.0822 - mean_absolute_error: 0.1649 - val_loss: 0.1391 - val_mean_absolute_error: 0.1918\n",
      "Epoch 166/300\n",
      "271/271 [==============================] - 0s 460us/step - loss: 0.0795 - mean_absolute_error: 0.1631 - val_loss: 0.1161 - val_mean_absolute_error: 0.1820\n",
      "Epoch 167/300\n",
      "271/271 [==============================] - 0s 459us/step - loss: 0.0794 - mean_absolute_error: 0.1633 - val_loss: 0.1247 - val_mean_absolute_error: 0.1858\n",
      "Epoch 168/300\n",
      "271/271 [==============================] - 0s 445us/step - loss: 0.0803 - mean_absolute_error: 0.1630 - val_loss: 0.1215 - val_mean_absolute_error: 0.1880\n",
      "Epoch 169/300\n",
      "271/271 [==============================] - 0s 497us/step - loss: 0.0840 - mean_absolute_error: 0.1663 - val_loss: 0.1160 - val_mean_absolute_error: 0.1776\n",
      "Epoch 170/300\n",
      "271/271 [==============================] - 0s 448us/step - loss: 0.0837 - mean_absolute_error: 0.1663 - val_loss: 0.1198 - val_mean_absolute_error: 0.1867\n",
      "Epoch 171/300\n",
      "271/271 [==============================] - 0s 455us/step - loss: 0.0808 - mean_absolute_error: 0.1644 - val_loss: 0.1218 - val_mean_absolute_error: 0.1853\n",
      "Epoch 172/300\n",
      "271/271 [==============================] - 0s 456us/step - loss: 0.0890 - mean_absolute_error: 0.1706 - val_loss: 0.1238 - val_mean_absolute_error: 0.1872\n",
      "Epoch 173/300\n",
      "271/271 [==============================] - 0s 457us/step - loss: 0.0825 - mean_absolute_error: 0.1656 - val_loss: 0.1189 - val_mean_absolute_error: 0.1821\n",
      "Epoch 174/300\n",
      "271/271 [==============================] - 0s 449us/step - loss: 0.0819 - mean_absolute_error: 0.1644 - val_loss: 0.1241 - val_mean_absolute_error: 0.1858\n",
      "Epoch 175/300\n",
      "271/271 [==============================] - 0s 456us/step - loss: 0.0785 - mean_absolute_error: 0.1624 - val_loss: 0.1181 - val_mean_absolute_error: 0.1848\n",
      "Epoch 176/300\n",
      "271/271 [==============================] - 0s 467us/step - loss: 0.0808 - mean_absolute_error: 0.1638 - val_loss: 0.1204 - val_mean_absolute_error: 0.1810\n",
      "Epoch 177/300\n",
      "271/271 [==============================] - 0s 482us/step - loss: 0.0828 - mean_absolute_error: 0.1656 - val_loss: 0.1170 - val_mean_absolute_error: 0.1848\n",
      "Epoch 178/300\n",
      "271/271 [==============================] - 0s 467us/step - loss: 0.0782 - mean_absolute_error: 0.1622 - val_loss: 0.1237 - val_mean_absolute_error: 0.1887\n",
      "Epoch 179/300\n",
      "271/271 [==============================] - 0s 449us/step - loss: 0.0954 - mean_absolute_error: 0.1724 - val_loss: 0.1196 - val_mean_absolute_error: 0.1892\n",
      "Epoch 180/300\n",
      "271/271 [==============================] - 0s 467us/step - loss: 0.0831 - mean_absolute_error: 0.1649 - val_loss: 0.1239 - val_mean_absolute_error: 0.1849\n",
      "Epoch 181/300\n",
      "271/271 [==============================] - 0s 477us/step - loss: 0.0778 - mean_absolute_error: 0.1617 - val_loss: 0.1250 - val_mean_absolute_error: 0.1824\n",
      "Epoch 182/300\n",
      "271/271 [==============================] - 0s 476us/step - loss: 0.0798 - mean_absolute_error: 0.1647 - val_loss: 0.1188 - val_mean_absolute_error: 0.1901\n",
      "Epoch 183/300\n",
      "271/271 [==============================] - 0s 475us/step - loss: 0.0809 - mean_absolute_error: 0.1634 - val_loss: 0.1216 - val_mean_absolute_error: 0.1820\n",
      "Epoch 184/300\n",
      "271/271 [==============================] - 0s 463us/step - loss: 0.0799 - mean_absolute_error: 0.1624 - val_loss: 0.1203 - val_mean_absolute_error: 0.1822\n",
      "Epoch 185/300\n",
      "271/271 [==============================] - 0s 456us/step - loss: 0.0780 - mean_absolute_error: 0.1624 - val_loss: 0.1258 - val_mean_absolute_error: 0.1873\n",
      "Epoch 186/300\n",
      "271/271 [==============================] - 0s 471us/step - loss: 0.0835 - mean_absolute_error: 0.1651 - val_loss: 0.1177 - val_mean_absolute_error: 0.1845\n",
      "Epoch 187/300\n",
      "271/271 [==============================] - 0s 467us/step - loss: 0.0819 - mean_absolute_error: 0.1642 - val_loss: 0.1473 - val_mean_absolute_error: 0.1920\n",
      "Epoch 188/300\n",
      "271/271 [==============================] - 0s 464us/step - loss: 0.0846 - mean_absolute_error: 0.1659 - val_loss: 0.1259 - val_mean_absolute_error: 0.1883\n",
      "Epoch 189/300\n",
      "271/271 [==============================] - 0s 471us/step - loss: 0.0797 - mean_absolute_error: 0.1632 - val_loss: 0.1305 - val_mean_absolute_error: 0.1889\n",
      "Epoch 190/300\n",
      "271/271 [==============================] - 0s 467us/step - loss: 0.0842 - mean_absolute_error: 0.1663 - val_loss: 0.1168 - val_mean_absolute_error: 0.1810\n",
      "Epoch 191/300\n",
      "271/271 [==============================] - 0s 471us/step - loss: 0.0808 - mean_absolute_error: 0.1641 - val_loss: 0.1193 - val_mean_absolute_error: 0.1808\n",
      "Epoch 192/300\n",
      "271/271 [==============================] - 0s 449us/step - loss: 0.0783 - mean_absolute_error: 0.1620 - val_loss: 0.1283 - val_mean_absolute_error: 0.1850\n",
      "Epoch 193/300\n",
      "271/271 [==============================] - 0s 460us/step - loss: 0.0777 - mean_absolute_error: 0.1621 - val_loss: 0.1272 - val_mean_absolute_error: 0.1879\n",
      "Epoch 194/300\n",
      "271/271 [==============================] - 0s 453us/step - loss: 0.0777 - mean_absolute_error: 0.1628 - val_loss: 0.1234 - val_mean_absolute_error: 0.1896\n",
      "Epoch 195/300\n",
      "271/271 [==============================] - 0s 448us/step - loss: 0.0852 - mean_absolute_error: 0.1674 - val_loss: 0.1218 - val_mean_absolute_error: 0.1850\n",
      "Epoch 196/300\n",
      "271/271 [==============================] - 0s 451us/step - loss: 0.0815 - mean_absolute_error: 0.1649 - val_loss: 0.1222 - val_mean_absolute_error: 0.1839\n",
      "Epoch 197/300\n",
      "271/271 [==============================] - 0s 480us/step - loss: 0.0797 - mean_absolute_error: 0.1644 - val_loss: 0.1163 - val_mean_absolute_error: 0.1801\n",
      "Epoch 198/300\n",
      "271/271 [==============================] - 0s 519us/step - loss: 0.0805 - mean_absolute_error: 0.1626 - val_loss: 0.1265 - val_mean_absolute_error: 0.1851\n",
      "Epoch 199/300\n",
      "271/271 [==============================] - 0s 500us/step - loss: 0.0821 - mean_absolute_error: 0.1661 - val_loss: 0.1310 - val_mean_absolute_error: 0.2008\n",
      "Epoch 200/300\n",
      "271/271 [==============================] - 0s 501us/step - loss: 0.0849 - mean_absolute_error: 0.1672 - val_loss: 0.1151 - val_mean_absolute_error: 0.1806\n",
      "Epoch 201/300\n",
      "271/271 [==============================] - 0s 467us/step - loss: 0.0822 - mean_absolute_error: 0.1647 - val_loss: 0.1218 - val_mean_absolute_error: 0.1830\n",
      "Epoch 202/300\n",
      "271/271 [==============================] - 0s 512us/step - loss: 0.0778 - mean_absolute_error: 0.1625 - val_loss: 0.1220 - val_mean_absolute_error: 0.1832\n",
      "Epoch 203/300\n",
      "271/271 [==============================] - 0s 475us/step - loss: 0.0778 - mean_absolute_error: 0.1623 - val_loss: 0.1181 - val_mean_absolute_error: 0.1863\n",
      "Epoch 204/300\n",
      "271/271 [==============================] - 0s 449us/step - loss: 0.0824 - mean_absolute_error: 0.1648 - val_loss: 0.1643 - val_mean_absolute_error: 0.2033\n",
      "Epoch 205/300\n",
      "271/271 [==============================] - 0s 456us/step - loss: 0.0787 - mean_absolute_error: 0.1636 - val_loss: 0.1208 - val_mean_absolute_error: 0.1898\n",
      "Epoch 206/300\n",
      "271/271 [==============================] - 0s 541us/step - loss: 0.0797 - mean_absolute_error: 0.1635 - val_loss: 0.1139 - val_mean_absolute_error: 0.1869\n",
      "Epoch 207/300\n",
      "271/271 [==============================] - 0s 464us/step - loss: 0.0776 - mean_absolute_error: 0.1626 - val_loss: 0.1214 - val_mean_absolute_error: 0.1841\n",
      "Epoch 208/300\n",
      "271/271 [==============================] - 0s 479us/step - loss: 0.0814 - mean_absolute_error: 0.1653 - val_loss: 0.1179 - val_mean_absolute_error: 0.1848\n",
      "Epoch 209/300\n",
      "271/271 [==============================] - 0s 478us/step - loss: 0.0799 - mean_absolute_error: 0.1649 - val_loss: 0.1246 - val_mean_absolute_error: 0.1853\n",
      "Epoch 210/300\n",
      "271/271 [==============================] - 0s 475us/step - loss: 0.0815 - mean_absolute_error: 0.1645 - val_loss: 0.1364 - val_mean_absolute_error: 0.1933\n",
      "Epoch 211/300\n",
      "271/271 [==============================] - 0s 477us/step - loss: 0.0852 - mean_absolute_error: 0.1668 - val_loss: 0.1264 - val_mean_absolute_error: 0.1865\n",
      "Epoch 212/300\n",
      "271/271 [==============================] - 0s 475us/step - loss: 0.0793 - mean_absolute_error: 0.1622 - val_loss: 0.1261 - val_mean_absolute_error: 0.1885\n",
      "Epoch 213/300\n",
      "271/271 [==============================] - 0s 530us/step - loss: 0.0789 - mean_absolute_error: 0.1636 - val_loss: 0.1228 - val_mean_absolute_error: 0.1826\n",
      "Epoch 214/300\n",
      "271/271 [==============================] - 0s 466us/step - loss: 0.0898 - mean_absolute_error: 0.1687 - val_loss: 0.1307 - val_mean_absolute_error: 0.1891\n",
      "Epoch 215/300\n",
      "271/271 [==============================] - 0s 467us/step - loss: 0.0790 - mean_absolute_error: 0.1629 - val_loss: 0.1166 - val_mean_absolute_error: 0.1826\n",
      "Epoch 216/300\n",
      "271/271 [==============================] - 0s 453us/step - loss: 0.0787 - mean_absolute_error: 0.1622 - val_loss: 0.1216 - val_mean_absolute_error: 0.1858\n",
      "Epoch 217/300\n",
      "271/271 [==============================] - 0s 464us/step - loss: 0.0787 - mean_absolute_error: 0.1631 - val_loss: 0.1232 - val_mean_absolute_error: 0.1865\n",
      "Epoch 218/300\n",
      "271/271 [==============================] - 0s 491us/step - loss: 0.0769 - mean_absolute_error: 0.1626 - val_loss: 0.1159 - val_mean_absolute_error: 0.1817\n",
      "Epoch 219/300\n",
      "271/271 [==============================] - 0s 467us/step - loss: 0.0851 - mean_absolute_error: 0.1675 - val_loss: 0.1178 - val_mean_absolute_error: 0.1795\n",
      "Epoch 220/300\n",
      "271/271 [==============================] - 0s 469us/step - loss: 0.0826 - mean_absolute_error: 0.1656 - val_loss: 0.1237 - val_mean_absolute_error: 0.1921\n",
      "Epoch 221/300\n",
      "271/271 [==============================] - 0s 451us/step - loss: 0.0792 - mean_absolute_error: 0.1635 - val_loss: 0.1222 - val_mean_absolute_error: 0.1848\n",
      "Epoch 222/300\n",
      "271/271 [==============================] - 0s 449us/step - loss: 0.0791 - mean_absolute_error: 0.1626 - val_loss: 0.1178 - val_mean_absolute_error: 0.1836\n",
      "Epoch 223/300\n",
      "271/271 [==============================] - 0s 442us/step - loss: 0.0795 - mean_absolute_error: 0.1623 - val_loss: 0.1220 - val_mean_absolute_error: 0.1855\n",
      "Epoch 224/300\n",
      "271/271 [==============================] - 0s 442us/step - loss: 0.0766 - mean_absolute_error: 0.1616 - val_loss: 0.1244 - val_mean_absolute_error: 0.1863\n",
      "Epoch 225/300\n",
      "271/271 [==============================] - 0s 440us/step - loss: 0.0771 - mean_absolute_error: 0.1620 - val_loss: 0.1163 - val_mean_absolute_error: 0.1827\n",
      "Epoch 226/300\n",
      "271/271 [==============================] - 0s 442us/step - loss: 0.0926 - mean_absolute_error: 0.1704 - val_loss: 0.1311 - val_mean_absolute_error: 0.1898\n",
      "Epoch 227/300\n",
      "271/271 [==============================] - 0s 449us/step - loss: 0.0865 - mean_absolute_error: 0.1693 - val_loss: 0.1242 - val_mean_absolute_error: 0.1887\n",
      "Epoch 228/300\n",
      "271/271 [==============================] - 0s 466us/step - loss: 0.0885 - mean_absolute_error: 0.1707 - val_loss: 0.1207 - val_mean_absolute_error: 0.1815\n",
      "Epoch 229/300\n",
      "271/271 [==============================] - 0s 466us/step - loss: 0.0778 - mean_absolute_error: 0.1621 - val_loss: 0.1163 - val_mean_absolute_error: 0.1821\n",
      "Epoch 230/300\n",
      "271/271 [==============================] - 0s 464us/step - loss: 0.0762 - mean_absolute_error: 0.1605 - val_loss: 0.1177 - val_mean_absolute_error: 0.1812\n",
      "Epoch 231/300\n",
      "271/271 [==============================] - 0s 453us/step - loss: 0.0756 - mean_absolute_error: 0.1613 - val_loss: 0.1224 - val_mean_absolute_error: 0.1885\n",
      "Epoch 232/300\n",
      "271/271 [==============================] - 0s 475us/step - loss: 0.0769 - mean_absolute_error: 0.1621 - val_loss: 0.1204 - val_mean_absolute_error: 0.1816\n",
      "Epoch 233/300\n",
      "271/271 [==============================] - 0s 467us/step - loss: 0.0758 - mean_absolute_error: 0.1606 - val_loss: 0.1230 - val_mean_absolute_error: 0.1868\n",
      "Epoch 234/300\n",
      "271/271 [==============================] - 0s 452us/step - loss: 0.0773 - mean_absolute_error: 0.1627 - val_loss: 0.1274 - val_mean_absolute_error: 0.1842\n",
      "Epoch 235/300\n",
      "271/271 [==============================] - 0s 458us/step - loss: 0.1190 - mean_absolute_error: 0.1899 - val_loss: 0.1219 - val_mean_absolute_error: 0.1830\n",
      "Epoch 236/300\n",
      "271/271 [==============================] - 0s 444us/step - loss: 0.0820 - mean_absolute_error: 0.1656 - val_loss: 0.1169 - val_mean_absolute_error: 0.1802\n",
      "Epoch 237/300\n",
      "271/271 [==============================] - 0s 448us/step - loss: 0.0765 - mean_absolute_error: 0.1608 - val_loss: 0.1176 - val_mean_absolute_error: 0.1813\n",
      "Epoch 238/300\n",
      "271/271 [==============================] - 0s 448us/step - loss: 0.0787 - mean_absolute_error: 0.1625 - val_loss: 0.1266 - val_mean_absolute_error: 0.1832\n",
      "Epoch 239/300\n",
      "271/271 [==============================] - 0s 453us/step - loss: 0.0767 - mean_absolute_error: 0.1617 - val_loss: 0.1213 - val_mean_absolute_error: 0.1830\n",
      "Epoch 240/300\n",
      "271/271 [==============================] - 0s 454us/step - loss: 0.0843 - mean_absolute_error: 0.1666 - val_loss: 0.1347 - val_mean_absolute_error: 0.1944\n",
      "Epoch 241/300\n",
      "271/271 [==============================] - 0s 451us/step - loss: 0.0793 - mean_absolute_error: 0.1632 - val_loss: 0.1166 - val_mean_absolute_error: 0.1820\n",
      "Epoch 242/300\n",
      "271/271 [==============================] - 0s 446us/step - loss: 0.0790 - mean_absolute_error: 0.1627 - val_loss: 0.1183 - val_mean_absolute_error: 0.1803\n",
      "Epoch 243/300\n",
      "271/271 [==============================] - 0s 447us/step - loss: 0.0774 - mean_absolute_error: 0.1611 - val_loss: 0.1297 - val_mean_absolute_error: 0.1896\n",
      "Epoch 244/300\n",
      "271/271 [==============================] - 0s 442us/step - loss: 0.0774 - mean_absolute_error: 0.1623 - val_loss: 0.1250 - val_mean_absolute_error: 0.1890\n",
      "Epoch 245/300\n",
      "271/271 [==============================] - 0s 449us/step - loss: 0.0780 - mean_absolute_error: 0.1621 - val_loss: 0.1222 - val_mean_absolute_error: 0.1842\n",
      "Epoch 246/300\n",
      "271/271 [==============================] - 0s 442us/step - loss: 0.0762 - mean_absolute_error: 0.1616 - val_loss: 0.1143 - val_mean_absolute_error: 0.1789\n",
      "Epoch 247/300\n",
      "271/271 [==============================] - 0s 438us/step - loss: 0.0761 - mean_absolute_error: 0.1613 - val_loss: 0.1257 - val_mean_absolute_error: 0.1840\n",
      "Epoch 248/300\n",
      "271/271 [==============================] - 0s 438us/step - loss: 0.0797 - mean_absolute_error: 0.1641 - val_loss: 0.1227 - val_mean_absolute_error: 0.1870\n",
      "Epoch 249/300\n",
      "271/271 [==============================] - 0s 438us/step - loss: 0.0908 - mean_absolute_error: 0.1699 - val_loss: 0.1239 - val_mean_absolute_error: 0.1831\n",
      "Epoch 250/300\n",
      "271/271 [==============================] - 0s 449us/step - loss: 0.0791 - mean_absolute_error: 0.1629 - val_loss: 0.1213 - val_mean_absolute_error: 0.1891\n",
      "Epoch 251/300\n",
      "271/271 [==============================] - 0s 475us/step - loss: 0.0754 - mean_absolute_error: 0.1613 - val_loss: 0.1183 - val_mean_absolute_error: 0.1835\n",
      "Epoch 252/300\n",
      "271/271 [==============================] - 0s 462us/step - loss: 0.0766 - mean_absolute_error: 0.1611 - val_loss: 0.1307 - val_mean_absolute_error: 0.1924\n",
      "Epoch 253/300\n",
      "271/271 [==============================] - 0s 467us/step - loss: 0.0803 - mean_absolute_error: 0.1636 - val_loss: 0.1209 - val_mean_absolute_error: 0.1826\n",
      "Epoch 254/300\n",
      "271/271 [==============================] - 0s 462us/step - loss: 0.0752 - mean_absolute_error: 0.1596 - val_loss: 0.1196 - val_mean_absolute_error: 0.1822\n",
      "Epoch 255/300\n",
      "271/271 [==============================] - 0s 453us/step - loss: 0.0763 - mean_absolute_error: 0.1607 - val_loss: 0.1229 - val_mean_absolute_error: 0.1839\n",
      "Epoch 256/300\n",
      "271/271 [==============================] - 0s 453us/step - loss: 0.0800 - mean_absolute_error: 0.1635 - val_loss: 0.1294 - val_mean_absolute_error: 0.1918\n",
      "Epoch 257/300\n",
      "271/271 [==============================] - 0s 600us/step - loss: 0.0783 - mean_absolute_error: 0.1632 - val_loss: 0.1231 - val_mean_absolute_error: 0.1834\n",
      "Epoch 258/300\n",
      "271/271 [==============================] - 0s 456us/step - loss: 0.0768 - mean_absolute_error: 0.1616 - val_loss: 0.1220 - val_mean_absolute_error: 0.1815\n",
      "Epoch 259/300\n",
      "271/271 [==============================] - 0s 461us/step - loss: 0.0780 - mean_absolute_error: 0.1619 - val_loss: 0.1180 - val_mean_absolute_error: 0.1847\n",
      "Epoch 260/300\n",
      "271/271 [==============================] - 0s 447us/step - loss: 0.0823 - mean_absolute_error: 0.1644 - val_loss: 0.1174 - val_mean_absolute_error: 0.1848\n",
      "Epoch 261/300\n",
      "271/271 [==============================] - 0s 448us/step - loss: 0.0763 - mean_absolute_error: 0.1620 - val_loss: 0.1277 - val_mean_absolute_error: 0.1889\n",
      "Epoch 262/300\n",
      "271/271 [==============================] - 0s 449us/step - loss: 0.0780 - mean_absolute_error: 0.1623 - val_loss: 0.1217 - val_mean_absolute_error: 0.1843\n",
      "Epoch 263/300\n",
      "271/271 [==============================] - 0s 449us/step - loss: 0.0769 - mean_absolute_error: 0.1608 - val_loss: 0.1186 - val_mean_absolute_error: 0.1852\n",
      "Epoch 264/300\n",
      "271/271 [==============================] - 0s 439us/step - loss: 0.0762 - mean_absolute_error: 0.1609 - val_loss: 0.1187 - val_mean_absolute_error: 0.1833\n",
      "Epoch 265/300\n",
      "271/271 [==============================] - 0s 436us/step - loss: 0.0761 - mean_absolute_error: 0.1596 - val_loss: 0.1180 - val_mean_absolute_error: 0.1875\n",
      "Epoch 266/300\n",
      "271/271 [==============================] - 0s 446us/step - loss: 0.0756 - mean_absolute_error: 0.1611 - val_loss: 0.1237 - val_mean_absolute_error: 0.1863\n",
      "Epoch 267/300\n",
      "271/271 [==============================] - 0s 438us/step - loss: 0.0776 - mean_absolute_error: 0.1621 - val_loss: 0.1145 - val_mean_absolute_error: 0.1815\n",
      "Epoch 268/300\n",
      "271/271 [==============================] - 0s 439us/step - loss: 0.0819 - mean_absolute_error: 0.1643 - val_loss: 0.1255 - val_mean_absolute_error: 0.1897\n",
      "Epoch 269/300\n",
      "271/271 [==============================] - 0s 441us/step - loss: 0.0781 - mean_absolute_error: 0.1628 - val_loss: 0.1197 - val_mean_absolute_error: 0.1856\n",
      "Epoch 270/300\n",
      "271/271 [==============================] - 0s 453us/step - loss: 0.0742 - mean_absolute_error: 0.1603 - val_loss: 0.1175 - val_mean_absolute_error: 0.1828\n",
      "Epoch 271/300\n",
      "271/271 [==============================] - 0s 455us/step - loss: 0.0744 - mean_absolute_error: 0.1604 - val_loss: 0.1128 - val_mean_absolute_error: 0.1785\n",
      "Epoch 272/300\n",
      "271/271 [==============================] - 0s 469us/step - loss: 0.0751 - mean_absolute_error: 0.1605 - val_loss: 0.1195 - val_mean_absolute_error: 0.1856\n",
      "Epoch 273/300\n",
      "271/271 [==============================] - 0s 460us/step - loss: 0.0770 - mean_absolute_error: 0.1610 - val_loss: 0.1232 - val_mean_absolute_error: 0.1864\n",
      "Epoch 274/300\n",
      "271/271 [==============================] - 0s 438us/step - loss: 0.0830 - mean_absolute_error: 0.1671 - val_loss: 0.1295 - val_mean_absolute_error: 0.1863\n",
      "Epoch 275/300\n",
      "271/271 [==============================] - 0s 460us/step - loss: 0.0768 - mean_absolute_error: 0.1609 - val_loss: 0.1197 - val_mean_absolute_error: 0.1834\n",
      "Epoch 276/300\n",
      "271/271 [==============================] - 0s 467us/step - loss: 0.0740 - mean_absolute_error: 0.1597 - val_loss: 0.1208 - val_mean_absolute_error: 0.1810\n",
      "Epoch 277/300\n",
      "271/271 [==============================] - 0s 467us/step - loss: 0.0745 - mean_absolute_error: 0.1602 - val_loss: 0.1244 - val_mean_absolute_error: 0.1913\n",
      "Epoch 278/300\n",
      "271/271 [==============================] - 0s 449us/step - loss: 0.0744 - mean_absolute_error: 0.1598 - val_loss: 0.1325 - val_mean_absolute_error: 0.1890\n",
      "Epoch 279/300\n",
      "271/271 [==============================] - 0s 453us/step - loss: 0.0759 - mean_absolute_error: 0.1620 - val_loss: 0.1314 - val_mean_absolute_error: 0.1898\n",
      "Epoch 280/300\n",
      "271/271 [==============================] - 0s 453us/step - loss: 0.0777 - mean_absolute_error: 0.1623 - val_loss: 0.1158 - val_mean_absolute_error: 0.1836\n",
      "Epoch 281/300\n",
      "271/271 [==============================] - 0s 453us/step - loss: 0.0751 - mean_absolute_error: 0.1608 - val_loss: 0.1170 - val_mean_absolute_error: 0.1800\n",
      "Epoch 282/300\n",
      "271/271 [==============================] - 0s 451us/step - loss: 0.0891 - mean_absolute_error: 0.1685 - val_loss: 0.1212 - val_mean_absolute_error: 0.1827\n",
      "Epoch 283/300\n",
      "271/271 [==============================] - 0s 454us/step - loss: 0.0809 - mean_absolute_error: 0.1620 - val_loss: 0.1217 - val_mean_absolute_error: 0.1893\n",
      "Epoch 284/300\n",
      "271/271 [==============================] - 0s 445us/step - loss: 0.0774 - mean_absolute_error: 0.1627 - val_loss: 0.1207 - val_mean_absolute_error: 0.1920\n",
      "Epoch 285/300\n",
      "271/271 [==============================] - 0s 442us/step - loss: 0.0746 - mean_absolute_error: 0.1601 - val_loss: 0.1190 - val_mean_absolute_error: 0.1797\n",
      "Epoch 286/300\n",
      "271/271 [==============================] - 0s 454us/step - loss: 0.0733 - mean_absolute_error: 0.1589 - val_loss: 0.1167 - val_mean_absolute_error: 0.1823\n",
      "Epoch 287/300\n",
      "271/271 [==============================] - 0s 452us/step - loss: 0.0801 - mean_absolute_error: 0.1625 - val_loss: 0.1393 - val_mean_absolute_error: 0.1952\n",
      "Epoch 288/300\n",
      "271/271 [==============================] - 0s 454us/step - loss: 0.0809 - mean_absolute_error: 0.1649 - val_loss: 0.1292 - val_mean_absolute_error: 0.1900\n",
      "Epoch 289/300\n",
      "271/271 [==============================] - 0s 438us/step - loss: 0.0754 - mean_absolute_error: 0.1611 - val_loss: 0.1225 - val_mean_absolute_error: 0.1822\n",
      "Epoch 290/300\n",
      "271/271 [==============================] - 0s 453us/step - loss: 0.0778 - mean_absolute_error: 0.1629 - val_loss: 0.1183 - val_mean_absolute_error: 0.1807\n",
      "Epoch 291/300\n",
      "271/271 [==============================] - 0s 445us/step - loss: 0.0783 - mean_absolute_error: 0.1631 - val_loss: 0.1202 - val_mean_absolute_error: 0.1852\n",
      "Epoch 292/300\n",
      "271/271 [==============================] - 0s 449us/step - loss: 0.0730 - mean_absolute_error: 0.1583 - val_loss: 0.1191 - val_mean_absolute_error: 0.1817\n",
      "Epoch 293/300\n",
      "271/271 [==============================] - 0s 442us/step - loss: 0.0761 - mean_absolute_error: 0.1610 - val_loss: 0.1246 - val_mean_absolute_error: 0.1847\n",
      "Epoch 294/300\n",
      "271/271 [==============================] - 0s 438us/step - loss: 0.0761 - mean_absolute_error: 0.1608 - val_loss: 0.1181 - val_mean_absolute_error: 0.1834\n",
      "Epoch 295/300\n",
      "271/271 [==============================] - 0s 449us/step - loss: 0.0799 - mean_absolute_error: 0.1636 - val_loss: 0.1197 - val_mean_absolute_error: 0.1845\n",
      "Epoch 296/300\n",
      "271/271 [==============================] - 0s 449us/step - loss: 0.1012 - mean_absolute_error: 0.1738 - val_loss: 0.1248 - val_mean_absolute_error: 0.1826\n",
      "Epoch 297/300\n",
      "271/271 [==============================] - 0s 451us/step - loss: 0.0763 - mean_absolute_error: 0.1608 - val_loss: 0.1197 - val_mean_absolute_error: 0.1826\n",
      "Epoch 298/300\n",
      "271/271 [==============================] - 0s 452us/step - loss: 0.0756 - mean_absolute_error: 0.1604 - val_loss: 0.1210 - val_mean_absolute_error: 0.1875\n",
      "Epoch 299/300\n",
      "271/271 [==============================] - 0s 448us/step - loss: 0.0748 - mean_absolute_error: 0.1595 - val_loss: 0.1197 - val_mean_absolute_error: 0.1825\n",
      "Epoch 300/300\n",
      "271/271 [==============================] - 0s 451us/step - loss: 0.0752 - mean_absolute_error: 0.1600 - val_loss: 0.1207 - val_mean_absolute_error: 0.1815\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ce4caa77c8>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3 = keras.Sequential(name='model-3')\n",
    "model_3.add(layers.Dense(64, \n",
    "                         kernel_regularizer=keras.regularizers.l2(0.001), \n",
    "                         activation='relu', input_shape=(21,)))\n",
    "model_3.add(layers.Dense(64, kernel_regularizer=keras.regularizers.l2(0.001), activation='relu'))\n",
    "model_3.add(layers.Dense(1))\n",
    "model_3.compile(keras.optimizers.Adam(0.001),\n",
    "                loss=keras.losses.MeanSquaredError(),\n",
    "                metrics=[keras.metrics.MeanAbsoluteError()])\n",
    "log_dir = os.path.join('lab2-logs', 'model-3')\n",
    "model_cbk = keras.callbacks.TensorBoard(log_dir=log_dir)\n",
    "model_mckp = keras.callbacks.ModelCheckpoint(model_dir + '/Best-model-3.h5', \n",
    "                                             monitor='val_mean_absolute_error', \n",
    "                                             save_best_only=True, \n",
    "                                             mode='min')\n",
    "model_3.fit(x_train, y_train, \n",
    "            batch_size=64 ,\n",
    "            epochs=300, \n",
    "            validation_data=(x_val, y_val), \n",
    "            callbacks=[model_cbk, model_mckp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b5666e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "  1/271 [..............................] - ETA: 0s - loss: 1.5090 - mean_absolute_error: 0.8205WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_train_batch_end` time: 0.0232s). Check your callbacks.\n",
      "271/271 [==============================] - 0s 1ms/step - loss: 0.4954 - mean_absolute_error: 0.4544 - val_loss: 0.2482 - val_mean_absolute_error: 0.3099\n",
      "Epoch 2/300\n",
      "271/271 [==============================] - 0s 706us/step - loss: 0.3036 - mean_absolute_error: 0.3500 - val_loss: 0.2443 - val_mean_absolute_error: 0.3015\n",
      "Epoch 3/300\n",
      "271/271 [==============================] - 0s 673us/step - loss: 0.2830 - mean_absolute_error: 0.3285 - val_loss: 0.2529 - val_mean_absolute_error: 0.3054\n",
      "Epoch 4/300\n",
      "271/271 [==============================] - 0s 723us/step - loss: 0.2546 - mean_absolute_error: 0.3142 - val_loss: 0.2029 - val_mean_absolute_error: 0.2695\n",
      "Epoch 5/300\n",
      "271/271 [==============================] - 0s 710us/step - loss: 0.2575 - mean_absolute_error: 0.3075 - val_loss: 0.2051 - val_mean_absolute_error: 0.2684\n",
      "Epoch 6/300\n",
      "271/271 [==============================] - 0s 724us/step - loss: 0.2213 - mean_absolute_error: 0.2907 - val_loss: 0.1995 - val_mean_absolute_error: 0.2566\n",
      "Epoch 7/300\n",
      "271/271 [==============================] - 0s 674us/step - loss: 0.2218 - mean_absolute_error: 0.2857 - val_loss: 0.2206 - val_mean_absolute_error: 0.2680\n",
      "Epoch 8/300\n",
      "271/271 [==============================] - 0s 707us/step - loss: 0.1987 - mean_absolute_error: 0.2765 - val_loss: 0.1723 - val_mean_absolute_error: 0.2465\n",
      "Epoch 9/300\n",
      "271/271 [==============================] - 0s 715us/step - loss: 0.1927 - mean_absolute_error: 0.2736 - val_loss: 0.1846 - val_mean_absolute_error: 0.2461\n",
      "Epoch 10/300\n",
      "271/271 [==============================] - 0s 709us/step - loss: 0.1907 - mean_absolute_error: 0.2694 - val_loss: 0.1770 - val_mean_absolute_error: 0.2383\n",
      "Epoch 11/300\n",
      "271/271 [==============================] - 0s 703us/step - loss: 0.1892 - mean_absolute_error: 0.2658 - val_loss: 0.1736 - val_mean_absolute_error: 0.2447\n",
      "Epoch 12/300\n",
      "271/271 [==============================] - 0s 726us/step - loss: 0.1834 - mean_absolute_error: 0.2638 - val_loss: 0.1508 - val_mean_absolute_error: 0.2361\n",
      "Epoch 13/300\n",
      "271/271 [==============================] - 0s 692us/step - loss: 0.1698 - mean_absolute_error: 0.2608 - val_loss: 0.1549 - val_mean_absolute_error: 0.2375\n",
      "Epoch 14/300\n",
      "271/271 [==============================] - 0s 706us/step - loss: 0.1684 - mean_absolute_error: 0.2569 - val_loss: 0.1661 - val_mean_absolute_error: 0.2351\n",
      "Epoch 15/300\n",
      "271/271 [==============================] - 0s 702us/step - loss: 0.1683 - mean_absolute_error: 0.2543 - val_loss: 0.1367 - val_mean_absolute_error: 0.2269\n",
      "Epoch 16/300\n",
      "271/271 [==============================] - 0s 750us/step - loss: 0.1704 - mean_absolute_error: 0.2539 - val_loss: 0.1530 - val_mean_absolute_error: 0.2249\n",
      "Epoch 17/300\n",
      "271/271 [==============================] - 0s 714us/step - loss: 0.1763 - mean_absolute_error: 0.2561 - val_loss: 0.1335 - val_mean_absolute_error: 0.2137\n",
      "Epoch 18/300\n",
      "271/271 [==============================] - 0s 659us/step - loss: 0.1645 - mean_absolute_error: 0.2506 - val_loss: 0.1918 - val_mean_absolute_error: 0.2418\n",
      "Epoch 19/300\n",
      "271/271 [==============================] - 0s 655us/step - loss: 0.1627 - mean_absolute_error: 0.2504 - val_loss: 0.1531 - val_mean_absolute_error: 0.2263\n",
      "Epoch 20/300\n",
      "271/271 [==============================] - 0s 654us/step - loss: 0.1588 - mean_absolute_error: 0.2467 - val_loss: 0.1381 - val_mean_absolute_error: 0.2255\n",
      "Epoch 21/300\n",
      "271/271 [==============================] - 0s 751us/step - loss: 0.1579 - mean_absolute_error: 0.2450 - val_loss: 0.1450 - val_mean_absolute_error: 0.2275\n",
      "Epoch 22/300\n",
      "271/271 [==============================] - 0s 681us/step - loss: 0.1546 - mean_absolute_error: 0.2464 - val_loss: 0.1698 - val_mean_absolute_error: 0.2301\n",
      "Epoch 23/300\n",
      "271/271 [==============================] - 0s 672us/step - loss: 0.1587 - mean_absolute_error: 0.2437 - val_loss: 0.1342 - val_mean_absolute_error: 0.2177\n",
      "Epoch 24/300\n",
      "271/271 [==============================] - 0s 666us/step - loss: 0.1547 - mean_absolute_error: 0.2413 - val_loss: 0.1358 - val_mean_absolute_error: 0.2183\n",
      "Epoch 25/300\n",
      "271/271 [==============================] - 0s 765us/step - loss: 0.1529 - mean_absolute_error: 0.2427 - val_loss: 0.1396 - val_mean_absolute_error: 0.2177\n",
      "Epoch 26/300\n",
      "271/271 [==============================] - 0s 674us/step - loss: 0.1488 - mean_absolute_error: 0.2376 - val_loss: 0.1570 - val_mean_absolute_error: 0.2207\n",
      "Epoch 27/300\n",
      "271/271 [==============================] - 0s 719us/step - loss: 0.1538 - mean_absolute_error: 0.2392 - val_loss: 0.1266 - val_mean_absolute_error: 0.2118\n",
      "Epoch 28/300\n",
      "271/271 [==============================] - 0s 725us/step - loss: 0.1428 - mean_absolute_error: 0.2364 - val_loss: 0.1437 - val_mean_absolute_error: 0.2248\n",
      "Epoch 29/300\n",
      "271/271 [==============================] - 0s 658us/step - loss: 0.1384 - mean_absolute_error: 0.2359 - val_loss: 0.1359 - val_mean_absolute_error: 0.2201\n",
      "Epoch 30/300\n",
      "271/271 [==============================] - 0s 660us/step - loss: 0.1432 - mean_absolute_error: 0.2327 - val_loss: 0.1371 - val_mean_absolute_error: 0.2197\n",
      "Epoch 31/300\n",
      "271/271 [==============================] - 0s 714us/step - loss: 0.1522 - mean_absolute_error: 0.2355 - val_loss: 0.1250 - val_mean_absolute_error: 0.2089\n",
      "Epoch 32/300\n",
      "271/271 [==============================] - 0s 672us/step - loss: 0.1349 - mean_absolute_error: 0.2320 - val_loss: 0.1284 - val_mean_absolute_error: 0.2187\n",
      "Epoch 33/300\n",
      "271/271 [==============================] - 0s 659us/step - loss: 0.1454 - mean_absolute_error: 0.2347 - val_loss: 0.1468 - val_mean_absolute_error: 0.2237\n",
      "Epoch 34/300\n",
      "271/271 [==============================] - 0s 655us/step - loss: 0.1345 - mean_absolute_error: 0.2311 - val_loss: 0.1336 - val_mean_absolute_error: 0.2115\n",
      "Epoch 35/300\n",
      "271/271 [==============================] - 0s 677us/step - loss: 0.1471 - mean_absolute_error: 0.2310 - val_loss: 0.1412 - val_mean_absolute_error: 0.2189\n",
      "Epoch 36/300\n",
      "271/271 [==============================] - 0s 656us/step - loss: 0.1351 - mean_absolute_error: 0.2309 - val_loss: 0.1439 - val_mean_absolute_error: 0.2134\n",
      "Epoch 37/300\n",
      "271/271 [==============================] - 0s 692us/step - loss: 0.1321 - mean_absolute_error: 0.2290 - val_loss: 0.1199 - val_mean_absolute_error: 0.2062\n",
      "Epoch 38/300\n",
      "271/271 [==============================] - 0s 698us/step - loss: 0.1335 - mean_absolute_error: 0.2304 - val_loss: 0.1399 - val_mean_absolute_error: 0.2060\n",
      "Epoch 39/300\n",
      "271/271 [==============================] - 0s 664us/step - loss: 0.1329 - mean_absolute_error: 0.2284 - val_loss: 0.1614 - val_mean_absolute_error: 0.2153\n",
      "Epoch 40/300\n",
      "271/271 [==============================] - 0s 703us/step - loss: 0.1379 - mean_absolute_error: 0.2285 - val_loss: 0.1176 - val_mean_absolute_error: 0.2038\n",
      "Epoch 41/300\n",
      "271/271 [==============================] - 0s 666us/step - loss: 0.1314 - mean_absolute_error: 0.2264 - val_loss: 0.1297 - val_mean_absolute_error: 0.2048\n",
      "Epoch 42/300\n",
      "271/271 [==============================] - 0s 659us/step - loss: 0.1349 - mean_absolute_error: 0.2270 - val_loss: 0.1187 - val_mean_absolute_error: 0.2141\n",
      "Epoch 43/300\n",
      "271/271 [==============================] - 0s 705us/step - loss: 0.1369 - mean_absolute_error: 0.2272 - val_loss: 0.1141 - val_mean_absolute_error: 0.2004\n",
      "Epoch 44/300\n",
      "271/271 [==============================] - 0s 673us/step - loss: 0.1295 - mean_absolute_error: 0.2257 - val_loss: 0.1308 - val_mean_absolute_error: 0.2115\n",
      "Epoch 45/300\n",
      "271/271 [==============================] - 0s 666us/step - loss: 0.1248 - mean_absolute_error: 0.2237 - val_loss: 0.1208 - val_mean_absolute_error: 0.2115\n",
      "Epoch 46/300\n",
      "271/271 [==============================] - 0s 665us/step - loss: 0.1330 - mean_absolute_error: 0.2270 - val_loss: 0.1396 - val_mean_absolute_error: 0.2151\n",
      "Epoch 47/300\n",
      "271/271 [==============================] - 0s 657us/step - loss: 0.1324 - mean_absolute_error: 0.2288 - val_loss: 0.1160 - val_mean_absolute_error: 0.2067\n",
      "Epoch 48/300\n",
      "271/271 [==============================] - 0s 661us/step - loss: 0.1279 - mean_absolute_error: 0.2254 - val_loss: 0.1172 - val_mean_absolute_error: 0.2051\n",
      "Epoch 49/300\n",
      "271/271 [==============================] - 0s 655us/step - loss: 0.1298 - mean_absolute_error: 0.2240 - val_loss: 0.1166 - val_mean_absolute_error: 0.2031\n",
      "Epoch 50/300\n",
      "271/271 [==============================] - 0s 651us/step - loss: 0.1249 - mean_absolute_error: 0.2240 - val_loss: 0.1056 - val_mean_absolute_error: 0.2076\n",
      "Epoch 51/300\n",
      "271/271 [==============================] - 0s 653us/step - loss: 0.1319 - mean_absolute_error: 0.2265 - val_loss: 0.1082 - val_mean_absolute_error: 0.2051\n",
      "Epoch 52/300\n",
      "271/271 [==============================] - 0s 658us/step - loss: 0.1259 - mean_absolute_error: 0.2239 - val_loss: 0.1196 - val_mean_absolute_error: 0.2029\n",
      "Epoch 53/300\n",
      "271/271 [==============================] - 0s 654us/step - loss: 0.1254 - mean_absolute_error: 0.2226 - val_loss: 0.1143 - val_mean_absolute_error: 0.2036\n",
      "Epoch 54/300\n",
      "271/271 [==============================] - 0s 651us/step - loss: 0.1227 - mean_absolute_error: 0.2217 - val_loss: 0.1143 - val_mean_absolute_error: 0.2112\n",
      "Epoch 55/300\n",
      "271/271 [==============================] - 0s 652us/step - loss: 0.1243 - mean_absolute_error: 0.2227 - val_loss: 0.1056 - val_mean_absolute_error: 0.2020\n",
      "Epoch 56/300\n",
      "271/271 [==============================] - 0s 650us/step - loss: 0.1329 - mean_absolute_error: 0.2229 - val_loss: 0.1200 - val_mean_absolute_error: 0.2028\n",
      "Epoch 57/300\n",
      "271/271 [==============================] - 0s 660us/step - loss: 0.1328 - mean_absolute_error: 0.2240 - val_loss: 0.1113 - val_mean_absolute_error: 0.2036\n",
      "Epoch 58/300\n",
      "271/271 [==============================] - 0s 656us/step - loss: 0.1309 - mean_absolute_error: 0.2243 - val_loss: 0.1167 - val_mean_absolute_error: 0.2011\n",
      "Epoch 59/300\n",
      "271/271 [==============================] - 0s 701us/step - loss: 0.1302 - mean_absolute_error: 0.2256 - val_loss: 0.1069 - val_mean_absolute_error: 0.1992\n",
      "Epoch 60/300\n",
      "271/271 [==============================] - 0s 655us/step - loss: 0.1245 - mean_absolute_error: 0.2219 - val_loss: 0.1277 - val_mean_absolute_error: 0.2126\n",
      "Epoch 61/300\n",
      "271/271 [==============================] - 0s 651us/step - loss: 0.1303 - mean_absolute_error: 0.2223 - val_loss: 0.1186 - val_mean_absolute_error: 0.2082\n",
      "Epoch 62/300\n",
      "271/271 [==============================] - 0s 651us/step - loss: 0.1219 - mean_absolute_error: 0.2206 - val_loss: 0.1105 - val_mean_absolute_error: 0.2065\n",
      "Epoch 63/300\n",
      "271/271 [==============================] - 0s 655us/step - loss: 0.1284 - mean_absolute_error: 0.2246 - val_loss: 0.1119 - val_mean_absolute_error: 0.2021\n",
      "Epoch 64/300\n",
      "271/271 [==============================] - 0s 662us/step - loss: 0.1244 - mean_absolute_error: 0.2205 - val_loss: 0.1128 - val_mean_absolute_error: 0.2009\n",
      "Epoch 65/300\n",
      "271/271 [==============================] - 0s 662us/step - loss: 0.1235 - mean_absolute_error: 0.2212 - val_loss: 0.1113 - val_mean_absolute_error: 0.2128\n",
      "Epoch 66/300\n",
      "271/271 [==============================] - 0s 656us/step - loss: 0.1236 - mean_absolute_error: 0.2202 - val_loss: 0.1093 - val_mean_absolute_error: 0.2022\n",
      "Epoch 67/300\n",
      "271/271 [==============================] - 0s 658us/step - loss: 0.1224 - mean_absolute_error: 0.2215 - val_loss: 0.1218 - val_mean_absolute_error: 0.2061\n",
      "Epoch 68/300\n",
      "271/271 [==============================] - 0s 694us/step - loss: 0.1380 - mean_absolute_error: 0.2256 - val_loss: 0.1126 - val_mean_absolute_error: 0.1982\n",
      "Epoch 69/300\n",
      "271/271 [==============================] - 0s 661us/step - loss: 0.1220 - mean_absolute_error: 0.2199 - val_loss: 0.1329 - val_mean_absolute_error: 0.2081\n",
      "Epoch 70/300\n",
      "271/271 [==============================] - 0s 659us/step - loss: 0.1285 - mean_absolute_error: 0.2211 - val_loss: 0.1213 - val_mean_absolute_error: 0.2047\n",
      "Epoch 71/300\n",
      "271/271 [==============================] - 0s 659us/step - loss: 0.1246 - mean_absolute_error: 0.2200 - val_loss: 0.1316 - val_mean_absolute_error: 0.2142\n",
      "Epoch 72/300\n",
      "271/271 [==============================] - 0s 655us/step - loss: 0.1232 - mean_absolute_error: 0.2209 - val_loss: 0.1134 - val_mean_absolute_error: 0.2048\n",
      "Epoch 73/300\n",
      "271/271 [==============================] - 0s 655us/step - loss: 0.1178 - mean_absolute_error: 0.2183 - val_loss: 0.1165 - val_mean_absolute_error: 0.2073\n",
      "Epoch 74/300\n",
      "271/271 [==============================] - 0s 649us/step - loss: 0.1350 - mean_absolute_error: 0.2222 - val_loss: 0.1285 - val_mean_absolute_error: 0.2215\n",
      "Epoch 75/300\n",
      "271/271 [==============================] - 0s 661us/step - loss: 0.1202 - mean_absolute_error: 0.2207 - val_loss: 0.1320 - val_mean_absolute_error: 0.2171\n",
      "Epoch 76/300\n",
      "271/271 [==============================] - 0s 696us/step - loss: 0.1237 - mean_absolute_error: 0.2227 - val_loss: 0.1128 - val_mean_absolute_error: 0.2029\n",
      "Epoch 77/300\n",
      "271/271 [==============================] - 0s 728us/step - loss: 0.1151 - mean_absolute_error: 0.2175 - val_loss: 0.1074 - val_mean_absolute_error: 0.1952\n",
      "Epoch 78/300\n",
      "271/271 [==============================] - 0s 723us/step - loss: 0.1150 - mean_absolute_error: 0.2168 - val_loss: 0.1366 - val_mean_absolute_error: 0.2076\n",
      "Epoch 79/300\n",
      "271/271 [==============================] - 0s 666us/step - loss: 0.1247 - mean_absolute_error: 0.2189 - val_loss: 0.1363 - val_mean_absolute_error: 0.2090\n",
      "Epoch 80/300\n",
      "271/271 [==============================] - 0s 651us/step - loss: 0.1132 - mean_absolute_error: 0.2160 - val_loss: 0.1205 - val_mean_absolute_error: 0.2086\n",
      "Epoch 81/300\n",
      "271/271 [==============================] - 0s 655us/step - loss: 0.1170 - mean_absolute_error: 0.2173 - val_loss: 0.1304 - val_mean_absolute_error: 0.2119\n",
      "Epoch 82/300\n",
      "271/271 [==============================] - 0s 666us/step - loss: 0.1215 - mean_absolute_error: 0.2195 - val_loss: 0.1137 - val_mean_absolute_error: 0.2080\n",
      "Epoch 83/300\n",
      "271/271 [==============================] - 0s 660us/step - loss: 0.1173 - mean_absolute_error: 0.2181 - val_loss: 0.1135 - val_mean_absolute_error: 0.2032\n",
      "Epoch 84/300\n",
      "271/271 [==============================] - 0s 731us/step - loss: 0.1203 - mean_absolute_error: 0.2184 - val_loss: 0.1154 - val_mean_absolute_error: 0.2067\n",
      "Epoch 85/300\n",
      "271/271 [==============================] - 0s 671us/step - loss: 0.1240 - mean_absolute_error: 0.2192 - val_loss: 0.1130 - val_mean_absolute_error: 0.2032\n",
      "Epoch 86/300\n",
      "271/271 [==============================] - 0s 649us/step - loss: 0.1184 - mean_absolute_error: 0.2186 - val_loss: 0.1191 - val_mean_absolute_error: 0.2217\n",
      "Epoch 87/300\n",
      "271/271 [==============================] - 0s 674us/step - loss: 0.1206 - mean_absolute_error: 0.2196 - val_loss: 0.1343 - val_mean_absolute_error: 0.2026\n",
      "Epoch 88/300\n",
      "271/271 [==============================] - 0s 673us/step - loss: 0.1215 - mean_absolute_error: 0.2193 - val_loss: 0.1120 - val_mean_absolute_error: 0.2103\n",
      "Epoch 89/300\n",
      "271/271 [==============================] - 0s 649us/step - loss: 0.1166 - mean_absolute_error: 0.2185 - val_loss: 0.1158 - val_mean_absolute_error: 0.2161\n",
      "Epoch 90/300\n",
      "271/271 [==============================] - 0s 666us/step - loss: 0.1141 - mean_absolute_error: 0.2174 - val_loss: 0.1033 - val_mean_absolute_error: 0.1959\n",
      "Epoch 91/300\n",
      "271/271 [==============================] - 0s 655us/step - loss: 0.1207 - mean_absolute_error: 0.2197 - val_loss: 0.1488 - val_mean_absolute_error: 0.2263\n",
      "Epoch 92/300\n",
      "271/271 [==============================] - 0s 670us/step - loss: 0.1211 - mean_absolute_error: 0.2186 - val_loss: 0.1216 - val_mean_absolute_error: 0.2011\n",
      "Epoch 93/300\n",
      "271/271 [==============================] - 0s 655us/step - loss: 0.1208 - mean_absolute_error: 0.2178 - val_loss: 0.1201 - val_mean_absolute_error: 0.2096\n",
      "Epoch 94/300\n",
      "271/271 [==============================] - 0s 662us/step - loss: 0.1190 - mean_absolute_error: 0.2186 - val_loss: 0.1218 - val_mean_absolute_error: 0.2086\n",
      "Epoch 95/300\n",
      "271/271 [==============================] - 0s 661us/step - loss: 0.1188 - mean_absolute_error: 0.2190 - val_loss: 0.1080 - val_mean_absolute_error: 0.1988\n",
      "Epoch 96/300\n",
      "271/271 [==============================] - 0s 661us/step - loss: 0.1171 - mean_absolute_error: 0.2168 - val_loss: 0.1450 - val_mean_absolute_error: 0.2304\n",
      "Epoch 97/300\n",
      "271/271 [==============================] - 0s 666us/step - loss: 0.1139 - mean_absolute_error: 0.2165 - val_loss: 0.1288 - val_mean_absolute_error: 0.2117\n",
      "Epoch 98/300\n",
      "271/271 [==============================] - 0s 706us/step - loss: 0.1205 - mean_absolute_error: 0.2183 - val_loss: 0.0990 - val_mean_absolute_error: 0.1913\n",
      "Epoch 99/300\n",
      "271/271 [==============================] - 0s 655us/step - loss: 0.1230 - mean_absolute_error: 0.2192 - val_loss: 0.1176 - val_mean_absolute_error: 0.2043\n",
      "Epoch 100/300\n",
      "271/271 [==============================] - 0s 659us/step - loss: 0.1201 - mean_absolute_error: 0.2171 - val_loss: 0.1188 - val_mean_absolute_error: 0.2000\n",
      "Epoch 101/300\n",
      "271/271 [==============================] - 0s 666us/step - loss: 0.1210 - mean_absolute_error: 0.2199 - val_loss: 0.1173 - val_mean_absolute_error: 0.1997\n",
      "Epoch 102/300\n",
      "271/271 [==============================] - 0s 716us/step - loss: 0.1253 - mean_absolute_error: 0.2183 - val_loss: 0.1191 - val_mean_absolute_error: 0.2035\n",
      "Epoch 103/300\n",
      "271/271 [==============================] - 0s 688us/step - loss: 0.1194 - mean_absolute_error: 0.2174 - val_loss: 0.1104 - val_mean_absolute_error: 0.2017\n",
      "Epoch 104/300\n",
      "271/271 [==============================] - 0s 703us/step - loss: 0.1131 - mean_absolute_error: 0.2135 - val_loss: 0.1309 - val_mean_absolute_error: 0.2137\n",
      "Epoch 105/300\n",
      "271/271 [==============================] - 0s 673us/step - loss: 0.1166 - mean_absolute_error: 0.2162 - val_loss: 0.1309 - val_mean_absolute_error: 0.2176\n",
      "Epoch 106/300\n",
      "271/271 [==============================] - 0s 655us/step - loss: 0.1099 - mean_absolute_error: 0.2132 - val_loss: 0.1302 - val_mean_absolute_error: 0.2123\n",
      "Epoch 107/300\n",
      "271/271 [==============================] - 0s 663us/step - loss: 0.1185 - mean_absolute_error: 0.2174 - val_loss: 0.1120 - val_mean_absolute_error: 0.2125\n",
      "Epoch 108/300\n",
      "271/271 [==============================] - 0s 666us/step - loss: 0.1211 - mean_absolute_error: 0.2194 - val_loss: 0.1500 - val_mean_absolute_error: 0.2176\n",
      "Epoch 109/300\n",
      "271/271 [==============================] - 0s 655us/step - loss: 0.1165 - mean_absolute_error: 0.2146 - val_loss: 0.1156 - val_mean_absolute_error: 0.2100\n",
      "Epoch 110/300\n",
      "271/271 [==============================] - 0s 651us/step - loss: 0.1137 - mean_absolute_error: 0.2137 - val_loss: 0.1079 - val_mean_absolute_error: 0.2078\n",
      "Epoch 111/300\n",
      "271/271 [==============================] - 0s 655us/step - loss: 0.1192 - mean_absolute_error: 0.2176 - val_loss: 0.1146 - val_mean_absolute_error: 0.2121\n",
      "Epoch 112/300\n",
      "271/271 [==============================] - 0s 653us/step - loss: 0.1244 - mean_absolute_error: 0.2179 - val_loss: 0.1207 - val_mean_absolute_error: 0.2026\n",
      "Epoch 113/300\n",
      "271/271 [==============================] - 0s 653us/step - loss: 0.1184 - mean_absolute_error: 0.2160 - val_loss: 0.1079 - val_mean_absolute_error: 0.2084\n",
      "Epoch 114/300\n",
      "271/271 [==============================] - 0s 655us/step - loss: 0.1135 - mean_absolute_error: 0.2157 - val_loss: 0.1644 - val_mean_absolute_error: 0.2317\n",
      "Epoch 115/300\n",
      "271/271 [==============================] - 0s 648us/step - loss: 0.1145 - mean_absolute_error: 0.2152 - val_loss: 0.1091 - val_mean_absolute_error: 0.2003\n",
      "Epoch 116/300\n",
      "271/271 [==============================] - 0s 685us/step - loss: 0.1187 - mean_absolute_error: 0.2175 - val_loss: 0.1078 - val_mean_absolute_error: 0.2012\n",
      "Epoch 117/300\n",
      "271/271 [==============================] - 0s 680us/step - loss: 0.1157 - mean_absolute_error: 0.2156 - val_loss: 0.1093 - val_mean_absolute_error: 0.2061\n",
      "Epoch 118/300\n",
      "271/271 [==============================] - 0s 670us/step - loss: 0.1137 - mean_absolute_error: 0.2144 - val_loss: 0.1105 - val_mean_absolute_error: 0.2035\n",
      "Epoch 119/300\n",
      "271/271 [==============================] - 0s 651us/step - loss: 0.1195 - mean_absolute_error: 0.2164 - val_loss: 0.1052 - val_mean_absolute_error: 0.2072\n",
      "Epoch 120/300\n",
      "271/271 [==============================] - 0s 655us/step - loss: 0.1190 - mean_absolute_error: 0.2168 - val_loss: 0.1149 - val_mean_absolute_error: 0.2026\n",
      "Epoch 121/300\n",
      "271/271 [==============================] - 0s 662us/step - loss: 0.1082 - mean_absolute_error: 0.2141 - val_loss: 0.1023 - val_mean_absolute_error: 0.2008\n",
      "Epoch 122/300\n",
      "271/271 [==============================] - 0s 656us/step - loss: 0.1194 - mean_absolute_error: 0.2162 - val_loss: 0.1398 - val_mean_absolute_error: 0.2138\n",
      "Epoch 123/300\n",
      "271/271 [==============================] - 0s 659us/step - loss: 0.1065 - mean_absolute_error: 0.2120 - val_loss: 0.1261 - val_mean_absolute_error: 0.2105\n",
      "Epoch 124/300\n",
      "271/271 [==============================] - 0s 655us/step - loss: 0.1178 - mean_absolute_error: 0.2150 - val_loss: 0.1148 - val_mean_absolute_error: 0.2022\n",
      "Epoch 125/300\n",
      "271/271 [==============================] - 0s 650us/step - loss: 0.1155 - mean_absolute_error: 0.2151 - val_loss: 0.1332 - val_mean_absolute_error: 0.2163\n",
      "Epoch 126/300\n",
      "271/271 [==============================] - 0s 655us/step - loss: 0.1114 - mean_absolute_error: 0.2157 - val_loss: 0.1301 - val_mean_absolute_error: 0.2148\n",
      "Epoch 127/300\n",
      "271/271 [==============================] - 0s 651us/step - loss: 0.1174 - mean_absolute_error: 0.2163 - val_loss: 0.1179 - val_mean_absolute_error: 0.2112\n",
      "Epoch 128/300\n",
      "271/271 [==============================] - 0s 655us/step - loss: 0.1080 - mean_absolute_error: 0.2137 - val_loss: 0.1095 - val_mean_absolute_error: 0.1979\n",
      "Epoch 129/300\n",
      "271/271 [==============================] - 0s 696us/step - loss: 0.1135 - mean_absolute_error: 0.2136 - val_loss: 0.1058 - val_mean_absolute_error: 0.1898\n",
      "Epoch 130/300\n",
      "271/271 [==============================] - 0s 655us/step - loss: 0.1148 - mean_absolute_error: 0.2135 - val_loss: 0.1499 - val_mean_absolute_error: 0.2121\n",
      "Epoch 131/300\n",
      "271/271 [==============================] - 0s 661us/step - loss: 0.1146 - mean_absolute_error: 0.2143 - val_loss: 0.1110 - val_mean_absolute_error: 0.2041\n",
      "Epoch 132/300\n",
      "271/271 [==============================] - 0s 651us/step - loss: 0.1148 - mean_absolute_error: 0.2134 - val_loss: 0.1069 - val_mean_absolute_error: 0.1990\n",
      "Epoch 133/300\n",
      "271/271 [==============================] - 0s 654us/step - loss: 0.1117 - mean_absolute_error: 0.2153 - val_loss: 0.1165 - val_mean_absolute_error: 0.2065\n",
      "Epoch 134/300\n",
      "271/271 [==============================] - 0s 651us/step - loss: 0.1108 - mean_absolute_error: 0.2145 - val_loss: 0.1221 - val_mean_absolute_error: 0.1978\n",
      "Epoch 135/300\n",
      "271/271 [==============================] - 0s 658us/step - loss: 0.1139 - mean_absolute_error: 0.2130 - val_loss: 0.1169 - val_mean_absolute_error: 0.2120\n",
      "Epoch 136/300\n",
      "271/271 [==============================] - 0s 648us/step - loss: 0.1134 - mean_absolute_error: 0.2151 - val_loss: 0.1119 - val_mean_absolute_error: 0.1966\n",
      "Epoch 137/300\n",
      "271/271 [==============================] - 0s 659us/step - loss: 0.1111 - mean_absolute_error: 0.2141 - val_loss: 0.1229 - val_mean_absolute_error: 0.2213\n",
      "Epoch 138/300\n",
      "271/271 [==============================] - 0s 651us/step - loss: 0.1123 - mean_absolute_error: 0.2139 - val_loss: 0.1365 - val_mean_absolute_error: 0.2085\n",
      "Epoch 139/300\n",
      "271/271 [==============================] - 0s 649us/step - loss: 0.1129 - mean_absolute_error: 0.2134 - val_loss: 0.1141 - val_mean_absolute_error: 0.2094\n",
      "Epoch 140/300\n",
      "271/271 [==============================] - 0s 666us/step - loss: 0.1073 - mean_absolute_error: 0.2115 - val_loss: 0.1263 - val_mean_absolute_error: 0.2086\n",
      "Epoch 141/300\n",
      "271/271 [==============================] - 0s 667us/step - loss: 0.1145 - mean_absolute_error: 0.2135 - val_loss: 0.1191 - val_mean_absolute_error: 0.2055\n",
      "Epoch 142/300\n",
      "271/271 [==============================] - 0s 665us/step - loss: 0.1051 - mean_absolute_error: 0.2090 - val_loss: 0.1142 - val_mean_absolute_error: 0.2085\n",
      "Epoch 143/300\n",
      "271/271 [==============================] - 0s 653us/step - loss: 0.1048 - mean_absolute_error: 0.2132 - val_loss: 0.1013 - val_mean_absolute_error: 0.1961\n",
      "Epoch 144/300\n",
      "271/271 [==============================] - 0s 654us/step - loss: 0.1124 - mean_absolute_error: 0.2108 - val_loss: 0.1127 - val_mean_absolute_error: 0.2122\n",
      "Epoch 145/300\n",
      "271/271 [==============================] - 0s 666us/step - loss: 0.1089 - mean_absolute_error: 0.2123 - val_loss: 0.1264 - val_mean_absolute_error: 0.2076\n",
      "Epoch 146/300\n",
      "271/271 [==============================] - 0s 655us/step - loss: 0.1109 - mean_absolute_error: 0.2118 - val_loss: 0.1433 - val_mean_absolute_error: 0.2202\n",
      "Epoch 147/300\n",
      "271/271 [==============================] - 0s 667us/step - loss: 0.1098 - mean_absolute_error: 0.2125 - val_loss: 0.1155 - val_mean_absolute_error: 0.2121\n",
      "Epoch 148/300\n",
      "271/271 [==============================] - 0s 662us/step - loss: 0.1098 - mean_absolute_error: 0.2131 - val_loss: 0.1090 - val_mean_absolute_error: 0.1999\n",
      "Epoch 149/300\n",
      "271/271 [==============================] - 0s 659us/step - loss: 0.1200 - mean_absolute_error: 0.2136 - val_loss: 0.1149 - val_mean_absolute_error: 0.2012\n",
      "Epoch 150/300\n",
      "271/271 [==============================] - 0s 666us/step - loss: 0.1178 - mean_absolute_error: 0.2137 - val_loss: 0.1271 - val_mean_absolute_error: 0.2096\n",
      "Epoch 151/300\n",
      "271/271 [==============================] - 0s 661us/step - loss: 0.1124 - mean_absolute_error: 0.2132 - val_loss: 0.1200 - val_mean_absolute_error: 0.2131\n",
      "Epoch 152/300\n",
      "271/271 [==============================] - 0s 656us/step - loss: 0.1061 - mean_absolute_error: 0.2104 - val_loss: 0.1207 - val_mean_absolute_error: 0.2126\n",
      "Epoch 153/300\n",
      "271/271 [==============================] - 0s 643us/step - loss: 0.1092 - mean_absolute_error: 0.2117 - val_loss: 0.1147 - val_mean_absolute_error: 0.2052\n",
      "Epoch 154/300\n",
      "271/271 [==============================] - 0s 654us/step - loss: 0.1034 - mean_absolute_error: 0.2099 - val_loss: 0.1199 - val_mean_absolute_error: 0.2117\n",
      "Epoch 155/300\n",
      "271/271 [==============================] - 0s 655us/step - loss: 0.1135 - mean_absolute_error: 0.2137 - val_loss: 0.1076 - val_mean_absolute_error: 0.1979\n",
      "Epoch 156/300\n",
      "271/271 [==============================] - 0s 659us/step - loss: 0.1075 - mean_absolute_error: 0.2107 - val_loss: 0.1033 - val_mean_absolute_error: 0.2030\n",
      "Epoch 157/300\n",
      "271/271 [==============================] - 0s 655us/step - loss: 0.1083 - mean_absolute_error: 0.2111 - val_loss: 0.1136 - val_mean_absolute_error: 0.2067\n",
      "Epoch 158/300\n",
      "271/271 [==============================] - 0s 659us/step - loss: 0.1140 - mean_absolute_error: 0.2120 - val_loss: 0.1105 - val_mean_absolute_error: 0.2025\n",
      "Epoch 159/300\n",
      "271/271 [==============================] - 0s 651us/step - loss: 0.1131 - mean_absolute_error: 0.2134 - val_loss: 0.1155 - val_mean_absolute_error: 0.2065\n",
      "Epoch 160/300\n",
      "271/271 [==============================] - 0s 661us/step - loss: 0.1135 - mean_absolute_error: 0.2120 - val_loss: 0.1331 - val_mean_absolute_error: 0.2171\n",
      "Epoch 161/300\n",
      "271/271 [==============================] - 0s 666us/step - loss: 0.1090 - mean_absolute_error: 0.2127 - val_loss: 0.1078 - val_mean_absolute_error: 0.2000\n",
      "Epoch 162/300\n",
      "271/271 [==============================] - 0s 666us/step - loss: 0.1054 - mean_absolute_error: 0.2097 - val_loss: 0.1175 - val_mean_absolute_error: 0.2156\n",
      "Epoch 163/300\n",
      "271/271 [==============================] - 0s 658us/step - loss: 0.1158 - mean_absolute_error: 0.2132 - val_loss: 0.1384 - val_mean_absolute_error: 0.2058\n",
      "Epoch 164/300\n",
      "271/271 [==============================] - 0s 658us/step - loss: 0.1082 - mean_absolute_error: 0.2111 - val_loss: 0.1134 - val_mean_absolute_error: 0.2028\n",
      "Epoch 165/300\n",
      "271/271 [==============================] - 0s 655us/step - loss: 0.1074 - mean_absolute_error: 0.2118 - val_loss: 0.1122 - val_mean_absolute_error: 0.2042\n",
      "Epoch 166/300\n",
      "271/271 [==============================] - 0s 654us/step - loss: 0.1064 - mean_absolute_error: 0.2094 - val_loss: 0.1162 - val_mean_absolute_error: 0.2019\n",
      "Epoch 167/300\n",
      "271/271 [==============================] - 0s 666us/step - loss: 0.1059 - mean_absolute_error: 0.2091 - val_loss: 0.1267 - val_mean_absolute_error: 0.2110\n",
      "Epoch 168/300\n",
      "271/271 [==============================] - 0s 658us/step - loss: 0.1168 - mean_absolute_error: 0.2117 - val_loss: 0.1213 - val_mean_absolute_error: 0.2169\n",
      "Epoch 169/300\n",
      "271/271 [==============================] - 0s 647us/step - loss: 0.1148 - mean_absolute_error: 0.2122 - val_loss: 0.1171 - val_mean_absolute_error: 0.2093\n",
      "Epoch 170/300\n",
      "271/271 [==============================] - 0s 653us/step - loss: 0.1072 - mean_absolute_error: 0.2109 - val_loss: 0.1116 - val_mean_absolute_error: 0.2062\n",
      "Epoch 171/300\n",
      "271/271 [==============================] - 0s 654us/step - loss: 0.1136 - mean_absolute_error: 0.2126 - val_loss: 0.1094 - val_mean_absolute_error: 0.1995\n",
      "Epoch 172/300\n",
      "271/271 [==============================] - 0s 655us/step - loss: 0.1008 - mean_absolute_error: 0.2090 - val_loss: 0.1172 - val_mean_absolute_error: 0.2020\n",
      "Epoch 173/300\n",
      "271/271 [==============================] - 0s 658us/step - loss: 0.1113 - mean_absolute_error: 0.2112 - val_loss: 0.1116 - val_mean_absolute_error: 0.2015\n",
      "Epoch 174/300\n",
      "271/271 [==============================] - 0s 651us/step - loss: 0.1106 - mean_absolute_error: 0.2111 - val_loss: 0.1051 - val_mean_absolute_error: 0.2039\n",
      "Epoch 175/300\n",
      "271/271 [==============================] - 0s 656us/step - loss: 0.1051 - mean_absolute_error: 0.2094 - val_loss: 0.1205 - val_mean_absolute_error: 0.2040\n",
      "Epoch 176/300\n",
      "271/271 [==============================] - 0s 657us/step - loss: 0.1056 - mean_absolute_error: 0.2113 - val_loss: 0.1168 - val_mean_absolute_error: 0.2122\n",
      "Epoch 177/300\n",
      "271/271 [==============================] - 0s 654us/step - loss: 0.1155 - mean_absolute_error: 0.2137 - val_loss: 0.1189 - val_mean_absolute_error: 0.2057\n",
      "Epoch 178/300\n",
      "271/271 [==============================] - 0s 659us/step - loss: 0.1134 - mean_absolute_error: 0.2133 - val_loss: 0.1072 - val_mean_absolute_error: 0.1938\n",
      "Epoch 179/300\n",
      "271/271 [==============================] - 0s 661us/step - loss: 0.1025 - mean_absolute_error: 0.2088 - val_loss: 0.1205 - val_mean_absolute_error: 0.2176\n",
      "Epoch 180/300\n",
      "271/271 [==============================] - 0s 664us/step - loss: 0.1098 - mean_absolute_error: 0.2118 - val_loss: 0.1263 - val_mean_absolute_error: 0.2162\n",
      "Epoch 181/300\n",
      "271/271 [==============================] - 0s 668us/step - loss: 0.1089 - mean_absolute_error: 0.2110 - val_loss: 0.1201 - val_mean_absolute_error: 0.2013\n",
      "Epoch 182/300\n",
      "271/271 [==============================] - 0s 654us/step - loss: 0.1114 - mean_absolute_error: 0.2130 - val_loss: 0.1321 - val_mean_absolute_error: 0.2168\n",
      "Epoch 183/300\n",
      "271/271 [==============================] - 0s 662us/step - loss: 0.1082 - mean_absolute_error: 0.2116 - val_loss: 0.1175 - val_mean_absolute_error: 0.2105\n",
      "Epoch 184/300\n",
      "271/271 [==============================] - 0s 653us/step - loss: 0.1043 - mean_absolute_error: 0.2098 - val_loss: 0.1161 - val_mean_absolute_error: 0.2151\n",
      "Epoch 185/300\n",
      "271/271 [==============================] - 0s 662us/step - loss: 0.1064 - mean_absolute_error: 0.2105 - val_loss: 0.1207 - val_mean_absolute_error: 0.2142\n",
      "Epoch 186/300\n",
      "271/271 [==============================] - 0s 659us/step - loss: 0.1082 - mean_absolute_error: 0.2108 - val_loss: 0.1145 - val_mean_absolute_error: 0.2158\n",
      "Epoch 187/300\n",
      "271/271 [==============================] - 0s 662us/step - loss: 0.1182 - mean_absolute_error: 0.2136 - val_loss: 0.1260 - val_mean_absolute_error: 0.2077\n",
      "Epoch 188/300\n",
      "271/271 [==============================] - 0s 659us/step - loss: 0.1077 - mean_absolute_error: 0.2115 - val_loss: 0.1287 - val_mean_absolute_error: 0.2081\n",
      "Epoch 189/300\n",
      "271/271 [==============================] - 0s 654us/step - loss: 0.1111 - mean_absolute_error: 0.2124 - val_loss: 0.1415 - val_mean_absolute_error: 0.2146\n",
      "Epoch 190/300\n",
      "271/271 [==============================] - 0s 657us/step - loss: 0.1103 - mean_absolute_error: 0.2122 - val_loss: 0.1238 - val_mean_absolute_error: 0.2139\n",
      "Epoch 191/300\n",
      "271/271 [==============================] - 0s 666us/step - loss: 0.1035 - mean_absolute_error: 0.2090 - val_loss: 0.1166 - val_mean_absolute_error: 0.2098\n",
      "Epoch 192/300\n",
      "271/271 [==============================] - 0s 661us/step - loss: 0.1105 - mean_absolute_error: 0.2110 - val_loss: 0.1393 - val_mean_absolute_error: 0.2185\n",
      "Epoch 193/300\n",
      "271/271 [==============================] - 0s 655us/step - loss: 0.1060 - mean_absolute_error: 0.2102 - val_loss: 0.1265 - val_mean_absolute_error: 0.2054\n",
      "Epoch 194/300\n",
      "271/271 [==============================] - 0s 659us/step - loss: 0.1070 - mean_absolute_error: 0.2098 - val_loss: 0.1201 - val_mean_absolute_error: 0.2081\n",
      "Epoch 195/300\n",
      "271/271 [==============================] - 0s 661us/step - loss: 0.1039 - mean_absolute_error: 0.2094 - val_loss: 0.1258 - val_mean_absolute_error: 0.2109\n",
      "Epoch 196/300\n",
      "271/271 [==============================] - 0s 661us/step - loss: 0.1039 - mean_absolute_error: 0.2083 - val_loss: 0.1097 - val_mean_absolute_error: 0.2050\n",
      "Epoch 197/300\n",
      "271/271 [==============================] - 0s 660us/step - loss: 0.1081 - mean_absolute_error: 0.2105 - val_loss: 0.1175 - val_mean_absolute_error: 0.1982\n",
      "Epoch 198/300\n",
      "271/271 [==============================] - 0s 666us/step - loss: 0.1046 - mean_absolute_error: 0.2079 - val_loss: 0.1275 - val_mean_absolute_error: 0.2080\n",
      "Epoch 199/300\n",
      "271/271 [==============================] - 0s 655us/step - loss: 0.1063 - mean_absolute_error: 0.2100 - val_loss: 0.1253 - val_mean_absolute_error: 0.2141\n",
      "Epoch 200/300\n",
      "271/271 [==============================] - 0s 663us/step - loss: 0.1079 - mean_absolute_error: 0.2095 - val_loss: 0.1149 - val_mean_absolute_error: 0.2088\n",
      "Epoch 201/300\n",
      "271/271 [==============================] - 0s 664us/step - loss: 0.1069 - mean_absolute_error: 0.2095 - val_loss: 0.1393 - val_mean_absolute_error: 0.2127\n",
      "Epoch 202/300\n",
      "271/271 [==============================] - 0s 656us/step - loss: 0.1130 - mean_absolute_error: 0.2105 - val_loss: 0.1242 - val_mean_absolute_error: 0.2095\n",
      "Epoch 203/300\n",
      "271/271 [==============================] - 0s 644us/step - loss: 0.1135 - mean_absolute_error: 0.2123 - val_loss: 0.1243 - val_mean_absolute_error: 0.2094\n",
      "Epoch 204/300\n",
      "271/271 [==============================] - 0s 656us/step - loss: 0.1042 - mean_absolute_error: 0.2085 - val_loss: 0.1191 - val_mean_absolute_error: 0.1954\n",
      "Epoch 205/300\n",
      "271/271 [==============================] - 0s 648us/step - loss: 0.1088 - mean_absolute_error: 0.2100 - val_loss: 0.1338 - val_mean_absolute_error: 0.2192\n",
      "Epoch 206/300\n",
      "271/271 [==============================] - 0s 649us/step - loss: 0.1055 - mean_absolute_error: 0.2096 - val_loss: 0.1370 - val_mean_absolute_error: 0.2137\n",
      "Epoch 207/300\n",
      "271/271 [==============================] - 0s 656us/step - loss: 0.1097 - mean_absolute_error: 0.2093 - val_loss: 0.1251 - val_mean_absolute_error: 0.2121\n",
      "Epoch 208/300\n",
      "271/271 [==============================] - 0s 651us/step - loss: 0.1079 - mean_absolute_error: 0.2110 - val_loss: 0.1142 - val_mean_absolute_error: 0.2082\n",
      "Epoch 209/300\n",
      "271/271 [==============================] - 0s 658us/step - loss: 0.1049 - mean_absolute_error: 0.2097 - val_loss: 0.1129 - val_mean_absolute_error: 0.1995\n",
      "Epoch 210/300\n",
      "271/271 [==============================] - 0s 651us/step - loss: 0.1006 - mean_absolute_error: 0.2069 - val_loss: 0.1156 - val_mean_absolute_error: 0.2105\n",
      "Epoch 211/300\n",
      "271/271 [==============================] - 0s 650us/step - loss: 0.1055 - mean_absolute_error: 0.2076 - val_loss: 0.1210 - val_mean_absolute_error: 0.2057\n",
      "Epoch 212/300\n",
      "271/271 [==============================] - 0s 652us/step - loss: 0.1057 - mean_absolute_error: 0.2084 - val_loss: 0.1167 - val_mean_absolute_error: 0.2092\n",
      "Epoch 213/300\n",
      "271/271 [==============================] - 0s 660us/step - loss: 0.1054 - mean_absolute_error: 0.2079 - val_loss: 0.1217 - val_mean_absolute_error: 0.2159\n",
      "Epoch 214/300\n",
      "271/271 [==============================] - 0s 651us/step - loss: 0.1089 - mean_absolute_error: 0.2111 - val_loss: 0.1206 - val_mean_absolute_error: 0.2137\n",
      "Epoch 215/300\n",
      "271/271 [==============================] - 0s 650us/step - loss: 0.1081 - mean_absolute_error: 0.2101 - val_loss: 0.1114 - val_mean_absolute_error: 0.2109\n",
      "Epoch 216/300\n",
      "271/271 [==============================] - 0s 664us/step - loss: 0.1099 - mean_absolute_error: 0.2116 - val_loss: 0.1158 - val_mean_absolute_error: 0.2171\n",
      "Epoch 217/300\n",
      "271/271 [==============================] - 0s 655us/step - loss: 0.1042 - mean_absolute_error: 0.2105 - val_loss: 0.1118 - val_mean_absolute_error: 0.2102\n",
      "Epoch 218/300\n",
      "271/271 [==============================] - 0s 662us/step - loss: 0.1092 - mean_absolute_error: 0.2113 - val_loss: 0.1253 - val_mean_absolute_error: 0.2242\n",
      "Epoch 219/300\n",
      "271/271 [==============================] - 0s 664us/step - loss: 0.1071 - mean_absolute_error: 0.2097 - val_loss: 0.1217 - val_mean_absolute_error: 0.2100\n",
      "Epoch 220/300\n",
      "271/271 [==============================] - 0s 655us/step - loss: 0.1123 - mean_absolute_error: 0.2126 - val_loss: 0.1181 - val_mean_absolute_error: 0.2116\n",
      "Epoch 221/300\n",
      "271/271 [==============================] - 0s 654us/step - loss: 0.1062 - mean_absolute_error: 0.2096 - val_loss: 0.1172 - val_mean_absolute_error: 0.2086\n",
      "Epoch 222/300\n",
      "271/271 [==============================] - 0s 655us/step - loss: 0.1018 - mean_absolute_error: 0.2070 - val_loss: 0.1178 - val_mean_absolute_error: 0.2059\n",
      "Epoch 223/300\n",
      "271/271 [==============================] - 0s 651us/step - loss: 0.1039 - mean_absolute_error: 0.2097 - val_loss: 0.1255 - val_mean_absolute_error: 0.2123\n",
      "Epoch 224/300\n",
      "271/271 [==============================] - 0s 659us/step - loss: 0.1090 - mean_absolute_error: 0.2092 - val_loss: 0.1213 - val_mean_absolute_error: 0.2056\n",
      "Epoch 225/300\n",
      "271/271 [==============================] - 0s 651us/step - loss: 0.1112 - mean_absolute_error: 0.2107 - val_loss: 0.1325 - val_mean_absolute_error: 0.2119\n",
      "Epoch 226/300\n",
      "271/271 [==============================] - 0s 653us/step - loss: 0.1126 - mean_absolute_error: 0.2112 - val_loss: 0.1156 - val_mean_absolute_error: 0.2116\n",
      "Epoch 227/300\n",
      "271/271 [==============================] - 0s 644us/step - loss: 0.1058 - mean_absolute_error: 0.2088 - val_loss: 0.1178 - val_mean_absolute_error: 0.2188\n",
      "Epoch 228/300\n",
      "271/271 [==============================] - 0s 652us/step - loss: 0.1098 - mean_absolute_error: 0.2105 - val_loss: 0.1263 - val_mean_absolute_error: 0.2131\n",
      "Epoch 229/300\n",
      "271/271 [==============================] - 0s 666us/step - loss: 0.1058 - mean_absolute_error: 0.2093 - val_loss: 0.1301 - val_mean_absolute_error: 0.2142\n",
      "Epoch 230/300\n",
      "271/271 [==============================] - 0s 650us/step - loss: 0.1045 - mean_absolute_error: 0.2091 - val_loss: 0.1029 - val_mean_absolute_error: 0.1981\n",
      "Epoch 231/300\n",
      "271/271 [==============================] - 0s 647us/step - loss: 0.1087 - mean_absolute_error: 0.2083 - val_loss: 0.1101 - val_mean_absolute_error: 0.2045\n",
      "Epoch 232/300\n",
      "271/271 [==============================] - 0s 659us/step - loss: 0.1051 - mean_absolute_error: 0.2092 - val_loss: 0.1193 - val_mean_absolute_error: 0.2133\n",
      "Epoch 233/300\n",
      "271/271 [==============================] - 0s 651us/step - loss: 0.1041 - mean_absolute_error: 0.2082 - val_loss: 0.1132 - val_mean_absolute_error: 0.2016\n",
      "Epoch 234/300\n",
      "271/271 [==============================] - 0s 651us/step - loss: 0.1041 - mean_absolute_error: 0.2094 - val_loss: 0.1135 - val_mean_absolute_error: 0.2009\n",
      "Epoch 235/300\n",
      "271/271 [==============================] - 0s 655us/step - loss: 0.1041 - mean_absolute_error: 0.2085 - val_loss: 0.1192 - val_mean_absolute_error: 0.2022\n",
      "Epoch 236/300\n",
      "271/271 [==============================] - 0s 655us/step - loss: 0.1084 - mean_absolute_error: 0.2094 - val_loss: 0.1266 - val_mean_absolute_error: 0.2029\n",
      "Epoch 237/300\n",
      "271/271 [==============================] - 0s 663us/step - loss: 0.1075 - mean_absolute_error: 0.2085 - val_loss: 0.1292 - val_mean_absolute_error: 0.2066\n",
      "Epoch 238/300\n",
      "271/271 [==============================] - 0s 663us/step - loss: 0.1054 - mean_absolute_error: 0.2089 - val_loss: 0.1238 - val_mean_absolute_error: 0.2058\n",
      "Epoch 239/300\n",
      "271/271 [==============================] - 0s 669us/step - loss: 0.1054 - mean_absolute_error: 0.2077 - val_loss: 0.1299 - val_mean_absolute_error: 0.2071\n",
      "Epoch 240/300\n",
      "271/271 [==============================] - 0s 659us/step - loss: 0.1072 - mean_absolute_error: 0.2107 - val_loss: 0.1051 - val_mean_absolute_error: 0.1978\n",
      "Epoch 241/300\n",
      "271/271 [==============================] - 0s 659us/step - loss: 0.1081 - mean_absolute_error: 0.2090 - val_loss: 0.1202 - val_mean_absolute_error: 0.2040\n",
      "Epoch 242/300\n",
      "271/271 [==============================] - 0s 655us/step - loss: 0.1083 - mean_absolute_error: 0.2116 - val_loss: 0.1227 - val_mean_absolute_error: 0.2059\n",
      "Epoch 243/300\n",
      "271/271 [==============================] - 0s 710us/step - loss: 0.1082 - mean_absolute_error: 0.2083 - val_loss: 0.1146 - val_mean_absolute_error: 0.2072\n",
      "Epoch 244/300\n",
      "271/271 [==============================] - 0s 780us/step - loss: 0.1099 - mean_absolute_error: 0.2093 - val_loss: 0.1190 - val_mean_absolute_error: 0.2065\n",
      "Epoch 245/300\n",
      "271/271 [==============================] - 0s 688us/step - loss: 0.1057 - mean_absolute_error: 0.2094 - val_loss: 0.1058 - val_mean_absolute_error: 0.2017\n",
      "Epoch 246/300\n",
      "271/271 [==============================] - 0s 681us/step - loss: 0.1075 - mean_absolute_error: 0.2102 - val_loss: 0.1038 - val_mean_absolute_error: 0.1932\n",
      "Epoch 247/300\n",
      "271/271 [==============================] - 0s 696us/step - loss: 0.1041 - mean_absolute_error: 0.2085 - val_loss: 0.1098 - val_mean_absolute_error: 0.1970\n",
      "Epoch 248/300\n",
      "271/271 [==============================] - 0s 681us/step - loss: 0.1060 - mean_absolute_error: 0.2093 - val_loss: 0.1336 - val_mean_absolute_error: 0.2088\n",
      "Epoch 249/300\n",
      "271/271 [==============================] - 0s 677us/step - loss: 0.1073 - mean_absolute_error: 0.2115 - val_loss: 0.1269 - val_mean_absolute_error: 0.2072\n",
      "Epoch 250/300\n",
      "271/271 [==============================] - 0s 764us/step - loss: 0.1070 - mean_absolute_error: 0.2091 - val_loss: 0.1313 - val_mean_absolute_error: 0.2225\n",
      "Epoch 251/300\n",
      "271/271 [==============================] - 0s 683us/step - loss: 0.1068 - mean_absolute_error: 0.2095 - val_loss: 0.1204 - val_mean_absolute_error: 0.2035\n",
      "Epoch 252/300\n",
      "271/271 [==============================] - 0s 842us/step - loss: 0.1028 - mean_absolute_error: 0.2082 - val_loss: 0.1213 - val_mean_absolute_error: 0.2044\n",
      "Epoch 253/300\n",
      "271/271 [==============================] - 0s 751us/step - loss: 0.1049 - mean_absolute_error: 0.2078 - val_loss: 0.1195 - val_mean_absolute_error: 0.1986\n",
      "Epoch 254/300\n",
      "271/271 [==============================] - 0s 688us/step - loss: 0.1044 - mean_absolute_error: 0.2085 - val_loss: 0.1307 - val_mean_absolute_error: 0.2206\n",
      "Epoch 255/300\n",
      "271/271 [==============================] - 0s 673us/step - loss: 0.1026 - mean_absolute_error: 0.2077 - val_loss: 0.1426 - val_mean_absolute_error: 0.2337\n",
      "Epoch 256/300\n",
      "271/271 [==============================] - 0s 696us/step - loss: 0.1051 - mean_absolute_error: 0.2094 - val_loss: 0.1354 - val_mean_absolute_error: 0.2195\n",
      "Epoch 257/300\n",
      "271/271 [==============================] - 0s 683us/step - loss: 0.1041 - mean_absolute_error: 0.2085 - val_loss: 0.1336 - val_mean_absolute_error: 0.2209\n",
      "Epoch 258/300\n",
      "271/271 [==============================] - 0s 676us/step - loss: 0.1089 - mean_absolute_error: 0.2094 - val_loss: 0.1155 - val_mean_absolute_error: 0.2056\n",
      "Epoch 259/300\n",
      "271/271 [==============================] - 0s 747us/step - loss: 0.1045 - mean_absolute_error: 0.2081 - val_loss: 0.1134 - val_mean_absolute_error: 0.2029\n",
      "Epoch 260/300\n",
      "271/271 [==============================] - 0s 751us/step - loss: 0.1064 - mean_absolute_error: 0.2089 - val_loss: 0.1292 - val_mean_absolute_error: 0.2116\n",
      "Epoch 261/300\n",
      "271/271 [==============================] - 0s 688us/step - loss: 0.1035 - mean_absolute_error: 0.2079 - val_loss: 0.1204 - val_mean_absolute_error: 0.2074\n",
      "Epoch 262/300\n",
      "271/271 [==============================] - 0s 677us/step - loss: 0.1100 - mean_absolute_error: 0.2110 - val_loss: 0.1168 - val_mean_absolute_error: 0.2056\n",
      "Epoch 263/300\n",
      "271/271 [==============================] - 0s 662us/step - loss: 0.1071 - mean_absolute_error: 0.2073 - val_loss: 0.1142 - val_mean_absolute_error: 0.2004\n",
      "Epoch 264/300\n",
      "271/271 [==============================] - 0s 687us/step - loss: 0.1101 - mean_absolute_error: 0.2098 - val_loss: 0.1519 - val_mean_absolute_error: 0.2340\n",
      "Epoch 265/300\n",
      "271/271 [==============================] - 0s 699us/step - loss: 0.1117 - mean_absolute_error: 0.2121 - val_loss: 0.1429 - val_mean_absolute_error: 0.2210\n",
      "Epoch 266/300\n",
      "271/271 [==============================] - 0s 807us/step - loss: 0.1037 - mean_absolute_error: 0.2094 - val_loss: 0.1163 - val_mean_absolute_error: 0.2084\n",
      "Epoch 267/300\n",
      "271/271 [==============================] - 0s 706us/step - loss: 0.1050 - mean_absolute_error: 0.2062 - val_loss: 0.1228 - val_mean_absolute_error: 0.2021\n",
      "Epoch 268/300\n",
      "271/271 [==============================] - 0s 662us/step - loss: 0.1036 - mean_absolute_error: 0.2072 - val_loss: 0.1252 - val_mean_absolute_error: 0.2193\n",
      "Epoch 269/300\n",
      "271/271 [==============================] - 0s 681us/step - loss: 0.1004 - mean_absolute_error: 0.2066 - val_loss: 0.1314 - val_mean_absolute_error: 0.2206\n",
      "Epoch 270/300\n",
      "271/271 [==============================] - 0s 718us/step - loss: 0.1038 - mean_absolute_error: 0.2079 - val_loss: 0.1198 - val_mean_absolute_error: 0.2088\n",
      "Epoch 271/300\n",
      "271/271 [==============================] - 0s 707us/step - loss: 0.1142 - mean_absolute_error: 0.2104 - val_loss: 0.1136 - val_mean_absolute_error: 0.1983\n",
      "Epoch 272/300\n",
      "271/271 [==============================] - 0s 683us/step - loss: 0.1005 - mean_absolute_error: 0.2057 - val_loss: 0.1124 - val_mean_absolute_error: 0.2054\n",
      "Epoch 273/300\n",
      "271/271 [==============================] - 0s 692us/step - loss: 0.0968 - mean_absolute_error: 0.2050 - val_loss: 0.1268 - val_mean_absolute_error: 0.2020\n",
      "Epoch 274/300\n",
      "271/271 [==============================] - 0s 720us/step - loss: 0.1029 - mean_absolute_error: 0.2071 - val_loss: 0.1167 - val_mean_absolute_error: 0.2128\n",
      "Epoch 275/300\n",
      "271/271 [==============================] - 0s 777us/step - loss: 0.1028 - mean_absolute_error: 0.2072 - val_loss: 0.1135 - val_mean_absolute_error: 0.1999\n",
      "Epoch 276/300\n",
      "271/271 [==============================] - 0s 683us/step - loss: 0.1026 - mean_absolute_error: 0.2067 - val_loss: 0.1177 - val_mean_absolute_error: 0.2066\n",
      "Epoch 277/300\n",
      "271/271 [==============================] - 0s 692us/step - loss: 0.1057 - mean_absolute_error: 0.2093 - val_loss: 0.1319 - val_mean_absolute_error: 0.2019\n",
      "Epoch 278/300\n",
      "271/271 [==============================] - 0s 702us/step - loss: 0.1047 - mean_absolute_error: 0.2072 - val_loss: 0.1238 - val_mean_absolute_error: 0.2123\n",
      "Epoch 279/300\n",
      "271/271 [==============================] - 0s 688us/step - loss: 0.1067 - mean_absolute_error: 0.2076 - val_loss: 0.1053 - val_mean_absolute_error: 0.1997\n",
      "Epoch 280/300\n",
      "271/271 [==============================] - 0s 692us/step - loss: 0.1014 - mean_absolute_error: 0.2070 - val_loss: 0.1285 - val_mean_absolute_error: 0.2147\n",
      "Epoch 281/300\n",
      "271/271 [==============================] - 0s 699us/step - loss: 0.1132 - mean_absolute_error: 0.2100 - val_loss: 0.1094 - val_mean_absolute_error: 0.2001\n",
      "Epoch 282/300\n",
      "271/271 [==============================] - 0s 692us/step - loss: 0.1080 - mean_absolute_error: 0.2084 - val_loss: 0.1331 - val_mean_absolute_error: 0.2263\n",
      "Epoch 283/300\n",
      "271/271 [==============================] - 0s 695us/step - loss: 0.1078 - mean_absolute_error: 0.2105 - val_loss: 0.1234 - val_mean_absolute_error: 0.2117\n",
      "Epoch 284/300\n",
      "271/271 [==============================] - 0s 701us/step - loss: 0.1064 - mean_absolute_error: 0.2086 - val_loss: 0.1082 - val_mean_absolute_error: 0.1993\n",
      "Epoch 285/300\n",
      "271/271 [==============================] - 0s 706us/step - loss: 0.1008 - mean_absolute_error: 0.2068 - val_loss: 0.1300 - val_mean_absolute_error: 0.2129\n",
      "Epoch 286/300\n",
      "271/271 [==============================] - 0s 673us/step - loss: 0.0990 - mean_absolute_error: 0.2067 - val_loss: 0.1228 - val_mean_absolute_error: 0.2035\n",
      "Epoch 287/300\n",
      "271/271 [==============================] - 0s 744us/step - loss: 0.1025 - mean_absolute_error: 0.2067 - val_loss: 0.1500 - val_mean_absolute_error: 0.2177\n",
      "Epoch 288/300\n",
      "271/271 [==============================] - 0s 687us/step - loss: 0.1014 - mean_absolute_error: 0.2061 - val_loss: 0.1170 - val_mean_absolute_error: 0.2213\n",
      "Epoch 289/300\n",
      "271/271 [==============================] - 0s 710us/step - loss: 0.1016 - mean_absolute_error: 0.2075 - val_loss: 0.1100 - val_mean_absolute_error: 0.2070\n",
      "Epoch 290/300\n",
      "271/271 [==============================] - 0s 704us/step - loss: 0.1068 - mean_absolute_error: 0.2089 - val_loss: 0.1181 - val_mean_absolute_error: 0.2055\n",
      "Epoch 291/300\n",
      "271/271 [==============================] - 0s 670us/step - loss: 0.1054 - mean_absolute_error: 0.2077 - val_loss: 0.1306 - val_mean_absolute_error: 0.2088\n",
      "Epoch 292/300\n",
      "271/271 [==============================] - ETA: 0s - loss: 0.1069 - mean_absolute_error: 0.211 - 0s 730us/step - loss: 0.1059 - mean_absolute_error: 0.2105 - val_loss: 0.1292 - val_mean_absolute_error: 0.2157\n",
      "Epoch 293/300\n",
      "271/271 [==============================] - 0s 688us/step - loss: 0.1061 - mean_absolute_error: 0.2094 - val_loss: 0.1151 - val_mean_absolute_error: 0.2074\n",
      "Epoch 294/300\n",
      "271/271 [==============================] - 0s 725us/step - loss: 0.1034 - mean_absolute_error: 0.2089 - val_loss: 0.1164 - val_mean_absolute_error: 0.2126\n",
      "Epoch 295/300\n",
      "271/271 [==============================] - 0s 672us/step - loss: 0.1002 - mean_absolute_error: 0.2070 - val_loss: 0.1318 - val_mean_absolute_error: 0.2167\n",
      "Epoch 296/300\n",
      "271/271 [==============================] - 0s 677us/step - loss: 0.1029 - mean_absolute_error: 0.2069 - val_loss: 0.1234 - val_mean_absolute_error: 0.2072\n",
      "Epoch 297/300\n",
      "271/271 [==============================] - 0s 696us/step - loss: 0.1074 - mean_absolute_error: 0.2087 - val_loss: 0.1198 - val_mean_absolute_error: 0.2010\n",
      "Epoch 298/300\n",
      "271/271 [==============================] - 0s 707us/step - loss: 0.1018 - mean_absolute_error: 0.2071 - val_loss: 0.1195 - val_mean_absolute_error: 0.2049\n",
      "Epoch 299/300\n",
      "271/271 [==============================] - 0s 703us/step - loss: 0.1114 - mean_absolute_error: 0.2109 - val_loss: 0.1132 - val_mean_absolute_error: 0.2029\n",
      "Epoch 300/300\n",
      "271/271 [==============================] - 0s 735us/step - loss: 0.1015 - mean_absolute_error: 0.2073 - val_loss: 0.1132 - val_mean_absolute_error: 0.2135\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ce4dbead88>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4 = keras.Sequential(name='model-4')\n",
    "model_4.add(layers.Dense(64, activation='relu', input_shape=(21,)))\n",
    "model_4.add(layers.Dropout(0.3))\n",
    "model_4.add(layers.Dense(64, activation='relu'))\n",
    "model_4.add(layers.Dropout(0.3))\n",
    "model_4.add(layers.Dense(1))\n",
    "model_4.compile(keras.optimizers.Adam(0.001),\n",
    "                loss=keras.losses.MeanSquaredError(),\n",
    "                metrics=[keras.metrics.MeanAbsoluteError()])\n",
    "log_dir = os.path.join('lab2-logs', 'model-4')\n",
    "model_cbk = keras.callbacks.TensorBoard(log_dir=log_dir)\n",
    "model_mckp = keras.callbacks.ModelCheckpoint(model_dir + '/Best-model-4.h5', \n",
    "                                             monitor='val_mean_absolute_error', \n",
    "                                             save_best_only=True, \n",
    "                                             mode='min')\n",
    "model_4.fit(x_train, y_train, \n",
    "            batch_size=64 ,\n",
    "            epochs=300, \n",
    "            validation_data=(x_val, y_val), \n",
    "            callbacks=[model_cbk, model_mckp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8bbbc54b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_2: 13.20%\n",
      "Model_3: 12.69%\n",
      "Model_4: 13.48%\n"
     ]
    }
   ],
   "source": [
    "model_2 = keras.models.load_model('lab2-logs/models/Best-model-2.h5')\n",
    "y_pred = model_2.predict(x_test)\n",
    "y_pred = np.reshape(y_pred * std['price'] + mean['price'], y_test.shape)\n",
    "percentage_error = np.mean(np.abs(y_test - y_pred)) / np.mean(y_test) * 100\n",
    "print(\"Model_2: {:.2f}%\".format(percentage_error))\n",
    "model_3 = keras.models.load_model('lab2-logs/models/Best-model-3.h5')\n",
    "y_pred = model_3.predict(x_test)\n",
    "y_pred = np.reshape(y_pred * std['price'] + mean['price'], y_test.shape)\n",
    "percentage_error = np.mean(np.abs(y_test - y_pred)) / np.mean(y_test) * 100\n",
    "print(\"Model_3: {:.2f}%\".format(percentage_error))\n",
    "model_4 = keras.models.load_model('lab2-logs/models/Best-model-4.h5')\n",
    "y_pred = model_4.predict(x_test)\n",
    "y_pred = np.reshape(y_pred * std['price'] + mean['price'], y_test.shape)\n",
    "percentage_error = np.mean(np.abs(y_test - y_pred)) / np.mean(y_test) * 100\n",
    "print(\"Model_4: {:.2f}%\".format(percentage_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1380d6bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
